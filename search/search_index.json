{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome to the official Portainer Documentation. This is an open source documentation project and all community contributions are welcome and encouraged. For information about contributing to the Portainer documentation, see Contribution guidelines . About Portainer Portainer Community Edition 2.0 is the foundation of the Portainer world. With over half a million regular users, it\u2019s a powerful, open-source toolset that allows you to easily build and manage containers in Docker, Swarm, Kubernetes and Azure ACI. Portainer works by hiding the complexity that makes managing containers hard, behind an easy to use GUI. By negating the need for users to use CLI, write YAML or understand manifests, Portainer makes deploying apps and troubleshooting problems so simple, anyone can do it. The Portainer development team is here to assist you on your container journey; you can engage with them any time through our community-based support channels. Knowledge Base and FAQs As the Portainer community continues to grow, we continue to support the community to the best of our ability. To streamline our operations and allow us to focus on delivering the right support and features in the right areas at the right time we encourage you to refer to our comprehensive Knowledge Base for any queries you may have. If you can't find what you're looking for Knowledge Base then please refer to one of the following support channels Support Channels Being a free and opensource product, we have been heavily reliant on our community to provide \"how to\" support to our community, recently we have invested significant time in improving and updating our documentation found on this site and our YouTube channel . While we endeavour to cover as many scenarios as possible there may be some that our documentation doesn\u2019t cover. QUESTIONS should be posted to either Github Issues or the community Slack channel . While other platforms exist (Reddit, Discord, Stack Overflow) the Portainer team is less active in these. Suspected BUGS should be posted to Github and will be managed by our support and development teams as appropriate. VULNERABILITIES should be emailed to security@portainer.io and will be dealt with immediately. ISSUES IN OUR DOCUMENTATION can be raised through our Github Documentation Channel , or you can follow the user contribution guidelines. We will not provide support over email. Notes Contribute to these docs","title":"Home"},{"location":"agent/","text":"Agent Purpose The Portainer Agent is a workaround for a Docker API limitation when using the Docker API to manage a Docker environment. The user interactions with specific resources (containers, networks, volumes and images) are limited to those available on the node targeted by the Docker API request. Docker Swarm mode introduces a concept which is the clustering of Docker nodes. It also adds services, tasks, configs and secrets which are cluster-aware resources. Cluster-aware means that you can query for a list of services or inspect a task inside any node on the cluster, as long as you\u2019re executing the Docker API request on a manager node. Containers, networks, volumes and images are node specific resources, not cluster-aware. When you, for example, want to list all the volumes available on a node inside your cluster, you will need to send a query to that specific node. The purpose of the agent aims to allow previously node specific resources to be cluster-aware. All while keeping the Docker API request format. As aforementioned, this means that you only need to execute one Docker API request to retrieve all these resources from every node inside the cluster. In all bringing a better Docker user experience when managing Swarm clusters. Deployment Instructions on how to deploy the Agent and how to connect it to Portainer. Deploy it as a stack Have a look at the deployment documentation Inside a Swarm cluster to quickly deploy the agent and a Portainer instance inside a Swarm cluster via docker stack deploy . Manual deployment Overall, the setup consists of the following steps: Step 1: Create a new overlay network in your Swarm cluster for the Agent. Step 2: Deploy the Agent as a global service in your cluster (connected to the overlay network). Step 3: Connect your Portainer instance to any of the agents by using the Agent's IP:PORT as an endpoint. Note : This setup assumes that you are executing the following instructions on a Swarm manager node. Step 1 , creating a new overlay network in your Swarm cluster: $ docker network create --driver overlay --attachable portainer_agent_network Step 2 , deploying the Agent as a global service in your cluster: $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --mode global \\ --constraint 'node.platform.os == linux' \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Step 3 , deploying the Portainer instance as a service: $ docker service create \\ --name portainer \\ --network portainer_agent_network \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ portainer/portainer -H \"tcp://tasks.portainer_agent:9001\" --tlsskipverify Step 4 , deploying the Agent for all Windows Server nodes Because of Docker limitation you need to deploy the Agent to all Windows Server nodes by running following command on each of them. $ docker run -d --name portainer_agent --restart always --network portainer_agent_network -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mount type=npipe,source=\\\\.\\pipe\\docker_engine,target=\\\\.\\pipe\\docker_engine portainer/agent:windows1803-amd64 Note : If you're using Windows server 1803, you might need to open up DNS ports to support the DNS resolution of tasks.portainer_agent. See: https://success.docker.com/article/swarm-internal-dns-is-inaccessible-on-windows-server-1803 Connecting an existing Portainer instance to an agent If you want to connect an existing Portainer instance to an agent, you can choose the Agent environment type when creating a new endpoint. Ensure when deploying the agent, that you expose the Agent's port inside your Swarm cluster, and that the mode is set to host (default port is 9001): $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --publish mode=host,target=9001,published=9001 \\ --mode global \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Note : Please be aware that this could potentially open up the Agent for use by anybody in case the Docker host is reachable from the internet. Publishing the Agent port 9001 in host mode basically means opening up this port in the Docker hosts firewall for all interfaces. Therefore it is highly recommended to use the AGENT_SECRET environment variable to define a shared secret, see Shared secret. The Agent implements the Trust On First Use (TOFU) principle, so only the first Portainer to connect will be able to use it, but you want to avoid an attacker beating you to it. You can then use the address of any node in your cluster (with the agent port) inside the Agent URL field. Alternatively, you can deploy the agent using the following stack: version: '3.2' services: agent: image: portainer/agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true Note : In case you are running only a single Agent cluster in the same Swarm overlay network as your Portainer instance, you can just omit publishing the Agent port 9001. Portainer and the Agents will be able to communicate with each other inside the same overlay network and there is no need for the Agents to be accessible from the outside. Configuration You can use variant agent configurations to achieve different setups or enable specific features. Shared secret By default, the agent will register the first Portainer instance that connects to it and prevent connections from any other instance after that. To bypass this security mechanism, Portainer and the agent can be configured at deployment time to use a shared secret. This configuration allows multiple Portainer instances to connect to the same agent endpoint. The AGENT_SECRET environment variable can be used to define the shared secret. When deploying the agent as a service: $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --publish mode=host,target=9001,published=9001 \\ -e AGENT_SECRET=mysecrettoken \\ --mode global \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Via a stack file: version: '3.2' services: agent: image: portainer/agent environment: AGENT_SECRET: mysecrettoken volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true The AGENT_SECRET must be specified when deploying Portainer as well: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -e AGENT_SECRET=mysecrettoken -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer Enable host management features The following features are disabled by default for security reasons: Ability to manage the filesystem of the host where the agent is running Ability to retrieve hardware information about the host where the agent is running (PCI devices/disks) In order to enable these features, the agent must be configured properly by: Enabling the host management features via the CAP_HOST_MANAGEMENT environment variable Bind-mounting the root of the host in the agent container (must be bind-mounted in /host ) Example when deploying the agent via a stack file: version: '3.2' services: agent: image: portainer/agent environment: CAP_HOST_MANAGEMENT: 1 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true Available options You can change the configuration of the agent by using environment variables. The following environment variables can be tuned: AGENT_PORT: Agent port (default: 9001 ) LOG_LEVEL: Agent log level (default: INFO ) AGENT_CLUSTER_ADDR: Address used by each agent to form a cluster. AGENT_SECRET: Shared secret used to authorize Portainer instances to connect to the agent CAP_HOST_MANAGEMENT: Enable host management features by setting the value to 1 Usage API If you want to use the Portainer API to query containers running on a specific node inside a Swarm cluster and when using the Portainer agent setup, you can specify the X-PortainerAgent-Target header in the HTTP request to target a specific node in the cluster. The value must be set to the name of a specific node that can be retrieved via the NodeName property when querying cluster resources (containers, volumes...).","title":"Agent"},{"location":"api/","text":"API Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. You may also use Portainer as a gateway (HTTP queries against the Portainer API) to the underlying Docker/Kubernetes API. API documentation is available on Swaggerhub Examples The following examples use httpie to execute API calls against Portainer Initialize the admin password On a fresh install of Portainer, you need to create an admin account to initialize Portainer. You will be asked for this when you visit the Portainer url for the very first time. You can acheive the same using the below http POST <portainer url>/api/users/admin/init Username = \"<admin username>\" Password = \"<adminpassword>\" Authenticate against the API using the admin account http POST <portainer url>/api/auth Username = \"<admin username>\" Password = \"<adminpassword>\" The response is a JSON object containing the JWT token inside the jwt field: { \"jwt\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" } You need to retrieve this token. You will need to pass this token inside the Authorization header when executing an authentication query against the API. The value of the Authorization header must be of the form Bearer . Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE Note : This token has a 8 hour validity, you'll need to generate another token to execute authenticated queries once this one expires. Create a new endpoint Here, We'll show how to create 3 different types of endpoints: Local endpoint using Docker socket communication Remote endpoint using TCP communication Remote endpoint using TCP communication secured via TLS Local endpoint via the Docker socket This query will create an endpoint called test-local and will use the Docker socket to communicate with this environment. Note : This example requires to you bind-mount the Docker socket when running Portainer. http --form POST <portainer url/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"<endpoint name>\" EndpointCreationType = 1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 2 , \"Name\" : \"<endpoint name>\" , \"PublicURL\" : \"\" , \"Type\" : 1 , \"TLSConfig\" : { \"TLS\" : false , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"unix:///var/run/docker.sock\" } Remote endpoint This query will create an endpoint called test-remote and will communicate with this environment over TCP using the IP address 10.0.7.10 and port 2375 (these are example values, ensure that you're using the correct IP & port). Note : The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST <portainer url>/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"test-remote\" URL = \"tcp://10.0.7.10:2375\" EndpointCreationType = 1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 1 , \"Type\" : 1 , \"Name\" : \"test-remote\" , \"PublicURL\" : \"\" , \"TLSConfig\" : { \"TLS\" : false , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"tcp://10.0.7.10:2375\" } Remote endpoint secured using TLS This query will create an endpoint called test-remote-tls and will communicate with this environment over TCP (secured with TLS) using the IP address 10.0.7.10 and port 2376 (these are example values, ensure that you're using the correct IP & port). Note : The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST <portainer url>/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"test-remote-tls\" URL = \"tcp://10.0.7.10:2376\" EndpointCreationType = 1 TLS = \"true\" TLSCACertFile@/path/to/ca.pem TLSCertFile@/path/to/cert.pem TLSKeyFile@/path/to/key.pem The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 1 , \"Type\" : 1 , \"Name\" : \"test-remote\" , \"PublicURL\" : \"\" , \"TLSConfig\" : { \"TLS\" : true , \"TLSCACert\" : \"/data/tls/1/ca.pem\" , \"TLSCert\" : \"/data/tls/1/cert.pem\" , \"TLSKey\" : \"/data/tls/1/key.pem\" , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"tcp://10.0.7.10:2376\" } Execute Docker queries against a specific endpoint By using the following Portainer HTTP API endpoint /api/endpoints/ /docker, you can now execute any of the Docker HTTP API requests. This Portainer HTTP API endpoint acts as a reverse-proxy to the Docker HTTP API. Note : You can refer to the Docker API documentation to get more information on how you can query the Docker engine. List all containers Here is how you can list all the containers available in a specific endpoint: http GET <portainer url>/api/endpoints/1/docker/containers/json \\ \"Authorization: Bearer <jwt token>\" \\ all == true The response is exactly the same as returned by the ContainerList operation of the Docker API, see the documentation for the ContainerList operation . Create a container Here is how you can create a container in a specific endpoint using the Portainer HTTP API as a gateway. This query will create a new Docker container inside the endpoint using the ID 1. The container will be named web01, use the nginx:latest Docker image and publish the container port 80 on via the 8080 port on the host. See the link below to retrieve more information on how you can create a container using the Docker HTTP API. http POST <portainer url>/api/endpoints/1/docker/containers/create \\ \"Authorization: Bearer <jwt token>\" \\ name == \"web01\" Image = \"nginx:latest\" \\ ExposedPorts: = '{ \"80/tcp\": {} }' \\ HostConfig: = '{ \"PortBindings\": { \"80/tcp\": [{ \"HostPort\": \"8080\" }] } }' The response is exactly the same as returned by the ContainerCreate operation of the Docker API, see the documentation for the ContainerCreate operation . Example response: { \"Id\" : \"5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107\" , \"Warnings\" : null } Retrieve the ID of the container, you will need it to execute actions against that container. Start a container You can now start the container that you previously created using the endpoint /api/endpoints/ /docker/containers/ /start (ensure you retrieved the ID of the container created previsouly): http POST <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107/start \\ \"Authorization: Bearer <jwt token>\" The response is exactly the same as returned by the ContainerStart operation of the Docker API, see the documentation for the ContainerStart operation . Delete a container You can create a container using the following endpoint /api/endpoints/ /docker/containers/ : http DELETE <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107 \\ \"Authorization: <jwt token>\" \\ force == true The response is exactly the same as returned by the ContainerDelete operation of the Docker API, see the documentation for the ContainerDelete operation . More Examples to be added soon Notes Contribute to these docs","title":":fontawesome-solid-code: API"},{"location":"quickstart/","text":"Installation Portainer is available in two flavours: Portainer CE and Portainer Business. Portainer CE is open source, free forever and suitable for use in home/home lab environments. Portainer Business builds on CE and adds the business-related functionality necessary to deploy Portainer in more complex, multi-cluster environments. View a feature comparison here . Choose the version of Portainer you would like to deploy Portainer CE Portainer can be deployed to Docker, Docker Swarm or Kubernetes environments. Click on the button to go to the relevant Installation Guide. Find installation requirements and the validated configuration matrix here Docker Docker Swarm Kubernetes Portainer Business Portainer Business requires a valid license to run. You can get free 30 day trial license here and a quote for purchasing a license here . Portainer can be deployed to Docker, Docker Swarm or Kubernetes environments. Click on the button to go to the relevant Installation Guide. Find installation requirements and the validated configuration matrix here Docker Docker Swarm Kubernetes Notes Contribute to these docs","title":"Quick Start"},{"location":"releasenotes/","text":"Release Notes Read about the new and enhanced features in our latest releases here. Portainer Business Release 2.4 Kubernetes\u200b Pods without workloads are now displayed as applications Improved UI/UX of configurations for creation / edition Introduced request of confirmation upon volume removal Introduced the advanced deployment panel to each resource list view Updated validation to prevent a user from exposing an application over an external load balancer with mixed protocols Introduced the ability to display the access policy associated to the storage of a volume Clarified advanced deployment feature Clarified sensitive configuration creation Clarified ingress controller configuration in the cluster setup view Renamed the create entry from file button when creating a configuration Improved validation warnings in the application creation / edition views Removed extra whitespace in stacks and storage datatables Fixed issue with access management feature on resource pools Fixed issue with ability to retrieve configs when a config is a binary file Fixed issue with advanced deployment feature on agent and Edge agent endpoints Fixed an issue that would mark a sensitive configuration as external without owner after an update Fixed issue with access to configuration details view for a configuration containing binary data Fixed labels to display system labels first in the node details view Fixed refresh issue on the view with the YAML panel selected Fixed invalid display issue when accessing the load balancer panel from the application panel Fixed issue when accessing the cluster setup incorrectly expanding the Endpoint sidebar Fixed issue with exposed configuration keys over filesystem inside an application not being applied Fixed issue when Adding a key to existing used configuration that would throw an error when editing an application using that configuration Fixed an issue with the form validation in the configuration creation view Fixed issue with resource pool \u201ccreated\u201d attribute not showing actual creation time Fixed issue with ability to apply a note to a Pod type application Fixed issue with creating Kubernetes resources with a username longer than 63 characters Fixed issue with special characters in usernames when creating Kubernetes resources Fixed issue with ability to retrieve config map error when trying to manager newly create resource pool \u200b Activity Logging \u200b Introduced user authentication activity logging Introduced user activity logging \u200b RBAC \u200b Introduced new RBAC \u201cOperator\u201d Role Fixed issue with user in 2 team with mix of helpdesk & endpoint admin resulting in the user having permissions of endpoint admin \u200b Registries \u200b Fixed issue causing Portainer to forget the password associated to a registry after an update Fixed issue preventing the registry manager feature to work properly with a ProGet registry Improved description for advanced mode usage with private registries \u200b Swarm \u200b Introduced validation to prevent adding a mount with nothing filled to and exiting service Fixed issue in service creation, switching to bind mode from volume mode with a volume selected fills the host field with {object Object} \u200b Stacks \u200b Introduced support for creating stacks with the same name across different endpoints Introduced extra stack information: creation, last update time and user who created the stack Minor UX change for the start/stop stack action Fixed issue with ability to use private registries with Standalone stacks Fixed issue showing editor tab on limited stacks when it should not Fixed issue when editing a stack, hitting backspace or delete keys with contents of web editor selected hides the entire editor UI element Fixed issue with stack create via API with a regular user account are incorrectly marked as administrator only Fixed issue of error being displayed when creating a stack on docker standalone despite the stack is created Fixed issue of stacks being created via API incorrectly marked private with no owner \u200b Docker \u200b Introduced support for Compose > v2 when deploying a stack on a Docker standalone environment Introduced the ability to download log file from Docker container/service views Display labels in Image Details Clarify the description of the restrict external access to the network property when creating a network \u200b User Management \u200b Automatically lowercase username when authenticating users Update the authentication UX to put an emphasis on OAuth when OAuth is enabled \u200b Portainer Introduced the ability to backup / restore Portainer Fixed issue of version not being shown correctly after update Support starting Portainer without having to specify any endpoint \u200b ACI Introduced RBAC to ACI Introduced UAC to ACI \u200b Minor Changes\u200b Removed the new version check Changed the license server errors to be a silent fail for offline environments Added JS source map for Portainer UI Release 2.0.1 Fixes Fix an issue preventing a user from creating Kuberneres resources if they have a @ character in their username Users with a @ character in their username were not able to create the following Kubernetes resources: Resource pool Application Configuration Fix platform issues with the Docker image for Portainer Business The Docker image can now be successfully deployed on the following platforms: Linux ARM64 Linux ARM Minor update to the license server mechanism The license server mechanism has been updated. Release 2.0.0 Initial Release of Portainer Business Portainer CE Latest release notes for Community Edition are availble here Notes Contribute to these docs","title":"Release Notes"},{"location":"upgrade/","text":"Switch from CE to Portainer Business Instructions to upgrade from CE to Portainer Business (including Free Trial Accounts) can be found here. Upgrade a Portainer Version Choose a Portainer Edition that you would like to Upgrade Portainer CE We have tested and validated Portainer CE Version Upgrades from 1.24.0 to the latest. Although un-tested, it is possible an upgrade path that has not been validated might work. It is recommended to test any upgrade path, validated or non-validated on a non critical system before applying it to your active production systems. You can find Requirements for different versions of Portainer here Backup Backup and Restore feature is available since Portainer CE Ver 2.5. It is higly recommended that you have a backup of Portainer before upgrade. Instructions here Upgrade Instructions for different deployments below... Docker DockerSwarm Kubernetes Portainer Business We have tested and validated Portainer Business Version Upgrades from 2.0.0 to the latest. It is recommended to test any upgrade path, validated or non-validated on a non critical system before applying it to your active production systems. You can find Requirements for different versions of Portainer here Backup Backup and Restore feature is available since Portainer Business Ver 2.4. It is higly recommended that you have a backup of Portainer before upgrade. Instructions here Upgrade Instructions for different deployments below... Docker DockerSwarm Kubernetes Notes Contribute to these docs","title":"Upgrade Path"},{"location":"api/api-examples/","text":"API Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. You may also use Portainer as a gateway (HTTP queries against the Portainer API) to the underlying Docker/Kubernetes API. API documentation is available here Examples The following examples use httpie to execute API calls against Portainer Initialize the admin password On a fresh install of Portainer, you need to create an admin account to initialize Portainer. You will be asked for this when you visit the Portainer url for the very first time. You can acheive the same using the below http POST <portainer url>/api/users/admin/init Username = \"<admin username>\" Password = \"<adminpassword>\" Authenticate against the API using the admin account http POST <portainer url>/api/auth Username = \"<admin username>\" Password = \"<adminpassword>\" The response is a JSON object containing the JWT token inside the jwt field: { \"jwt\" : \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" } You need to retrieve this token. You will need to pass this token inside the Authorization header when executing an authentication query against the API. The value of the Authorization header must be of the form Bearer . Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE Note : This token has a 8 hour validity, you'll need to generate another token to execute authenticated queries once this one expires. Create a new endpoint Here, We'll show how to create 3 different types of endpoints: Local endpoint using Docker socket communication Remote endpoint using TCP communication Remote endpoint using TCP communication secured via TLS Local endpoint via the Docker socket This query will create an endpoint called test-local and will use the Docker socket to communicate with this environment. Note : This example requires to you bind-mount the Docker socket when running Portainer. http --form POST <portainer url/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"<endpoint name>\" EndpointCreationType = 1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 2 , \"Name\" : \"<endpoint name>\" , \"PublicURL\" : \"\" , \"Type\" : 1 , \"TLSConfig\" : { \"TLS\" : false , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"unix:///var/run/docker.sock\" } Remote endpoint This query will create an endpoint called test-remote and will communicate with this environment over TCP using the IP address 10.0.7.10 and port 2375 (these are example values, ensure that you're using the correct IP & port). Note : The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST <portainer url>/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"test-remote\" URL = \"tcp://10.0.7.10:2375\" EndpointCreationType = 1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 1 , \"Type\" : 1 , \"Name\" : \"test-remote\" , \"PublicURL\" : \"\" , \"TLSConfig\" : { \"TLS\" : false , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"tcp://10.0.7.10:2375\" } Remote endpoint secured using TLS This query will create an endpoint called test-remote-tls and will communicate with this environment over TCP (secured with TLS) using the IP address 10.0.7.10 and port 2376 (these are example values, ensure that you're using the correct IP & port). Note : The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST <portainer url>/api/endpoints \\ \"Authorization: Bearer <jwt token>\" \\ Name = \"test-remote-tls\" URL = \"tcp://10.0.7.10:2376\" EndpointCreationType = 1 TLS = \"true\" TLSCACertFile@/path/to/ca.pem TLSCertFile@/path/to/cert.pem TLSKeyFile@/path/to/key.pem The response is a JSON object representing the endpoint: { \"AuthorizedTeams\" : [], \"AuthorizedUsers\" : [], \"Extensions\" : [], \"GroupId\" : 1 , \"Id\" : 1 , \"Type\" : 1 , \"Name\" : \"test-remote\" , \"PublicURL\" : \"\" , \"TLSConfig\" : { \"TLS\" : true , \"TLSCACert\" : \"/data/tls/1/ca.pem\" , \"TLSCert\" : \"/data/tls/1/cert.pem\" , \"TLSKey\" : \"/data/tls/1/key.pem\" , \"TLSSkipVerify\" : false }, \"Type\" : 1 , \"URL\" : \"tcp://10.0.7.10:2376\" } Execute Docker queries against a specific endpoint By using the following Portainer HTTP API endpoint /api/endpoints/ /docker, you can now execute any of the Docker HTTP API requests. This Portainer HTTP API endpoint acts as a reverse-proxy to the Docker HTTP API. Note : You can refer to the Docker API documentation to get more information on how you can query the Docker engine. List all containers Here is how you can list all the containers available in a specific endpoint: http GET <portainer url>/api/endpoints/1/docker/containers/json \\ \"Authorization: Bearer <jwt token>\" \\ all == true The response is exactly the same as returned by the ContainerList operation of the Docker API, see the documentation for the ContainerList operation . Create a container Here is how you can create a container in a specific endpoint using the Portainer HTTP API as a gateway. This query will create a new Docker container inside the endpoint using the ID 1. The container will be named web01, use the nginx:latest Docker image and publish the container port 80 on via the 8080 port on the host. See the link below to retrieve more information on how you can create a container using the Docker HTTP API. http POST <portainer url>/api/endpoints/1/docker/containers/create \\ \"Authorization: Bearer <jwt token>\" \\ name == \"web01\" Image = \"nginx:latest\" \\ ExposedPorts: = '{ \"80/tcp\": {} }' \\ HostConfig: = '{ \"PortBindings\": { \"80/tcp\": [{ \"HostPort\": \"8080\" }] } }' The response is exactly the same as returned by the ContainerCreate operation of the Docker API, see the documentation for the ContainerCreate operation . Example response: { \"Id\" : \"5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107\" , \"Warnings\" : null } Retrieve the ID of the container, you will need it to execute actions against that container. Start a container You can now start the container that you previously created using the endpoint /api/endpoints/ /docker/containers/ /start (ensure you retrieved the ID of the container created previsouly): http POST <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107/start \\ \"Authorization: Bearer <jwt token>\" The response is exactly the same as returned by the ContainerStart operation of the Docker API, see the documentation for the ContainerStart operation . Delete a container You can create a container using the following endpoint /api/endpoints/ /docker/containers/ : http DELETE <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107 \\ \"Authorization: <jwt token>\" \\ force == true The response is exactly the same as returned by the ContainerDelete operation of the Docker API, see the documentation for the ContainerDelete operation . More Examples to be added soon Notes Contribute to these docs","title":"Examples"},{"location":"api/api-schema/","text":"API Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. You may also use Portainer as a gateway (HTTP queries against the Portainer API) to the underlying Docker/Kubernetes API. API examples are here const ui = SwaggerUIBundle({ url: 'api-2.6.json', dom_id: '#swagger-ui', }) Notes Contribute to these docs","title":"Documentation"},{"location":"archive/1.23.2/","text":"Portainer documentation The Portainer documentation has been moved and is now available at https://www.portainer.io/documentation/","title":"Index"},{"location":"archive/1.23.2/API/","text":"API Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. Documentation The API documentation is available on Swaggerhub and you can also find some examples here .","title":"API"},{"location":"archive/1.23.2/agent/","text":"Agent Purpose The Portainer Agent is a workaround for a Docker API limitation when using the Docker API to manage a Docker environment. The user interactions with specific resources (containers, networks, volumes and images) are limited to those available on the node targeted by the Docker API request. Docker Swarm mode introduces a concept which is the clustering of Docker nodes. It also adds services, tasks, configs and secrets which are cluster-aware resources. Cluster-aware means that you can query for a list of services or inspect a task inside any node on the cluster, as long as you\u2019re executing the Docker API request on a manager node. Containers, networks, volumes and images are node specific resources, not cluster-aware. When you, for example, want to list all the volumes available on a node inside your cluster, you will need to send a query to that specific node. The purpose of the agent aims to allow previously node specific resources to be cluster-aware. All while keeping the Docker API request format. As aforementioned, this means that you only need to execute one Docker API request to retrieve all these resources from every node inside the cluster. In all bringing a better Docker user experience when managing Swarm clusters. Deployment Instructions on how to deploy the Agent and how to connect it to Portainer. Deploy it as a stack Have a look at the deployment documentation Inside a Swarm cluster to quickly deploy the agent and a Portainer instance inside a Swarm cluster via docker stack deploy . Manual deployment Overall, the setup consists of the following steps: Step 1: Create a new overlay network in your Swarm cluster for the Agent. Step 2: Deploy the Agent as a global service in your cluster (connected to the overlay network). Step 3: Connect your Portainer instance to any of the agents by using the Agent's IP:PORT as an endpoint. Note : This setup assumes that you are executing the following instructions on a Swarm manager node. Step 1 , creating a new overlay network in your Swarm cluster: $ docker network create --driver overlay --attachable portainer_agent_network Step 2 , deploying the Agent as a global service in your cluster: $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --mode global \\ --constraint 'node.platform.os == linux' \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Step 3 , deploying the Portainer instance as a service: $ docker service create \\ --name portainer \\ --network portainer_agent_network \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ portainer/portainer -H \"tcp://tasks.portainer_agent:9001\" --tlsskipverify Step 4 , deploying the Agent for all Windows Server nodes Because of Docker limitation you need to deploy the Agent to all Windows Server nodes by running following command on each of them. $ docker run -d --name portainer_agent --restart always --network portainer_agent_network -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mount type=npipe,source=\\\\.\\pipe\\docker_engine,target=\\\\.\\pipe\\docker_engine portainer/agent:windows1803-amd64 Note : If you're using Windows server 1803, you might need to open up DNS ports to support the DNS resolution of tasks.portainer_agent. See: https://success.docker.com/article/swarm-internal-dns-is-inaccessible-on-windows-server-1803 Connecting an existing Portainer instance to an agent If you want to connect an existing Portainer instance to an agent, you can choose the Agent environment type when creating a new endpoint. Ensure when deploying the agent, that you expose the Agent's port inside your Swarm cluster, and that the mode is set to host (default port is 9001): $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --publish mode=host,target=9001,published=9001 \\ --mode global \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Note : Please be aware that this could potentially open up the Agent for use by anybody in case the Docker host is reachable from the internet. Publishing the Agent port 9001 in host mode basically means opening up this port in the Docker hosts firewall for all interfaces. Therefore it is highly recommended to use the AGENT_SECRET environment variable to define a shared secret, see Shared secret. The Agent implements the Trust On First Use (TOFU) principle, so only the first Portainer to connect will be able to use it, but you want to avoid an attacker beating you to it. You can then use the address of any node in your cluster (with the agent port) inside the Agent URL field. Alternatively, you can deploy the agent using the following stack: version: '3.2' services: agent: image: portainer/agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true Note : In case you are running only a single Agent cluster in the same Swarm overlay network as your Portainer instance, you can just omit publishing the Agent port 9001. Portainer and the Agents will be able to communicate with each other inside the same overlay network and there is no need for the Agents to be accessible from the outside. Configuration You can use variant agent configurations to achieve different setups or enable specific features. Shared secret By default, the agent will register the first Portainer instance that connects to it and prevent connections from any other instance after that. To bypass this security mechanism, Portainer and the agent can be configured at deployment time to use a shared secret. This configuration allows multiple Portainer instances to connect to the same agent endpoint. The AGENT_SECRET environment variable can be used to define the shared secret. When deploying the agent as a service: $ docker service create \\ --name portainer_agent \\ --network portainer_agent_network \\ --publish mode=host,target=9001,published=9001 \\ -e AGENT_SECRET=mysecrettoken \\ --mode global \\ --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \\ --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \\ portainer/agent Via a stack file: version: '3.2' services: agent: image: portainer/agent environment: AGENT_SECRET: mysecrettoken volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true The AGENT_SECRET must be specified when deploying Portainer as well: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -e AGENT_SECRET=mysecrettoken -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer Enable host management features The following features are disabled by default for security reasons: Ability to manage the filesystem of the host where the agent is running Ability to retrieve hardware information about the host where the agent is running (PCI devices/disks) In order to enable these features, the agent must be configured properly by: Enabling the host management features via the CAP_HOST_MANAGEMENT environment variable Bind-mounting the root of the host in the agent container (must be bind-mounted in /host ) Example when deploying the agent via a stack file: version: '3.2' services: agent: image: portainer/agent environment: CAP_HOST_MANAGEMENT: 1 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true Available options You can change the configuration of the agent by using environment variables. The following environment variables can be tuned: AGENT_PORT: Agent port (default: 9001 ) LOG_LEVEL: Agent log level (default: INFO ) AGENT_CLUSTER_ADDR: Address used by each agent to form a cluster. AGENT_SECRET: Shared secret used to authorize Portainer instances to connect to the agent CAP_HOST_MANAGEMENT: Enable host management features by setting the value to 1 Usage API If you want to use the Portainer API to query containers running on a specific node inside a Swarm cluster and when using the Portainer agent setup, you can specify the X-PortainerAgent-Target header in the HTTP request to target a specific node in the cluster. The value must be set to the name of a specific node that can be retrieved via the NodeName property when querying cluster resources (containers, volumes...).","title":"Agent"},{"location":"archive/1.23.2/configuration/","text":"Configuration Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command: $ htpasswd -nb -B admin | cut -d \":\" -f 2 or if your system does not provide htpasswd you can use a docker container with the command: $ docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"password\" | cut -d \":\" -f 2 To specify the admin password from the command line, start Portainer with the --admin-password flag: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer --admin-password='$2y$05$qFHAlNAH0A.6oCDe1/4W.ueCWC/iTfBMXIHBI97QYfMWlMCJ7N.a6' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: $ echo -n mypassword > /tmp/portainer_password $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer --admin-password-file /tmp/portainer_password This works well with Swarm & Docker secrets too: $ echo -n mypassword | docker secret create portainer-pass - $ docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\ portainer/portainer \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note : This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): $ docker run -d --label owner=acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer -l owner=acme Note that the -l flag can be repeated multiple times to specify multiple labels: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer -l owner=acme -l service=secret Use your own logo You do not like our logo? Want to make Portainer more corporate? Don't worry, you can easily switch for an external logo (it must be exactly 155px by 55px) using the --logo flag: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you'll need to clear any existing templates (default templates) via the HTTP API. There are two ways to specify your own templates: Bind-mount your own templates Using the --template-file flag you can specify the path to your own template file on the file-system. By default, it points to /templates.json on both Linux and Windows hosts. For example, you can mount your own template file inside the container: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/my/templates.json:/templates.json portainer/portainer Or using the --template-file to specify a specific path to the templates file: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/template/folder:/templates portainer/portainer --template-file /templates/templates.json Host your template file Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer --templates http://my-host.my-domain/templates.json For more information about hosting your own template definitions see Templates \\<templates> Use an external endpoint source Portainer gives you the option to define all the endpoints available in the UI from a JSON file. You just need to start Portainer with the --external-endpoints flag and specify the path to the JSON file in the container. Note: when using the external endpoint management, endpoint management will be disabled in the UI. $ docker run -d -p 9000:9000 -p 8000:8000 -v /tmp/endpoints:/endpoints portainer/portainer --external-endpoints /endpoints/endpoints.json For more information about the endpoint definition format see External endpoints \\<external_endpoints> Available flags The following CLI flags are available: --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind , -p : Address and port to serve Portainer (default: :9000 ) --data , -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --external-endpoints : Enable external endpoint management by specifying the path to a JSON endpoint source in a file --hide-label , -l : Hide containers with a specific label in the UI --host , -H : Docker daemon endpoint --logo : URL to a picture to be displayed as a logo in the UI, use Portainer logo if not specified --no-analytics : Disable analytics (default: false ) --no-snapshot : Disable periodic endpoint snapshot (default: false ) --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s , 5m , 1h ... as supported by the time.ParseDuration method (default: 5m ) --ssl : Secure Portainer instance using SSL (default: false ) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt , C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key , C:\\certs\\portainer.key on Windows) --sync-interval : Time interval between two endpoint synchronization requests expressed as a string, e.g. 30s , 5m , 1h ... as supported by the time.ParseDuration method (default: 60s ) --templates , -t : URL to templates (apps) definitions --template-file : Path on disk to templates (apps) definitions (default: /templates.json ) --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem , C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem , C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false ) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001","title":"Configuration"},{"location":"archive/1.23.2/contribute/","text":"Contribute Use the following instructions and guidelines to contribute to the Portainer project. Build Portainer locally Requirements Ensure you have Docker , Node.js >= 6, yarn and Golang (>= 1.11) installed on your system. Build Checkout the project, set up the project inside your $GOPATH and go inside the root directory: $ git clone https://github.com/portainer/portainer.git $ mkdir -p ${GOPATH}/src/github.com/portainer $ ln -s ${PWD}/portainer ${GOPATH}/src/github.com/portainer/portainer $ cd portainer Install dependencies with yarn: $ yarn Build and run the project: $ yarn start Access Portainer at http://localhost:9000 tip The frontend application will be updated when you save your changes to any of the sources (app/**/*.js, assets/css/app.css or index.html). Just refresh the browser. Contribution guidelines Please follow the contribution guidelines on the repository . Contributing to the documentation Checkout the project and go inside the root directory: $ git clone https://github.com/portainer/portainer-docs.git $ cd portainer-docs Update the documentation and trigger a local build: $ docker run --rm -v ${PWD}/docs:/src portainer/docbuilder:latest make html This will create a local folder docs/build/html where you will find the generated static files for the documentation.","title":"Contribute"},{"location":"archive/1.23.2/deployment/","text":"Deployment Portainer is built to run on Docker and is really simple to deploy. Portainer deployment scenarios can be executed on any platform unless specified. Quick start If you are running Linux, deploying Portainer is as simple as: $ docker volume create portainer_data $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer Voil\u00e0, you can now use Portainer by accessing the port 9000 on the server where Portainer is running. Inside a Swarm cluster Before deploying Portainer inside your Swarm cluster, you should ensure that Docker and your Swarm are configured correctly. You can refer to the Troubleshooting section to ensure you have correctly configured your environment. Following the above, you are ready to deploy Portainer inside a Swarm cluster using our recommended agent-enabled deployment. Note : This setup will assume that you're executing the following instructions on a Swarm manager node. $ curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o portainer-agent-stack.yml $ docker stack deploy --compose-file=portainer-agent-stack.yml portainer Have a look at the Agent section to find more details on how to connect an existing Portainer instance to a manually deployed Portainer agent. Persist Portainer data By default, Portainer store its data inside the container in the /data folder on Linux ( C:\\\\data on Windows). You'll need to persist Portainer data to keep your changes after restart/upgrade of the Portainer container. You can use a bind mount on Linux to persist the data on the Docker host folder: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v /path/on/host/data:/data portainer/portainer Windows Docker for Windows 10 supports running both Linux and Windows containers and you need to use a different start command depending on which container type you are using. Windows Server supports only native Windows containers. Note: You must create the folder in which you want the data to be persisted before running the following command. For example, if you want the data to persist in C:ProgramDataPortainer you need to create the Portainer directory within C:ProgramData as it does not exist by default. Example for Linux containers: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v C:\\ProgramData\\Portainer:/data portainer/portainer Example for native Windows containers: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine -v C:\\ProgramData\\Portainer:C:\\data portainer/portainer Docker Swarm service If you deployed Portainer as a Docker Swarm service: $ docker service create \\ --name portainer \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ --mount type=bind,src=//path/on/host/data,dst=/data \\ portainer/portainer Note : The Swarm service example will persist Portainer data in /path/on/host/data for each host in the cluster. If the container is re-scheduled on another node, existing Portainer data might not be available. Persisting data across all nodes of a Swarm cluster is outside the scope of this documentation. Advanced deployment Advanced Portainer deployment scenarios. Declaring the Docker environment to manage upon deployment You can specify the initial environment you want Portainer to manage via the CLI, use the -H flag and the tcp:// protocol to connect to a remote Docker environment: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v portainer_data:/data portainer/portainer -H tcp://<REMOTE_HOST>:<REMOTE_PORT> Ensure you replace REMOTE_HOST and REMOTE_PORT with the address/port of the Docker server you want to manage. You can also bind mount the Docker socket to manage a local Docker environment ( only possible on environments where the Unix socket is available ): $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer -H unix:///var/run/docker.sock If your Docker environment is protected using TLS, you'll need to ensure that you have access to CA, the certificate and the public key used to access your Docker engine. You can upload the required files via the Portainer UI or use the --tlsverify flag on the CLI. Portainer will try to use the following paths to the files specified previously (on Linux, see the configuration section for details about Windows): CA: /certs/ca.pem certificate: /certs/cert.pem public key: /certs/key.pem You must ensure these files are present in the container using a bind mount: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /path/to/certs:/certs -v portainer_data:/data portainer/portainer -H tcp://<DOCKER_HOST>:<DOCKER_PORT> --tlsverify You can also use the --tlscacert , --tlscert and --tlskey flags if you want to change the default path to the CA, certificate and key file respectively: $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer -v /path/to/certs:/certs portainer/portainer -H tcp://<DOCKER_HOST>:<DOCKER_PORT> --tlsverify --tlscacert /certs/myCa.pem --tlscert /certs/myCert.pem --tlskey /certs/myKey.pem $ docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /path/to/certs:/certs -v portainer_data:/data portainer/portainer -H tcp://<DOCKER_HOST>:<DOCKER_PORT> --tlsverify --tlscacert /certs/myCa.pem --tlscert /certs/myCert.pem --tlskey /certs/myKey.pem Secure Portainer using SSL By default, Portainer's web interface and API is exposed over HTTP. This is not secured, it's recommended to enable SSL in a production environment. To do so, you can use the following flags --ssl , --sslcert and --sslkey : $ docker run -d -p 443:9000 -p 8000:8000 --name portainer --restart always -v ~/local-certs:/certs -v portainer_data:/data portainer/portainer --ssl --sslcert /certs/portainer.crt --sslkey /certs/portainer.key You can use the following commands to generate the required files: $ openssl genrsa -out portainer.key 2048 $ openssl ecparam -genkey -name secp384r1 -out portainer.key $ openssl req -new -x509 -sha256 -key portainer.key -out portainer.crt -days 3650 Note that Certbot could be used as well to generate a certificate and a key. However, because Docker has issues with symlinks , if you use Certbot, you will need to pass both the \"live\" and \"archive\" directories as volumes (shown below). docker run -d -p 9000:9000 -p 8000:8000 \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /root/portainer/data:/data \\ -v /etc/letsencrypt/live/<redacted>:/certs/live/<redacted>:ro \\ -v /etc/letsencrypt/archive/<redacted>:/certs/archive/<redacted>:ro \\ --name portainer \\ portainer/portainer:1.13.4 --ssl --sslcert /certs/live/<redacted>/cert.pem --sslkey /certs/live/<redacted>/privkey.pem Deploy Portainer via docker-compose You can use docker-compose to deploy Portainer. Here is an example compose file: version: '2' services: portainer: image: portainer/portainer command: -H unix:///var/run/docker.sock restart: always ports: - 9000:9000 - 8000:8000 volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data volumes: portainer_data: Click here to download the Compose file. Deploy Portainer without Docker Portainer binaries are available on each release page: Portainer releases Download and extract the binary to a location on disk: $ cd /opt $ wget https://github.com/portainer/portainer/releases/download/1.23.2/portainer-1.23.2-linux-amd64.tar.gz $ tar xvpfz portainer-1.23.2-linux-amd64.tar.gz Then just use the portainer binary as you would use CLI flags with Docker. Note : Portainer will try to write its data into the /data folder by default. You must ensure this folder exists first (or change the path it will use via the --data , see below). $ mkdir /data $ cd /opt/portainer $ ./portainer --template-file \"${PWD}/templates.json\" You can use the -p flag to serve Portainer on another port: $ ./portainer -p :8080 You can change the folder used by Portainer to store its data with the --data flag: $ ./portainer --data /opt/portainer-data","title":"Deployment"},{"location":"archive/1.23.2/external_endpoints/","text":"External endpoints External endpoint definitions are written in JSON. It must consist of an array with every endpoint definition consisting of one element. [ { \"Name\": \"my-first-endpoint\", \"URL\": \"tcp://myendpoint.mydomain:2375\" }, { \"Name\": \"my-second-endpoint\", \"URL\": \"tcp://mysecondendpoint.mydomain:2375\", \"TLS\": true, \"TLSSkipVerify\": true, \"TLSCACert\": \"/tmp/ca.pem\", \"TLSCert\": \"/tmp/cert.pem\", \"TLSKey\": \"/tmp/key.pem\" } ] Endpoint definition format An endpoint element must be a valid JSON object. Example: { \"Name\": \"my-secure-endpoint\", \"URL\": \"tcp://myendpoint.mydomain:2375\", \"TLS\": true, \"TLSCACert\": \"/tmp/ca.pem\", \"TLSCert\": \"/tmp/cert.pem\", \"TLSKey\": \"/tmp/key.pem\" } It is composed of multiple fields, some mandatory and some optionals. Name Name of the endpoint. Used to check if an endpoint already exists in the database during a synchronization request. It will also be displayed in the UI. This field is mandatory . URL How to reach the endpoint. Protocol must be specified, only tcp:// and unix:// are supported at the moment. Any definition not using one of these 2 protocols will be skipped. This field is mandatory . TLS Specify this field to true if you need to use TLS to connect to the endpoint. Defaults to false . When applying the true value to this field, Portainer will expect the TLSCACertPath, TLSCertPath and TLSKeyPath fields to be defined too. This field is optional . TLSSkipVerify Specify this field to true if you want to skip server verification. Defaults to false . This field is optional . TLSCACert Path to the CA used to connect to the endpoint. This field is optional . TLSCert Path to the certificate used to connect to the endpoint. This field is optional . TLSKey Path to the key used to connect to the endpoint. This field is optional . Endpoint synchronization When using the --external-endpoints flag, Portainer will read the specified JSON file at startup and automatically create the endpoints. Portainer will then read the file based on the interval defined in --sync-interval (every 60s by default) and will automatically do the following: For each endpoint in the database, it will automatically merge any configuration find in the file using the enpoint name as the comparison key If an endpoint exists in the database but is not present in the file, it will be removed from the database If an endpoint exists in the file but not in the database it will be created in the database When using external endpoint management, endpoint management will via the UI will be disabled to avoid any possible configuration overwrite (the endpoints view is still accessible but will only display the list of endpoints without giving the possibility to create/update endpoints). A simple warning message will be displayed in the endpoints view.","title":"External Endpoints"},{"location":"archive/1.23.2/faq/","text":"FAQ How do I reset my Portainer password? At this stage, you cannot reset your password using Portainer if you have forgotten it. You can however ask another Portainer admin to reset the password for you. There is an open feature request for this functionality which can be tracked on our GitHub repository here. Why are my stacks showing as Limited in Portainer? A Limited stack as the name implies has limited functionality. This includes browsing through to related services from the Stack Details view, or deleting the stack. A stack could show as Limited in Portainer, either because the stack was deployed outside of Portainer (Portainer doesn't have a copy of the Stack file) or because the Portainer database has been lost (the volume it is on isn't persisted and/or highly available). A Total control stack in Portainer brings you added functionality such as editing and updating a stack, duplicating the stack or migrating the stack. If you wish to have a Total control stack , you will need to deploy it within Portainer so that the file is kept in the database & ensure that the database is persisted and/or highly available. Why is my version number not matching the latest version? If you have recently updated your version of Portainer, this is an indication that your browser is holding onto the previous version number of Portainer in it's cache. To properly clear your cache, you will need to go into the browser settings and empty the cache. Note: You can use Ctrl + shift + R on most browsers to load the specific page without cache, however you will need to repeat this on each page of Portainer to load the changes. Can I activate my extension licenses without an internet connection? Currently, it is not possible to activate extensions offline as Portainer runs a license check against our license verification server. There is a feature request open for this offline activation functionality which can be tracked on our GitHub repository here. My licenses/extensions don't activate, what do I do? As stated above, Portainer needs internet access to activate extensions. One way to test is to run a busybox container and see if it can reach the internet via ping or curl. If Portainer can reach the internet then this is not the problem. If you have access to the Portainer data filesystem you can check whether the extension binaries have been downloaded. Navigate to the filesystem in use by Portainer and check the bin directory to make sure the extension has been downloaded. If there is no extensions present, then there is an issue with Portainer downloading the extension. If the extensions are present, then you may have a permissions issue and they may not be able to run. Check to make sure that they are executable. Note: Open Media Vault mounts filesystems & shared volumes with the noexec flag by default, meaning Portainer extensions can't be enabled. To fix this, remove noexec from the OMV_FSTAB_MNTOPS_EXT4 variable. If the filesystem or shared volume is already mounted, modify the variable in the fstab section of /etc/openmediavault/config.xml , otherwise modify the variable in /etc/default/openmediavault . Users have access to an endpoint, but they cannot see anything. Why? By default all resources inside an endpoint are assigned to administrator only for security reasons. To give non-admin users access you can use the access control widget within each resource to assign users ownership, or you can make the resource public to give all users access. Alternatively, when using the Role Based Access Control (RBAC) extension you can assign users and teams a role at the endpoint level. You can read more about the RBAC extension and it's features here. Note: The RBAC extension requires Portainer version 1.21.0 or newer. Portainer lost it's configuration, why? Portainer as a Container: If you have not created a persistent volume for your Portainer container, then Portainer data will be stored inside the Docker container. If the container is then restarted, you will lose all of your data. Portainer as a Service: If you have not created a persistent volume for your Portainer service, then Portainer data will be stored inside the Docker container created by the service. If the service is updated, you may lose your Portainer configuration. See Deployment on how to create a persistent volume. If you have a persistent volume, then the issue may be that Portainer is not constrained to the node where the data is persisted. See the below section for more info . How do I make sure Portainer stays where my data is persisted? Our recommended deployment stack file constrains Portainer to a manager node, when you have multiple managers this will potentially become a problem. Each stack or service update action could move the Portainer container between them, and you may see Portainer appear as a fresh install. The solution is to constrain your Portainer container to the node where your Portainer data is being persisted. Step 1: Following deployment of our stack file you will need to find the hostname of the node where the Portainer volume is being persisted. Within Portainer, navigate to the volumes view and note down the hostname of your Portainer volume. In this example the hostname is owner . Alternatively you can run docker node ls and note down the hostname of the node where your Portainer data is persisted. ![Viewing hostname of Portainer volume] (assets/Viewing-hostname-of-Portainer-volume.png) Step 2: Navigate to the Service details view for your Portainer service & navigate to placement constraints. Step 3: Click the placement constraints button to add a new constraint and fill in node.hostname for the name and the hostname you gathered previously for the value. Step 4. Click the Apply changes button to apply your constraint. Why doesn't Portainer support compose version 3 on a standalone (non-swarm) host? Portainer uses the library Libcompose to deploy stacks on a standalone host, this library has been depreciated by Docker and the repository for it sits unmaintained. You can view this repository here. How do I get the logs from Portainer? You can either get the logs for Portainer from Portainer's own GUI or from the Docker CLI on the command line. Getting Portainer's logs from within Portainer Step 1. Navigate to the Container view and click on the logs button for your Portainer container. Step 2. Click on the copy button to copy the logs of the Portainer container to your clipboard. Getting Portainer's logs from the Docker CLI Step 1. Navigate to the commandline of a Docker manager node/ non-swarm Docker host and enter docker ps -a to list all of the Docker containers. Step 2. Note down the CONTAINER_ID attribute of your Portainer container. Step 3. Enter the following command and the logs of the Portainer container will output to the commandline: docker container logs CONTAINER_ID Published ports in the services view redirect me to , what can I do? If you deployed the recommended agent stack or manage the local endpoint, you will need to set a public IP on your endpoint for published ports to work on services in Portainer. How to set the public IP of an endpoint: Step 1: Go to endpoints view Step 2: Click on your endpoint to see it's details Fill in the Public IP field for your endpoint like below: For an agent endpoint, add the IP of one of the nodes from your cluster For the local endpoint add the IP of the host Clicking on the published port in the Services view should now correctly redirect you to the published port of your service in the browser. External endpoints are not working in the latest Portainer version, is this a bug? We are aware that the --external-endpoint feature is not working in some of the latest versions of Portainer. If you require use of external endpoints, we recommend rolling back to Portainer version 1.21.0 until a fix has been released. Where can I find the source code of the Portainer agent? The Portainer agent is now open source! You can find it's source code here. My host is using SELinux, can I use Portainer ? If you want to manage a local Docker environment with SELinux enabled, you'll need to pass the --privileged flag to the Docker run command when deploying Portainer: $ docker run -d --privileged -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer You can also have a look at this helper: https://github.com/dpw/selinux-dockersock . How can I use Portainer behind a proxy? With Portainer behind a proxy, some features requiring access to the Internet (such as Apps Templates) might be unavailable. When running Portainer as a container, you can set the HTTP_PROXY and HTTPS_PROXY env vars to specify which proxy should be used: : $ docker run -d -p 9000:9000 -p 8000:8000 -e HTTP_PROXY=my.proxy.domain:7777 portainer/portainer For examples on how to configure a reverse proxy to work with Portainer, you can refer to our example repo here. Note: these are in no way production ready, and are intended solely for demonstration purposes. How can I expose the Docker API over TCP so that Portainer can communicate with my environment? Portainer strongly recommend to deploy Portainer using our agent enabled deployment due to the risk involved with exposing the Docker API. If for whatever reason it is not possible to configure Portainer with the Agent, you can configure Portainer to communicate with the Docker API over the network (usually on TCP 2375, 2376 with TLS). Refer to Daemon socket option in the Docker Reference and to Docker Engine on Windows. How can I set up Portainer on Windows Server 2016? This is a great blog post which gives instructions on how to set up Portainer on Windows Server 2016. Note: this is applicable to Windows Server 2016 only. How can I play with Portainer outside of the public demo? You can deploy Portainer as a stack in Play-with-Docker. Exposed ports in the container view redirects me to 0.0.0.0, what can I do? In order for Portainer to be able to redirect you to your Docker host IP address and not the 0.0.0.0 address, you will have to change the configuration of your Docker daemon and add the --ip option. Note: that you will have to restart your Docker daemon for the changes to be taken in effect. Have a look at the Docker documentation for more details. How do I troubleshoot Portainer? Depending on your issue, make sure you first check the Portainer documentation and our user guides to ensure everything is configured correctly. The next thing is to check the logs of Portainer & the Portainer Agent. For instructions on how to do this, refer to the Portainer logs section above. If you cannot see anything wrong with your configuration or anything in the container logs, then the next step is to troubleshoot your environment. Make sure that Docker is running with the command docker version .","title":"FAQ"},{"location":"archive/1.23.2/limitations/","text":"Limitations Information about supported platforms and Docker versions. Docker Portainer is compatible with the following versions of Docker: Docker > 1.9 Portainer has partial support for the following versions of Docker: Docker 1.9 Portainer is not compatible with the following versions of Docker: Docker \\< 1.9 Swarm Portainer is compatible with the following versions of Docker Swarm standalone: Docker Swarm >= 1.2.3 Note: this is not related to Docker Swarm mode, see https://docs.docker.com/swarm/swarm_at_scale/deploy-app/ Supported platforms Portainer can be deployed on the following platforms: Linux amd64 Linux arm Linux arm64 Linux ppc64le Linux s390x Windows amd64 Darwin amd64","title":"Limitations"},{"location":"archive/1.23.2/templates/","text":"Templates Template definitions are written in JSON. It must consist of an array with every template definition consisting of one element. Container template definition format A template element must be a valid JSON object. Example of a container template: { \"type\": 1, \"title\": \"Nginx\", \"description\": \"High performance web server\", \"logo\": \"https://cloudinovasi.id/assets/img/logos/nginx.png\", \"image\": \"nginx:latest\", \"ports\": [ \"8080:80/tcp\", \"443/tcp\" ] } It is composed of multiple fields, some mandatory and some optionals. type Template type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). NOTE: Type 3 (Compose stack) is limited to using the version: \"2\" stack format, this is a limitation of docker/libcompose. This field is mandatory . title Title of the template. This field is mandatory . description Description of the template. This field is mandatory . image The Docker image associated to the template. The image tag must be included. This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template's logo. This field is optional . registry The registry where the Docker image is stored. If not specified, Portainer will use the Dockerhub as the default registry. This field is optional . command The command to run in the container. If not specified, the container will use the default command specified in its Dockerfile. This field is optional . Example: { \"command\": \"/bin/bash -c \\\"echo hello\\\" && exit 777\" } env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } network A string corresponding to the name of an existing Docker network. Will auto-select the network (if it exists) in the templates view. This field is optional . Example: { \"network\": \"host\" } volumes A JSON array describing the associated volumes of the template. Each element in the array must be a valid JSON object that has a required container property. For each element in the array, a Docker volume will be created and associated when starting the container. If a bind property is defined it will be used as the source of a bind mount. If a readonly property is is defined and true, the volume will be mounted in read-only mode. This field is optional . Example: { \"volumes\": [ { \"container\": \"/etc/nginx\" }, { \"container\": \"/usr/share/nginx/html\", \"bind\": \"/var/www\", \"readonly\": true } ] } ports A JSON array describing the ports exposed by template. Each element in the array must be a valid JSON string specifying the port number in the container and the protocol. It can be optionally prefixed with the port that must be mapped on the host in the port: form. If the host port is not specified, the Docker host will automatically assign one when starting the container. This field is optional . Example: { \"ports\": [\"8080:80/tcp\", \"443/tcp\"] } labels A JSON array describing the labels associated to the template. Each element in the array must be a valid JSON object with two properties name and value . This field is optional . Example: { \"labels\": [ { \"name\": \"com.example.vendor\", \"value\": \"Acme\" }, { \"name\": \"com.example.license\", \"value\": \"GPL\" }, { \"name\": \"com.example.version\", \"value\": \"1.0\" } ] } privileged Should the container be started in privileged mode. Boolean, will default to false if not specified. This field is optional . { \"privileged\": true } interactive Should the container be started in foreground (equivalent of -i -t flags). Boolean, will default to false if not specified. This field is optional . { \"interactive\": true } restart_policy Restart policy associated to the container. Value must be one of the following: no unless-stopped on-failure always This field is optional . Will default to always if not specified. { \"restart_policy\": \"unless-stopped\" } hostname Set the hostname of the container. This field is optional . Will use Docker default if not specified. { \"hostname\": \"mycontainername\" } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to linux or windows . This will display a small platform related icon in the Portainer UI. This field is optional . { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Stack template definition format A template element must be a valid JSON object. Example of a stack template: { \"type\": 2, \"title\": \"CockroachDB\", \"description\": \"CockroachDB cluster\", \"note\": \"Deploys an insecure CockroachDB cluster, please refer to CockroachDB documentation for production deployments.\", \"categories\": [\"database\"], \"platform\": \"linux\", \"logo\": \"https://cloudinovasi.id/assets/img/logos/cockroachdb.png\", \"repository\": { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } } It is composed of multiple fields, some mandatory and some optionals. type Template type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). A Swarm stack will be deployed using the equivalent of docker stack deploy whereas a Compose stack will be deployed using the equivalent of docker-compose . NOTE: Type 3 (Compose stack) is limited to using the version: \"2\" stack format, this is a limitation of docker/libcompose. This field is mandatory . title Title of the template. This field is mandatory . description Description of the template. This field is mandatory . repository A JSON object describing the public git repository from where the stack template will be loaded. It indicates the URL of the git repository as well as the path to the Compose file inside the repository. Element format: { \"url\": \"URL of the public git repository (mandatory)\", \"stackfile\": \"Path to the Compose file inside the repository (mandatory)\", } Example: { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template's logo. This field is optional . env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to linux or windows . This will display a small platform related icon in the Portainer UI. This field is optional . { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Build and host your own templates The simplest way to use your own templates is to bind mount your own template file directly into the Portainer container, see Configuration \\<configuration>. You can also build your own container that will use Nginx to serve the templates definitions. Clone the Portainer templates repository , edit the templates file, build and run the container: {.sourceCode .bash} $ git clone https://github.com/portainer/templates.git portainer-templates $ cd portainer-templates Edit the file templates.json $ docker build -t portainer-templates . $ docker run -d -p \"8080:80\" portainer-templates Now you can access your templates definitions at http://docker-host:8080/templates.json . You can also mount the templates.json file inside the container, so you can edit the file and see live changes: {.sourceCode .bash} $ docker run -d -p \"8080:80\" -v \"${PWD}/templates.json:/usr/share/nginx/html/templates.json\" portainer-templates","title":"Templates"},{"location":"archive/1.23.2/troubleshooting/","text":"Troubleshooting Portainer is built to run on Docker. If Docker is not configured correctly, then this can cause issues that appear to be coming from Portainer. Ensuring Docker is configured correctly The first thing to look at whether Docker is actually functioning correctly on your system. $ docker version The above command should have returned information about Docker running on your system. Below is a snippet of what this may look like. $ Client: Docker Engine - Community Version: 19.03.3 API version: 1.40 Go version: go1.12.10 Git commit: a872fc2f86 Built: Tue Oct 8 00:59:59 2019 OS/Arch: linux/amd64 Experimental: false Ensuring Docker Swarm is configured correctly All nodes will require the following ports to be open: 7946/tcp 7946/udp 4789/udp For the manager node: 2377/tcp Next, make sure you are using the --advertise-addr option. When creating the cluster via docker swarm init , use --advertise-addr with either the private IP address or NIC name directly ( --advertise-addr eth1 for example) When joining a cluster on worker nodes via docker swarm join , use --advertise-addr the same as above with either private IP address or NIC name directly","title":"Troubleshooting"},{"location":"archive/1.23.2/userguide/","text":"User guide WIP","title":"User Guide"},{"location":"contributing/instructions/","text":"Contributing to the Portainer Project How to setup the development environment Note : Make sure you have installed the dependencies for this project on your Mac or Linux machine before continuing this tutorial. Note 2 : Windows is currently not supported by the Portainer development environment. Instructions: Step 1 : Navigate to the folder you wish to store the code for the Portainer project. This can be anywhere such as on your desktop or in your downloads folder. Step 2 : Download the Portainer project: git clone https://github.com/portainer/portainer.git Step 3 : Navigate into the Portainer project you downloaded: cd portainer Step 4 : Install the development dependencies: yarn Step 5 : Build and run the project: yarn start You should now be able to access Portainer at http://localhost:9000 Tip : The frontend application will be updated when you save your changes to any of the sources (app/* / .js, assets/css/app.css or index.html). Just refresh the browser :) Contribution Guidelines Please follow the contribution guidelines on the repository when contributing to the Portainer codebase. Notes Contribute to these docs","title":"Instructions"},{"location":"contributing/tools-linux/","text":"Install required tools on Linux The following instructions were followed to install the required tools on Linux Note : This tutorial was written using Ubuntu 18.04.2 LTS. You can refer to the linked documentation within the dependencies sections for instructions for other systems. Dependencies: Docker CE is the docker application run on your machine to enable use of docker features. The latest version is not a requirement for this development stack, however it is always advised to keep up to date as improvements and security fixes are released frequently. \u200b Yarn is package manager for installing new software packages on your system and is used to run the Portainer dev environment . Node.JS is a JavaScript package used when building applications leveraging networking, such as Portainer. Version 12 or greater is required. Golang is an open-source language, from which we build a majority of the Portainer software. Version 1.15 is required. Wget is a package for retrieving files using common internet protocols such as HTTP and FTP. Docker Note : he below instructions were run on Ubuntu, for up-to-date instructions on this and other Linux flavours refer to the official Docker CE documentation . You must configure the Docker repository before installing Docker. Configure Docker repository Update your system's packages: sudo apt-get update Install required packages to use repos over HTTPS: sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common Install the official GPG key for Docker: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Verify that you now have the key with the fingerprint 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 : sudo apt-key fingerprint 0EBFCD88 Correct output should be: pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 uid [ unknown] Docker Release (CE deb) <docker@docker.com> sub rsa4096 2017-02-22 [S] Use the following command to set up the stable repository: sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" Installing Docker Update your system's packages: sudo apt-get update Install Docker and it's associated packages: sudo apt-get install docker-ce docker-ce-cli containerd.io Verify that Docker was correctly installed and is running on your system: sudo docker run hello-world This command should download a test image, run it in a container and print an informational message then exit. Tip : It is always a good idea to install software based on up-to-date instructions from the offical vendor. This guide was written based on the official Docker help doc for installation on Linux which can be found here . That\u2019s it for Docker! Yarn Note : If you are running a different Linux flavour than Ubuntu, you can refer to the official installation instructions for yarn on Linux here . Installation Instructions: Running the below command in the terminal will configure the yarn repository on your system: curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list Update your system's packages & install yarn: sudo apt-get update && sudo apt-get install yarn Confirm Yarn has successfully installed by running the below command in the terminal yarn --version The current version of yarn should now print out in your terminal . This indicates that yarn is successfully installed and running on your system. Troubleshooting: If you are receiving errors when trying to install or use yarn, you can refer to their official documentation here . Node.JS Note : This tutorial will make use of NVM to install Node.JS (Node.JS version 12 or greater is required). NVM allows install of multiple different versions of Node.JS on a system & provides an easy way to switch between them. You can find the official documentation for NVM here . Installing or Updating Node.JS Install or update Node.JS to the latest version by entering the below command in the terminal: nvm install node Check if Node is installed on your system: node --version The latest version of Node.JS should now print out. Troubleshooting: If you cannot install or update Node.JS, refer to the official NVM documentation here . Golang Note : Go version 1.15 is required. You can refer to offical go documentation here for up to date instructions. If you are upgrading from an older version of Go you must first remove the existing version . Installing GO using a Linux Tar file: Download the appropriate version of go for your system appropriate for your system and navigate to where it was downloaded. Extract it to the /usr/local directory: sudo tar -C /usr/local -xzf go1.15.3.linux-amd64.tar.gz Add /usr/local/go/bin to the PATH environment variable inside your shell profile (example using bash): echo \"export PATH=$PATH:$HOME/go/bin:/usr/local/go/bin\" >> ~/.bashrc Note : You may need to logout and log back in for this to take effect. Verify GO is installed correctly by following the Test your installation section of the offical documentation here . Troubleshooting: If you are having errors trying to install or use GO, you can refer to the Getting help section of the official guide here . Wget Installing Wget on Linux is simple enough. Just run the apt-get install wget command in the terminal. Troubleshooting: If you are having errors trying to install or use Wget, you can refer to the official guide here . Notes Contribute to these docs","title":"Install required tools on Linux"},{"location":"contributing/tools-macos/","text":"Install required tools on MacOS The following instructions were followed to install the required tools on macOS 10.14.3 (Mojave) Dependencies: Docker for Mac installs the Docker application and other Docker tools. The latest version is not a requirement for this development stack, however it is always advised to keep up to date as improvements and security fixes are released frequently. Yarn is package manager for installing new software packages on your system and is used to run the Portainer development environment. Node.JS is a JavaScript package used when building applications leveraging networking, such as Portainer. Version 12 or greater is required. \u200b Golang is an open-source language, from which we build a majority of the Portainer software. Version 1.15 is required. Wget is a package for retrieving files using common internet protocols such as HTTP and FTP. Docker for Mac Note : Docker for Mac requires OSX Mountain Lion or later, otherwise it WILL NOT work. Make sure you check your version before you begin following this guide! Installation Instructions To begin installation Download Docker . Navigate to where the Docker.dmg file downloaded and double click to open. Drag-and-drop Docker into your Applications folder. Next you must authorize the installation with your system password. Wait for Docker to finish installing, and thats it! Optional Steps: It's a good idea to check your Docker installed successfully. Double-click Docker inside your Applications folder to start Docker. The whale icon should appear in your status bar, indicating Docker is running and accessible. Checking the installed Docker version Click on the Docker icon in the status bar and select \"About Docker Desktop\" from the menu. Depending on your Docker version this option may be worded a little different . A Docker window should now pop up displaying the current version of Docker and its supporting software. Tip : It is always a good idea to install software based on up-to-date instructions from the offical vendor. This guide was written based on the official Docker help doc for installation on macOS which can be found here . That\u2019s it for Docker! Yarn Note : This tutorial will makes use of the Homebrew package manager. If you don't have this installed, you can follow the tutorial on the offical website . If you don't want to use Homebrew, you can find alternative tutorials on the offical Yarn website . Installation Instructions: Running brew install yarn in the macOS terminal will install Yarn. Confirm Yarn has successfully installed by running yarn --version command in the macOS terminal. The current version of yarn should now print out in your terminal . This indicates that yarn is successfully installed and running on your system. Troubleshooting: If you are receiving errors when trying to install or use yarn, you can refer to their official documentation here . Node.JS Tip : If you followed the above steps of this tutorial and used Homebrew to install Yarn, Node.JS should have been installed alongside it. Alternatively you can install it following the offical documentation here . To check if Node is installed on your system run node --version in your terminal. The current version of Node.JS should now print out. If you have a version of Node.JS greater than version 6 updating Node.JS is optional, however it is always recommended to check everything is up to date. Updating Node.JS If you are running a version of Node.JS older than version 6 , then you will not be able to run the Portainer development environment and will need to upgrade. You can follow the below instructions to upgrade Node.JS if it was installed using Homebrew. Run brew upgrade node in the macOS terminal to upgrade. Check the version of node to make sure that it has successfully installed by running node --version in your terminal. You should see a version newer than v6 . Troubleshooting: If you are having errors trying to install or upgrade Node.JS using Homebrew, it might be helpful to refer to the official documentation here . Golang Note : Go version 1.15 is required. If you are upgrading from an older version of Go you must first remove the existing version . There are two ways to install Go on a macOS system, using a tar and a package file. This tutorial makes use of the package installer. You can refer to offical go documentation here for up-to-date instructions. Installing GO using the macOS package installer: Download the package file , open it, and follow the prompts to install the Go tools. This package installs the Go distribution to /usr/local/go. The next step is to create a Go Workspace directory: navigate to /Home and create a directory (folder) called go . If you'd like to use a different directory, you will need to set the GOPATH environment variable . Verify GO is installed correctly by following the official documentation here . Wget Installing Wget on macOS is simple when you use Homebrew. Just run the brew install wget command in the terminal. Troubleshooting: If you are having errors trying to install or use Wget, you can refer to the official guide here . Notes Contribute to these docs","title":"Install required tools on Mac OS"},{"location":"v2.0/access/inportainer/","text":"Access Control All docker or docker swarm resources created through Portainer except images have Access Control settings. You can set these at the time of creation or later on as needed. Any resources created through a stack or service will inherit the same access as the parent. Below are examples of different sets of Access Controls you can have. Administrators Only The is an example Create Stack screen, deploys a stack with Access Control Enabled and only Portainer Administrators will have access to the Stack and any Resources created through the stack (eg. Containers/Services/Volumes/Networks/Secrets etc) Public This is an example Create Service Screen, deploys a service with Access Control disabled. All Portainer Users will have access to the service and any resources created through the service (eg. Containers/Volumes/Networks/Secrets etc) Restricted to Specific Groups/Users This is an example Create Container Screen, deploys a Container with Access Control Enabled. Once you select the Restricted option, you may select 'one or more teams' and or 'one or more users' to have access to the Resource. Notes Contribute to these docs","title":"Resources Deployed through Portainer"},{"location":"v2.0/access/outofportainer/","text":"Access Control Any resources deployed to docker or docker swarm outside of Portainer will be marked as external and you will have limited control over these resources. You can still enable Access Control on these using Labels. By default any resources deployed outside of Portainer has Administrator Only access. You can control access using Labels: Label Description Notes io.portainer.accesscontrol.public All portainers users have access to the resource(s) Takes precedence over team/user assignments io.portainer.accesscontrol.teams=dev,prod Access restricted to Teams dev and prod only Can be used in conjunction with io.portainer.accesscontrol.users io.portainer.accesscontrol.users=bob,adam Access restricted to users bob and adam only Can be used in conjunction with io.portainer.accesscontrol.teams Examples Deploy a stack using docker-compose and restrict access to Teams dev and prod version : '3.2' services : ltest : image : busybox:latest command : \"ping localhost\" labels : io.portainer.accesscontrol.teams : dev,prod Deploy a stack using docker cli and restrict access to Team testers and Users bob and adam version : '3.2' services : ltest : image : busybox:latest command : \"ping localhost\" labels : io.portainer.accesscontrol.teams : testers io.portainer.accesscontrol.users : bob,adam Deploy a container using docker cli and make it accessible to all Portainer Users docker run -d --label io.portainer.accesscontrol.public nginx:latest Deploy a container using docker cli and restrict access to Teams dev and prod and Users bob docker run -d --label io.portainer.accesscontrol.teams = dev,prod --label io.portainer.accesscontrol.users = bob nginx:latest Notes Contribute to these docs","title":"Resources Deployed outside of Portainer"},{"location":"v2.0/aci/aci/","text":"Azure Container Instances Portainer CE allows you to deploy and manage apps in Azure Container Instances quickly and easily and like no other tool. There is no need to type commands via CLI or go to the Azure Portal to manage your containers; Portainer does it all. Simply deploy Portainer in an Azure container and manage it like any other node. Portainer CE 2.0 allows you to manage your container nodes, even in the Cloud. Quickly create new containers in Azure Container Instances. Overall view of the containers running in ACIs from a unique instance of Portainer. Define from one page-to-run name, image, resource groups and locations. Have you multiple instances and teams? no problem, define one or more instances to one or more teams and control the usage of the different environments. Adding an ACI Endpoint You can view how to add an ACI Endpoint in our Administrator Guide . Notes Contribute to these docs","title":"About ACI"},{"location":"v2.0/aci/add_container/","text":"Add a Container Instance From Portainer you can add new containers in your Azure Container Instance service. Adding a New Container Instance From Portainer Home, click in your Azure Container Instance endpoint . Click Container Instances and then Add Container . In the next screen, you need to define the container configuration, these options are available: Subscription: If you have two or more subscriptions attached, you can choose where you want to deploy your container. Resource Group: If you have two or more resources groups created, you need to define where you want to deploy your container. Location: Here you need to define in which datacenter you want to run your container. Name: Name your container. Image: Type the name of the image you want to deploy. OS: Select the appropriate OS, usually Linux or Windows. Port Mapping: Choose what port you need to publish to the Internet. CPU: Define how much CPU you want for your container. Memory: Define how much memory you want for your container. When everything is set, click Deploy the Container . Meanwhile the deployment is in progress this message will show in the button. After the deployment has completed, Portainer will exit to the container list and you will see your new container deployed in Azure Container Instances. Notes Contribute to these docs","title":"Add New Container"},{"location":"v2.0/aci/delete_container/","text":"Delete a Container From Portainer, you can delete your containers running in Azure containers instances. Deleting containers Click Container Instances , select the container you want to delete and click Remove . After removing the container, you will see a pop up confirming that action. Notes Contribute to these docs","title":"Delete a Container"},{"location":"v2.0/ad/nginx/rp-nginx/","text":"Deploy Portainer behind NGINX Reverse Proxy Deploying in a Docker Standalone scenario To deploy Portainer behind NGINX Proxy in a Docker standalone scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Server and NGINX Proxy. version: \"2\" services: nginx-proxy: image: jwilder/nginx-proxy restart: always networks: - proxy ports: - \"80:80\" volumes: - \"/var/run/docker.sock:/tmp/docker.sock:ro\" - \"./vhost.d:/etc/nginx/vhost.d:ro\" portainer: image: portainer/portainer-ce:2.0.0 command: -H unix:///var/run/docker.sock restart: always networks: - proxy environment: - VIRTUAL_HOST=portainer.yourdomain.com - VIRTUAL_PORT=9000 ports: - 8000:8000 volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data networks: proxy: volumes: portainer_data: To setup and start working with this recipe, you need to change the VIRTUAL_HOST value. You can then run the following: docker-compose up -d Once complete, you will able to run docker ps and you will see an output similar to this: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088da047e931 portainer/portainer-ce:2.0.0 \"/portainer -H unix:\u2026\" 32 minutes ago Up 22 minutes 0.0.0.0:8000->8000/tcp, 9000/tcp nginx-port_portainer_1 1ec0594f8a01 jwilder/nginx-proxy \"/app/docker-entrypo\u2026\" 32 minutes ago Up 22 minutes 0.0.0.0:80->80/tcp nginx-port_nginx-proxy_1 Once the deployment is complete you can browse portainer.yourdomain.com . Deploying in a Docker Swarm scenario Deploying Portainer in Docker Swarm behind NGINX has similar steps to the Docker Standalone scenario. First, you need to create a few networks. One for the agent and the communication with Portainer Server and other to \"expose\" the Portainer container to the same network that the Reverse Proxy. Before deploying, you need to create 2 elements: Networks and volumes. First, create 2 networks for the agent to communicate with Portainer Server and other to \"expose\" the Portainer container to the same network that as the Reverse Proxy docker network create -d overlay proxy docker network create -d overlay agent_network Then create the volume: docker volume create portainer_data Save the below recipe as portainer.yml version: '3.2' services: nginx-proxy: image: jwilder/nginx-proxy networks: - proxy ports: - \"80:80\" volumes: - \"/var/run/docker.sock:/tmp/docker.sock:ro\" - \"./vhost.d:/etc/nginx/vhost.d:ro\" agent: image: portainer/agent environment: # REQUIRED: Should be equal to the service name prefixed by \"tasks.\" when # deployed inside an overlay network AGENT_CLUSTER_ADDR: tasks.agent # AGENT_PORT: 9001 # LOG_LEVEL: debug volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ce:2.0.0 command: -H tcp://tasks.agent:9001 --tlsskipverify volumes: - data:/data environment: - VIRTUAL_HOST=portainer.yourdomain.com - VIRTUAL_PORT=9000 ports: - 8000:8000 networks: - proxy - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] networks: proxy: external: true agent_network: external: true volumes: data: To setup and start working with this recipe, you need to change the VIRTUAL_HOST value. You're now ready to deploy Portainer by executing the following: docker stack deploy portainer -c portainer.yml To check the deployment you can run docker service ls and you will see an output similar to the following: ID NAME MODE REPLICAS IMAGE PORTS gy2bjxid0g4p portainer_agent global 1/1 portainer/agent:latest jwvjp5bux4sz portainer_nginx-proxy replicated 1/1 jwilder/nginx-proxy:latest *:80->80/tcp 5nflcvoxl3c7 portainer_portainer replicated 1/1 portainer/portainer-ce:2.0.0 *:8000->8000/tcp Once the services are running, you can browse the url specified (e.g. portainer.yourdomain.com) to access Portainer. Deploying in a Kubernetes scenario WIP Notes Contribute to these docs","title":"Nginx"},{"location":"v2.0/ad/traefik/rp-traefik/","text":"Deploy Portainer behind Traefik Proxy Traefik Proxy is a reverse proxy and load balancing solution focused on micro services. Deploying in a Docker Standalone scenario To deploy Portainer behind Traefik Proxy in a Docker standalone scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Traefik with SSL support and Portainer Server. version: \"3.3\" services: traefik: container_name: traefik image: \"traefik:latest\" command: - --entrypoints.web.address=:80 - --entrypoints.websecure.address=:443 - --providers.docker - --log.level=ERROR - --certificatesresolvers.leresolver.acme.httpchallenge=true - --certificatesresolvers.leresolver.acme.email=your-email #Set your email address here, is for the generation of SSL certificates with Let's Encrypt. - --certificatesresolvers.leresolver.acme.storage=./acme.json - --certificatesresolvers.leresolver.acme.httpchallenge.entrypoint=web ports: - \"80:80\" - \"443:443\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./acme.json:/acme.json\" labels: - \"traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)\" - \"traefik.http.routers.http-catchall.entrypoints=web\" - \"traefik.http.routers.http-catchall.middlewares=redirect-to-https\" - \"traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https\" portainer: image: portainer/portainer-ce:2.0.0 command: -H unix:///var/run/docker.sock restart: always volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data labels: # Frontend - \"traefik.enable=true\" - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.frontend.entrypoints=websecure\" - \"traefik.http.services.frontend.loadbalancer.server.port=9000\" - \"traefik.http.routers.frontend.service=frontend\" - \"traefik.http.routers.frontend.tls.certresolver=leresolver\" # Edge - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" - \"traefik.http.routers.edge.entrypoints=websecure\" - \"traefik.http.services.edge.loadbalancer.server.port=8000\" - \"traefik.http.routers.edge.service=edge\" - \"traefik.http.routers.edge.tls.certresolver=leresolver\" volumes: portainer_data: Before you run this file in Docker you will need to create the acme.json file that will store the SSL certificates. Once it has been created you need to define the path of that file in the following sections: In the volume and command section of the Traefik Proxy container - \"./acme.json:/acme.json\" - --certificatesresolvers.leresolver.acme.storage=./acme.json You need to setup your email address for the registration with Let's Encrypt. - --certificatesresolvers.leresolver.acme.email=your-email Next, need to customize some labels in the Traefik container. The following labels need to be modified with the url that you want use to access Portainer. - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" After all this setup, you're ready to deploy Portainer: docker-compose up -d After the images have been downloaded and deployed you will able to access Portainer in the URL you defined earlier. Eg: https://portainer.yourdomain.com This file also exists in our repository on Github . Deploying in a Docker Swarm scenario To deploy Portainer behind Traefik Proxy in a Docker Swarm scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Traefik with SSL support and Portainer Server. Before deploying, you need to create 2 elements: Networks and volumes. First, create 2 overlay networks: docker network create -d overlay agent_network docker network create -d overlay public Then create the volume: docker volume create portainer_data Save the below recipe as portainer.yml version: '3.2' services: traefik: image: \"traefik:latest\" command: - --entrypoints.web.address=:80 - --entrypoints.websecure.address=:443 - --providers.docker=true - --providers.docker.swarmMode=true - --providers.docker.exposedbydefault=false - --providers.docker.network=public - --api - --log.level=ERROR ports: - \"80:80\" - \"443:443\" networks: - public volumes: - \"/var/run/docker.sock:/var/run/docker.sock:ro\" agent: image: portainer/agent environment: # REQUIRED: Should be equal to the service name prefixed by \"tasks.\" when # deployed inside an overlay network AGENT_CLUSTER_ADDR: tasks.agent # AGENT_PORT: 9001 # LOG_LEVEL: debug volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ce:2.0.0 command: -H tcp://tasks.agent:9001 --tlsskipverify volumes: - data:/data networks: - public - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] labels: - \"traefik.enable=true\" - \"traefik.http.routers.portainer.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.portainer.entrypoints=web\" - \"traefik.http.services.portainer.loadbalancer.server.port=9000\" - \"traefik.http.routers.portainer.service=portainer\" # Edge - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" - \"traefik.http.routers.edge.entrypoints=web\" - \"traefik.http.services.edge.loadbalancer.server.port=8000\" - \"traefik.http.routers.edge.service=edge\" networks: public: external: true agent_network: external: true volumes: data: Before you can deploy, you need to customize this labels to match with the URL that you want. - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" You're now ready to deploy Portainer by executing the following: docker stack deploy portainer -c portainer.yml To check the deployment you can run docker service ls and you will see an output similar to the following: ID NAME MODE REPLICAS IMAGE PORTS lt21zrypsll6 portainer_agent global 1/1 portainer/agent:latest m6912ynwdcd7 portainer_portainer replicated 1/1 portainer/portainer-ce:2.0.0 tw2nb4i640e4 portainer_traefik replicated 1/1 traefik:latest *:80->80/tcp, *:443->443/tcp Once the services are running, you can browse the url specified (e.g. portainer.yourdomain.com) to access Portainer. Deploying in a Kubernetes scenario WIP Notes Contribute to these docs","title":"Traefik"},{"location":"v2.0/auth/internal/","text":"Local Authentication When using internal authentication, Portainer will encrypt user passwords and store credentials locally. Notes Contribute to these docs","title":"Internal"},{"location":"v2.0/auth/ldap/","text":"LDAP/AD Authentication Portainer can be configured to accept Lightweight Directory Access Protocol (LDAP) authentication if your organization has implemented LDAP or Active Directory authentication. When users attempt to log into Portainer, the application will authenticate them against your LDAP directory or Active Directory. If authentication is successful, the user is allowed to log into Portainer. In order to configure Portainer LDAP authentication, you first need to add a user to your directory service for the purpose of authenticating from Portainer to read the LDAP. The user should be a service account that needs read-only access to LDAP/Active Directory. Enabling LDAP Log into Portainer as an administrator and navigate to Settings > Authentication. Select the \u2018LDAP Authentication' option. Portainer will then display additional fields for configuring LDAP. Enter in the IP address/FQDN and the port number of your LDAP server, and then select to either connect anonymously (your LDAP server must support this), or enter a user account that has READ access to the directory. Click \"Test Connectivity\" to validate you can connect. Note: For AD use the Reader DN format should be username@MYDOMAIN.com or domain\\userfirstname.userlastname . For OpenLDAP, the Reader DN format should be CN= ,DC=DOMAIN,DC=DOMAIN . You can now configure the remaining LDAP settings: Explanation of Settings Here is an explanation of the above settings: LDAP Security Use StartTLS: After the initial connection, elevate the insecure connection to secure. Use TLS: Initiate a connection to LDAP using TLS. Skip Verification of Certificate: If you do not have access to the certificate of the LDAP server, skipping verification enables encrypted communications, but you must manually ensure that you are talking to the intended LDAP server that you gave in your URL. If that gets maliciously redirected then you could be talking to a different server. Use with caution. TLS CA Certificate: Upload your CA Certificate for the secure connection. Connectivity Check:Validate successful connectivity before continuing. Automatic User Provisioning Automatic User Provisioning: Enabling this setting automatically creates users within Portainer once they are successfully authenticated by LDAP. If you do not enable this, you must manually create users with the same username as the corresponding LDAP directory. User Search Configurations Base DN: Enter DC=MYDOMAIN,DC=com to search your entire Directory for the username attempting to login. or OU= ,DC= ,DC= to search for users only within the specified OU, or CN=NAME,DC= ,DC= if your users are only in a container (in AD, the default is that all users are in a container called users; CN=Users). If you have a large number of users in your Domain, you should narrow the scope Portainer searches by using OU's. Username Attribute: For Native LDAP, Enter uid ; For Active Directory, either enter userPrincipalName if your usernames will be in the format of user@mydomain.com enter SAMAccountName if your usernames will be in the format username . Do not use uid with Active Directory as it will not work. Note: These entries are case sensitive. Filter: Enter a criteria to pre-filter the results returned from LDAP to Portainer. Example, to only allow users who are members of a group, which is a group defined within an OU to login, set the Filter to be: (the brackets are important, so copy the entire string below).. (&(objectClass=user)(memberOf=CN= ,OU= ,DC= ,DC= )) The example below shows that in the domain portainer.local, we have an OU called \"Groups\" and within that OU is a group called \"PortainerDevUsers\". This search filter will only allow users to login to Portainer that are members of the PortainerDevUsers LDAP group. Group Search Portainer optionally allows you to set a Group Search as well as the User Search. If this is configured, if an LDAP user is a member of an LDAP group, and that LDAP Group corresponds to an identically named Portainer TEAM, then the LDAP user will automatically be placed into the Portainer Team based on their LDAP group membership. This is very useful for automatically granting access to Portainer endpoints via group membership. Group Base DN: Enter DC= ,DC= to search your entire Directory for the list of groups. or OU= ,DC= ,DC= to search for groups only within the specified OU, or CN=NAME,DC= ,DC= if your groups are only in a container (in AD, the default is that all groups are in a container called users; CN=Users). If you have a large number of groups in your Domain, you should narrow the scope Portainer searches by using OU's. Group Membership Attribute: Enter \"member\" as the attribute that determines if a user is a member of a group. Group Filter: If you want to filter the list of groups returned, to say, only return groups that contain the string \"Portainer\" (eg PortainerDev, PortainerProd, PortainerUAT\", you can set the filter as follows: (&(objectclass=group)(cn=*Portainer*)) Optional - if you are NOT enabling user Auto Provisioning - Creating LDAP Users Navigate to User Management. Create a username that matches your LDAP source users with the format defined when enabling LDAP (either \u2018username\u2019 or \u2018username@mydomain.com\u2019). Notes Contribute to these docs","title":"LDAP"},{"location":"v2.0/auth/oauth/","text":"OAuth authentication Portainer allows that the authentication can be done with OAuth and with this help article, you will see a overview of what's the requirement to configure Portainer CE with OAuth. Start to configure OAuth authentication in Portainer Once you logged to Portainer, click in Settings and then in authentication . After that, select OAuth option. In this screen, you need to fill in the details using the details provided by your OAuth provider. The fields are: Use SSO: Using SSO, the OAuth provider is not forced to prompt for credentials when the user has a currently logged in session. Automatic User Provisioning: Toggle on the Automatic User Provisioning to see the options. You can use this option if you want a user added to Portainer for each OAuth useron first login. After enabling the toggle, you may choose a team for these Auto Populated Users. Client ID: This is the public identifier of the OAuth application. Client Secret: Here, you need to fill with the token access to the OAuth Application. Authorization URL: URL used to authenticate against the OAuth provider. Will redirect the user to the OAuth provider login view. Access Token URL: URL used to exchange a valid OAuth authentication code for an access token. Resource URL: URL used by Portainer to retrieve information about the authenticated user. Redirect URL: URL used by the OAuth provider to redirect the user after successful authentication. Should be set to your Portainer instance URL. Logout URL: URL used by the OAuth provider to logout the user. User Identifier: Identifier that will be used by Portainer to create an account for the authenticated user. Retrieved from the resource server specified via the Resource URL field. Scopes: Required by the OAuth provider to retrieve information about the authenticated user. Refer to your OAuth provider documentation for more information about this. Once that all fields are completed, do a click in Save Settings Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Examples Take a look at the following examples for configuration OAuth using Azure, Google and Github configuration. The client ID, called application ID in the MSFT world. The tenant ID (grayed information in the screenshot), is a GUID specific for your ID. This is just a custom-defined name for the URL of Portainer. Azure Google Github Keycloak Notes Contribute to these docs","title":"OAuth"},{"location":"v2.0/backup/backup/","text":"Backup Portainer Backup and Restore feature is introduced in Portainer CE Version 2.5 Backup includes all information that Portainer stores on the /data volume, archived in a tar.gz file and optionally encrypted with a provided password. This archive is all you need to restore Portainer. Logged in as an Admin, you will find the Backup option under Settings menu in Portainer. Backup to Local Disk Login as an Admin User into Portainer Click on Settings in the menu Scroll down to Backup Portainer Option Download backup file is the default option, you can toggle the Password protect on and enter a password to encrypt the backup file Click on Download backup A tar.gz file will be downloaded through your browser. Notes Contribute to these docs","title":"Backup"},{"location":"v2.0/backup/restore/","text":"Restore Portainer Backup and Restore feature is introduced in Portainer CE Version 2.5 Restore could be only performed on a fresh instance of Portainer, during its' initialization stage. When you need to restore portainer, deploy a fresh instance of Portainer with an empty data volume and choose the Restore Portainer from backup option on the initialization page of the new instance. Restore from local file On the initialization page, expand Restore Portainer from backup option Click on Select file , browse to and select the tar.gz backup file Enter the password if the backup was originally encrypted Click Restore Portainer Restore may take a few moments. Once complete you will be redirected to the login page. You should now be able to login with your previous credentials. All your Portainer config should be restored. Notes Contribute to these docs","title":"Restore"},{"location":"v2.0/configs/add/","text":"Add configs Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Adding Configs To add configs to Portainer click Configs and then Add config . Then, in the Editor, you need to write your configuration. In this example, you can see an nginx configuration file. Once this config is defined, you can add labels and/or manage access control of this config. When everything is set, click Create config . Notes Contribute to these docs","title":"Add custom configs"},{"location":"v2.0/configs/delete/","text":"Delete Configs From Portainer you can delete the configs that you created before. Deleting Configs To delete a config, go to Configs , select the config you want to delete and click Remove . Notes Contribute to these docs","title":"Delete configs"},{"location":"v2.0/containers/console/","text":"Access to a Container console Adjusting or editing containers can be done through the console. Accesing to container console To access to a specific container console, go to Containers and select the container you want. Then click Console . Select your command and the user you want to allow access for. If you're using an Alpine Linux container, you need to change your command from the list and pick /bin/ash. If successful, you will see the console and you can run commands like any other Linux system. Notes Contribute to these docs","title":"Access container console"},{"location":"v2.0/containers/create/","text":"New Containers Portainer allows you to deploy a new container direct from the UI with no code required. Deploying a New Container First select the Endpoint you want to add a container to, then select Containers from the side menu before clicking Add Container . Add details to your container: Name: Friendly name for your container Registry: Where your image is hosted Image: The name of the image you want to deploy Ports: Expose the desired ports Advanced Settings: Many options available here to customise the deploymeny from volume and environment configuration to capabilities Once complete, click Deploy the Container . If successful your container will be shown in the Container List. Notes Contribute to these docs","title":"Create New Container"},{"location":"v2.0/containers/delete/","text":"Delete/Remove a container In Portainer, you can Remove/Delete containers in simply and easily. Deleting Containers To delete a container, click Containers , then check the container you want delete and select Remove A pop up will ask for confirmation, and ask you decide if you want to automatically the non-persistent volumes . Once you selection has been made, click Remove If successfully removed, a pop up will confirm this. Notes Contribute to these docs","title":"Delete/Remove a Container"},{"location":"v2.0/containers/duplicate-edit/","text":"Duplicate or Edit Containers In Portainer you have the ability to duplicate and / or edit your containers. Duplicate a running container To duplicate a container, click Containers and then select the container you want to duplicate. Click Duplicate/Edit . Change the settings you need, in this example I have changed the name of the container and published a random port, the port exposed by the container by default. When all the changes needed are done, click Deploy the Container If everything worked as expected, you will see your duplicate container in the containers list. Edit a container You can change: * The command & logging options, * volumes, * Networks, * Environment Variables, * Labels, * Restart Policy, * Runtime & Resources and * Capabilites. To change a running container, you need to click Containers , Choose the container you want to change. Click Duplicate/edit . Scrolldown to the bottom of the page and you will see the options to configure to this container. When the changes are made, click Deploy Container . You will see a warning about removing and re-creating the current container with the new settings. If everything works as expected, you will see a pop up confirming the creation of the new container with the new settings and the removal of the old one. Notes Contribute to these docs","title":"Duplicate or Edit a Container"},{"location":"v2.0/containers/inspect/","text":"Inspect a Container Inspecting a container allows you to view information about your container, such as networking settings, volumes, images, etc. Inspecting a Container To inspect a container, click Containers , select your container and click the Inspect button. Here, you can view all the information of this container. Clicking on a category will show more information if available. Notes Contribute to these docs","title":"Inspect a Container"},{"location":"v2.0/containers/logs/","text":"View Containers Logs Viewing container logs is one of the most important features for troubleshooting and investigation. Viewing Containers Logs To view a container logs, click Containers and then select your container. Then click Logs In the following screen, you will see a few options: Auto-refresh logs: Disabling this option allows you to pause the logs collection process and the auto-scrolling. Wrap lines: To allow easier reading of long lines of logs. Display timestamps: this options is useful when you need to find specific time and date logs. Fetch: This option allows you to filter the logs by day, hours or minutes. Search: You can find specific words in the logs, very useful for finding specific errors. Lines: Specify how many lines you want to the see in the logs; default is 100. Actions: You can copy all the logs displayed or a select number of lines. Notes Contribute to these docs","title":"View logs"},{"location":"v2.0/containers/ownership/","text":"Change Container Ownership Portainer allows you to to limit the usage of resources to certains teams or users from the GUI. Changing Container Ownership To change your container ownership, click in Containers , pick the container you want to change the ownership. Scroll down to Access Control section and click Change Ownership . You will see three options: Administrators: This resource is only managed by Portainer Administrators. Restricted: Use this option when you want to restrict this resource to a specific Team or User. Public: Use this options if you want that anyone that had access to the endpoint can manage this container. After you define the ownership, click Update Ownership . You will be presented with a warning: If everything works as expected, you will see a pop up confirming your updates: After that, you can view your ownership settings applied in the container: Notes Contribute to these docs","title":"Change Container Ownership"},{"location":"v2.0/containers/stats/","text":"View Container Stats Stats are very important to understand the resource consumption of yours containers. In Portainer, you are able to monitor this from the UI. Viewing Container Stats First Click Containers , select the container you want to see the stats. Then click Stats Here, you can view a very comprehensive list of consumption stats: Memory Usage CPU Usage Network Usage: RX and TX Process running in the container Refresh Rate: You can configure time intervals to get new stats data. Notes Contribute to these docs","title":"View Container stats"},{"location":"v2.0/deploy/ceinstalldocker/","text":"Deploying Portainer CE in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. If you are using Docker Swarm, please refer to the Swarm-specific installation instructions . Regardless of your configuration, you will need: The latest version of Docker installed and working. You can refer to the Docker documentation for platform-specific instructions. Administrator or sudo access on the machine that will host your Portainer instance. If you are using Docker Desktop on Windows you need to enable WSL2 if you need to run Linux containers. By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Portainer Deployment Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Docker on Linux Portainer Server Deployment docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Docker on Windows WSL / Docker Desktop Before you can deploy Portainer in Docker Standalone running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Portainer Server Deployment docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Docker on Windows Container Service To run Portainer in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands: netsh advfirewall firewall add rule name = \"cluster_management\" dir = in action = allow protocol = TCP localport = 2377 netsh advfirewall firewall add rule name = \"node_communication_tcp\" dir = in action = allow protocol = TCP localport = 7946 netsh advfirewall firewall add rule name = \"node_communication_udp\" dir = in action = allow protocol = UDP localport = 7946 netsh advfirewall firewall add rule name = \"overlay_network\" dir = in action = allow protocol = UDP localport = 4789 netsh advfirewall firewall add rule name = \"swarm_dns_tcp\" dir = in action = allow protocol = TCP localport = 53 netsh advfirewall firewall add rule name = \"swarm_dns_udp\" dir = in action = allow protocol = UDP localport = 53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. Once it has restarted you're ready to deploy Portainer. Portainer Server Deployment docker volume create portainer_data docker run -d -p 9000 :9000 --name portainer --restart always -v \\\\ . \\p ipe \\d ocker_engine: \\\\ . \\p ipe \\d ocker_engine -v portainer_data:C: \\d ata portainer/portainer-ce Now you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Portainer Agent Only Deployment To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v \\\\ . \\p ipe \\d ocker_engine: \\\\ . \\p ipe \\d ocker_engine portainer/agent Advanced Options CLI Configuration Options Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command if you have installed apache2-utils package: htpasswd -nb -B admin \"your-password\" | cut -d \":\" -f 2 If your system does not have the mentioned command, you can run a container to run the command: docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"your-password\" | cut -d \":\" -f 2 To specify the admin password from the command line, start Portainer with the --admin-password flag: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --admin-password = '$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: Add your password to a file, for example with the following command: echo -n mypassword > /tmp/portainer_password Now you can start the Portainer container by running: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ce --admin-password-file /tmp/portainer_password This works well with Docker Swarm and Docker secrets too: echo -n mypassword | docker secret create portainer-pass - docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000 :9000 \\ --publish 8000 :8000 \\ --replicas = 1 \\ --constraint 'node.role == manager' \\ --mount type = bind,src = /var/run/docker.sock,dst = /var/run/docker.sock \\ portainer/portainer-ce \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): docker run -d --label owner = acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme Note that the -l flag can be repeated multiple times to specify multiple labels: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme -l service = secret Use your own logo If you wish to replace our logo with your own, you can specify an external logo (it must be exactly 155px by 55px) using the --logo flag : docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" This can also be updated via the GUI in the Portainer Settings menu. Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you\u2019ll need to clear any existing templates (default templates) via the user interface or the HTTP API. Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --templates http://my-host.my-domain/templates.json The template file must be accessible from Portainer without authentication. We suggest hosting the template files on Github . Available flags The following CLI flags are available: --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind, -p : Address and port to serve Portainer (default: :9000) --data, -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --edge-compute : Automatically enable edge-compute features --hide-label, -l : Hide containers with a specific label in the UI --host, -H : Docker daemon endpoint --logo : URL to an image to be displayed as a logo in the UI. Uses the Portainer logo if not specified --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s, 5m, 1h\u2026 as supported by the time.ParseDuration method (default: 5m) --ssl : Secure Portainer instance using SSL (default: false) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt, C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key, C:\\certs\\portainer.key on Windows) --templates, -t : URL to templates (apps) definitions --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem, C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem, C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001 Notes Contribute to these docs","title":"Docker"},{"location":"v2.0/deploy/ceinstallk8s/","text":"Deploying Portainer CE in Kubernetes Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight containers on Kubernetes. There are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Regardless of your configuration, you will need: A working and up to date Kubernetes cluster Access to run Helm or kubectl commands on your cluster Cluster Admin rights on your Kubernetes cluster. This is so Portainer can create the necessary ServiceAccount and ClusterRoleBinding for it to access the Kubernetes cluster. A default StorageClass configured (see below) By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Access Control & RBAC Kubernetes RBAC needs to enabled and working for Access Control to work properly in Portainer. Portainer Deployment Pre-Req Note: Portainer requires data persistence, and as a result needs at least one storage-class available to use. Portainer will attempt to use the \"default\" storage class during deployment. If you do NOT have a storage class tagged as \"default\" the deployment will likely fail. You can check if you have a default storage class by running: kubectl get sc and looking for a storage class with (default) after its name: kubectl patch storageclass <storage-class-name> -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' and replace with the name of your storage class Example: kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Alternatively, if installing using our Helm chart you can add the following option with helm install: --set persistence.storageClass = <storage-class-name> To deploy Portainer within a Kubernetes cluster, you can either use our HELM chart, or our provided manifests. Deploy using Helm Portainer Server Deployment Ensure you're using at least Helm v3.2, which includes support for the --create-namespace argument. First, add the Portainer helm repo by running the following: helm repo add portainer https://portainer.github.io/k8s/ helm repo update Based on how you would like to expose the Portainer Service, select an option below: NodePort Using the following command, Portainer will be available on port 30777. helm install --create-namespace -n portainer portainer portainer/portainer Ingress Using the following command, the Portainer service will be assigned a Cluster IP. You should use this with an Ingress, see Chart Configuration Options for Ingress related options. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set service.type = ClusterIP Example Deployment with Nginx Ingress helm install --create-namespace -n portainer portainer portainer/portainer \\ --set service.type = ClusterIP \\ --set ingress.enabled = true \\ --set ingress.annotations. 'kubernetes\\.io/ingress\\.class' = nginx \\ --set ingress.hosts [ 0 ] .host = portainer.example.io \\ --set ingress.hosts [ 0 ] .paths [ 0 ] .path = \"/\" LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set service.type = LoadBalancer Chart Configuration Options The following table lists the configurable parameters of the Portainer chart and their default values. The values file can be found under deploy/helm/portainer/values.yaml . The parameters will be keep updating. Parameter Description Default replicaCount Number of Portainer service replicas (ALWAYS set to 1) 1 image.repository Portainer Docker Hub repository portainer/portainer-ce image.tag Tag for the Portainer image latest image.pullPolicy Portainer image pulling policy IfNotPresent imagePullSecrets If Portainer image requires to be in a private repository nil nodeSelector Used to apply a nodeSelector to the deployment {} serviceAccount.annotations Annotations to add to the service account null serviceAccount.name The name of the service account to use portainer-sa-clusteradmin service.type Service Type for the main Portainer Service; ClusterIP, NodePort and LoadBalancer LoadBalancer service.httpPort HTTP port for accessing Portainer Web 9000 service.httpNodePort Static NodePort for accessing Portainer Web. Specify only if the type is NodePort 30777 service.edgePort TCP port for accessing Portainer Edge 8000 service.edgeNodePort Static NodePort for accessing Portainer Edge. Specify only if the type is NodePort 30776 service.annotations Annotations to add to the service {} ingress.enabled Create an ingress for Portainer false ingress.annotations Annotations to add to the ingress. For instane, kubernetes.io/ingress.class: nginx {} ingress.hosts.host URL for Portainer Web. For instance, portainer.example.io nil ingress.hosts.paths.path Path for the Portainer Web. / ingress.hosts.paths.port Port for the Portainer Web. 9000 ingress.tls TLS support on ingress. Must create a secret with TLS certificates in advance [] resources Portainer resource requests and limits {} persistence.enabled Whether to enable data persistence true persistence.existingClaim Name of an existing PVC to use for data persistence nil persistence.size Size of the PVC used for persistence 10Gi persistence.annotations Annotations to apply to PVC used for persistence {} persistence.storageClass StorageClass to apply to PVC used for persistence default persistence.accessMode AccessMode for persistence ReadWriteOnce persistence.selector Selector for persistence nil Portainer Agent Only Deployment Helm chart for Agent Only Deployments will be available soon. In the meantime please head over to YAML Manifests tab. Deploy using YAML Manifests Portainer Server Deployment Based on how you would like expose Portainer Service, Select an option below NodePort Using the following command, Portainer will be available on port 30777. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Portainer Agent Only Deployment Choose one of the tabs below based on how you would like to expose the agent. NodePort Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on port 30778. kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml LoadBalancer Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on LoadBalancer assigned IP @ port 9001 kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-lb.yaml Deploy on Windows WSL / Docker Desktop You can deploy Portainer in a Kubernetes environment in Windows using Docker Desktop. Note This scenario is for testing purpose only. Enable Kubernetes in Docker Desktop To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right click the Docker icon in the system tray and click \"dashboard\" Click Settings: Select Kubernetes 2. Select 'Enable Kubernetes' 3. Click 'Apply and Restart'. After a few minutes, you will see that Kubernetes is running: Portainer Server Deployment Based on how you would like expose the Portainer Service, select an option below: NodePort Using the following command, Portainer will be available on port 30777. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Portainer Agent Only Deployment Choose one of the tabs below based on how you would like to expose the agent: NodePort Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on port 30778. kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml LoadBalancer Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on LoadBalancer assigned IP @ port 9001 kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-lb.yaml Regarding Persisting Data The charts/manifests will create a persistent volume for storing Portainer data, using the default StorageClass. In some Kubernetes clusters (for example microk8s), the default StorageClass simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, \"leaving\" all the persistent data behind and starting the pod with an \"empty\" volume. While this behaviour is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively \"pins\" the Portainer pod to a particular node. The nodeSelector can be added in the following ways: Edit your own values.yaml and set the value of nodeSelector: nodeSelector: kubernetes.io/hostname: \\<YOUR NODE NAME> Explicitly set the target node when deploying/updating the Helm chart on the CLI, by including --set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME> If you've deployed Portainer via manifests, without Helm, run the following one-liner to \"patch\" the deployment, forcing the pod to always be scheduled on the node it's currently running on: kubectl patch deployments -n portainer portainer -p '{\"spec\": {\"template\": {\"spec\": {\"nodeSelector\": {\"kubernetes.io/hostname\": \"'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'\"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1) Notes Contribute to these docs","title":"Kubernetes"},{"location":"v2.0/deploy/ceinstallswarm/","text":"Deploying Portainer CE in Docker Swarm Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Regardless of your configuration, you will need: The latest version of Docker installed and working, with swarm mode enabled and your nodes added. You can refer to the Docker documentation for platform-specific instructions. Administrator or sudo access on the machine that will host the Portainer Server service. Administrator or sudo access on the machines where you will deploy the Portainer Agent if you need to add more endpoints to your Portainer instance. By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Portainer Deployment Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Docker Swarm on Linux Portainer Server Deployment Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Note : By default this stack doesn't enable Host Management Features, you need to enable this from the UI of Portainer. Portainer Agent Only Deployment To deploy Portainer Agent on a remote Linux Swarm Cluster as a Swarm Service, run this command on a manager node in the remote cluster. First create the network: docker network create --driver overlay --attachable portainer_agent_network The following step will deploy the Agent: docker service create --name portainer_agent --network portainer_agent_network --publish mode = host,target = 9001 ,published = 9001 -e AGENT_CLUSTER_ADDR = tasks.portainer_agent --mode global --mount type = bind,src = //var/run/docker.sock,dst = /var/run/docker.sock --mount type = bind,src = //var/lib/docker/volumes,dst = /var/lib/docker/volumes --mount type = bind,src = /,dst = /host portainer/agent Docker Swarm on Windows WSL / Docker Desktop Before you can deploy Portainer in Docker Swarm running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker Swarm commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Portainer Server Deployment Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploys the Portainer Agent as a global service on every node in your cluster. Remember to initiate the Docker Swarm mode when you use Docker Desktop. You can do this by running the following command: docker swarm init The terminal will reply with this: Swarm initialized: current node ( 15gbf4d66mvzk3die00sgirpf ) is now a manager. To add a worker to this swarm, run the <code>swarm join</code> command that is provided when initializing the swarm ( it will look similar to the following ) : docker swarm join --token SWMTKN-1-096qbnf2b9yywagu5ht3731zlpkeqazgctffolntsiljfp0m34-c4snnxplgwq2bd1ohta8k48b9 192 .168.65.3:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. Once this is done, you can continue with the installation by running the following command: curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Portainer Agent Only Deployment First create the network: docker network create --driver overlay --attachable portainer_agent_network To deploy Portainer Agent on a Swarm Cluster as a Swarm Service, run this command in a manager node in the cluster: docker service create --name portainer_agent --network portainer_agent_network --publish mode = host,target = 9001 ,published = 9001 -e AGENT_CLUSTER_ADDR = tasks.portainer_agent --mode global --mount type = bind src = //var/run/docker.sock,dst = /var/run/docker.sock --mount type = bind,src = //var/lib/docker/volumes,dst = /var/lib/docker/volumes \u2013-mount type = bind,src = /,dst = /host portainer/agent Docker Swarm on Windows Container Service To run Portainer in a Windows Server/Desktop Environment, you need to create exceptions in the firewall. These can be easily added through PowerShell by running the following commands: netsh advfirewall firewall add rule name = \"cluster_management\" dir = in action = allow protocol = TCP localport = 2377 netsh advfirewall firewall add rule name = \"node_communication_tcp\" dir = in action = allow protocol = TCP localport = 7946 netsh advfirewall firewall add rule name = \"node_communication_udp\" dir = in action = allow protocol = UDP localport = 7946 netsh advfirewall firewall add rule name = \"overlay_network\" dir = in action = allow protocol = UDP localport = 4789 netsh advfirewall firewall add rule name = \"swarm_dns_tcp\" dir = in action = allow protocol = TCP localport = 53 netsh advfirewall firewall add rule name = \"swarm_dns_udp\" dir = in action = allow protocol = UDP localport = 53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. After it has restarted, you're ready to deploy Portainer. Portainer Server Deployment You can use our YML manifest to run Portainer in Windows using Windows Containers. In Powershell, run: curl https :// downloads . portainer . io / portainer_windows_stack . yml -o portainer_windows_stack . yml docker stack deploy - -compose -file = portainer_windows_stack . yml portainer Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Portainer Agent Only Deployment To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: curl -L https :// downloads . portainer . io / agent-stack-windows . yml -o agent-stack-windows . yml && docker stack deploy - -compose -file = agent-stack-windows . yml portainer-agent Notes Contribute to these docs","title":"Docker Swarm"},{"location":"v2.0/deploy/cli/","text":"CLI Configuration Options Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command if you have installed apache2-utils package: htpasswd -nb -B admin \"your-password\" | cut -d \":\" -f 2 If your system does not have the mentioned command, you can run a container to run the command: docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"your-password\" | cut -d \":\" -f 2 s To specify the admin password from the command line, start Portainer with the --admin-password flag: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --admin-password='$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: Add your password to a file running the following command: echo -n mypassword > /tmp/portainer_password Now you can start the Portainer container by running: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ce --admin-password-file /tmp/portainer_password This works well with Docker Swarm and Docker secrets too: echo -n mypassword | docker secret create portainer-pass - docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\ portainer/portainer-ce \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): docker run -d --label owner=acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner=acme Note that the -l flag can be repeated multiple times to specify multiple labels: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner=acme -l service=secret Use your own logo You do not like our logo? Want to make Portainer more corporate? Don\u2019t worry, you can easily switch for an external logo (it must be exactly 155px by 55px) using the --logo flag : docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" This can also be completed via the GUI in the Portaner Settings menu Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you\u2019ll need to clear any existing templates (default templates) via the HTTP API. Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --templates http://my-host.my-domain/templates.json Suggestion: You can host your template files in Github Available flags The following CLI flags are available: --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind, -p : Address and port to serve Portainer (default: :9000) --data, -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --edge-compute : Automatically enable edge-compute features --hide-label, -l : Hide containers with a specific label in the UI --host, -H : Docker daemon endpoint --logo : URL to a picture to be displayed as a logo in the UI, use Portainer logo if not specified --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s, 5m, 1h\u2026 as supported by the time.ParseDuration method (default: 5m) --ssl : Secure Portainer instance using SSL (default: false) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt, C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key, C:\\certs\\portainer.key on Windows) --templates, -t : URL to templates (apps) definitions --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem, C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem, C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001 Notes Contribute to these docs","title":"CLI Configuration Options"},{"location":"v2.0/deploy/edgeagent/","text":"Edge Agent In standard deployments, the central Portainer instance and any endpoints it manages are assumed to be on the same network, that is, Portainer and the agents are able to seamlessly communicate to one another. However, in environments where the remote endpoints are on a completely separate network to Portainer, say, across the internet, historically, we would have been unable to centrally manage these devices. With the new edge agent, we altered the architecture, so that rather than Portainer needing seamless access the remote endpoint, now, only the remote endpoints need to be able to access Portainer. This is important in Internet connected environments where there is no desire to expose the Portainer agent to the internet. For Edge Agent, Portainer now requires two tcp ports to be exposed; 9000, and 8000. 9000 has historically been the port we served the UI from as well as the Portainer API, but now we have extended the API so that the remote agents can poll for instructions. Port 8000 is a tls tunnel server and is used to create a secure tunnel between the agent and the Portainer instance. When you create an edge agent in Portainer, two things happen. First, you are prompted for the endpoint name (for us humans to use in the UI), and you are asked to confirm the FQDN:PORT of your Portainer instance. Be sure this is correct as its what your agents will use to connect (so make sure dns resolves etc).Second, we also dynamically generate an edge ID, which is a random UUID assigned to each endpoint. You can see this in the command syntax we provide for your convenience. Note the edge ID and the join token are unique per endpoint. Note that the edge join token comprises the following encoded data: The Portainer instance API URL (this is how the edge agent knows how to \"call home\" to your Portainer instance) The Portainer instance reverse tunnel server address (same as the API URL but with the SSH tunnel server port, 8000 is the default) The endpoint identifier key (endpoint ID) The Portainer instance reverse tunnel server fingerprint (used when creating a tunnel to prevent MITM) You now take the convenience command syntax to deploy an edge agent across your remote node or remote swarm cluster. Portainer <--> Agent Communication The agent is configured to POLL the Portainer instance, as defined in the Portainer settings, every 5 seconds (by default); the agent simply says to Portainer \"Hi, i am agent , my join token is , do you need me at the moment\". Portainer checks its internal database to ensure the edge uuid and join token match. If there is no UUID in the Portainer DB associated to the endpoint's provided join token (endpoint is not associated yet - allowed to accommodate pre-staged agent deployments), Portainer will associate the agent provided UUID to the endpoints join token. If the UUID/Join Token combo do not match, the connection is rejected, and if they do match, it responds with either \"No, i dont need you, please check in again in X seconds\" (where x is the agent check-in frequency), or \"Yes, i do need you, please connect to me using these tunnel credentials \" (where XXXXXXXX is an encrypted randomly generated one-time-use username and password). Note: The tunnel credentials are encrypted by Portainer using the edge_UUID as the encryption key. The edge agent, on getting confirmation it needs, immediately decrypts the credentials, and establishes a tunnel on port 8000 to the Portainer instance. Note that where the remote endpoint is a swarm cluster, every node of the cluster is running an instance of the agent, and every instance checks in with Portainer. When the \"required\" flag is raised, the first agent in the cluster to receive this is the agent that establishes the tunnel. Portainer will then be able to query the agent where the tunnel is open. If the tunnel closes for whatever reason (network disruption) then the agent will re-establish it immediately. The agent keeps a record of when Portainer last communicated with it, and after a period of inactivity (5 minutes), the tunnel will close, and the access credentials are retired. Just before closing the tunnel, the agent takes a snapshot of the current configuration and sends this to Portainer to update its snapshot record. Now, what triggers Portainer to require the agent to establish a tunnel? Simple, when an administrator, using the Portainer UI (or API), selects an edge endpoint for interactive management. On clicking, the \"you are required flag\" is raised, and the UI shows a \"connecting to edge endpoint\" whilst waiting for the agent to check in and establish its tunnel. Under default settings, this waiting time would be no longer than 10 seconds (5 seconds potential wait time until next check-in, then a few seconds for tunnel to open). In order to stop premature tunnel termination, whenever an admin has an active session with an edge endpoint, we send \"keep alives\" every 1 minute, even if the admin is not performing a task (because the admin might be in the middle of a task, get distracted, come back to the task, and rightfully, expect to just continue without error). Clearly, having many thousands of endpoints checking in with Portainer every 5 seconds places quite a load on the network, and that is right, 324B/s per agent to be exact (per agent, not per endpoint, so keep this in mind); for this reason, we recommend that if you are infrequently needing to administer your edge endpoints, that you change the check-in period. In the settings of Portainer, you can change this to 5, 10, or 30 seconds. Remember, when changing this, if you do want to perform an admin activity, you will see \"connecting to the edge agent\" for up to 2x the check-in period, so simply drop the time back down before you need to do things. We load tested Portainer with 15,000 actively connected endpoints, with a check-in frequency of 5 seconds. This generated 7Mbps of network traffic to the Portainer instance, and Portainer needed 4 CPUs to handle the encryption / tunnel load. This edge agent release is our first attempt at massive scale centralised management, so we will continue to refine and improve things, with a view to reducing the network overhead of the check-in process. Notes Contribute to these docs","title":"Edge Agent"},{"location":"v2.0/deploy/initial/","text":"Initial Set Up Once Portainer is deployed and you have navigated to http://ip-server:9000, you will see the following screens. Set Password Admin The first thing to do is set a password for the admin user. This password needs to be at least eight characters long. The password can also be set up from the command line or from a configuration file: From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command: $ htpasswd -nb -B admin | cut -d \":\" -f 2 or if your system does not provide htpasswd you can use a docker container with the command: $ docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"password\" | cut -d \":\" -f 2 To specify the admin password from the command line, start Portainer with the --admin-password flag: $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer --admin-password='$2y$05$qFHAlNAH0A.6oCDe1/4W.ueCWC/iTfBMXIHBI97QYfMWlMCJ7N.a6' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: $ echo -n mypassword > /tmp/portainer_password $ docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer --admin-password-file /tmp/portainer_password This works well with Swarm & Docker secrets too: $ echo -n mypassword | docker secret create portainer-pass - $ docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\ portainer/portainer \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Collection of statistics We anonymously collect information about how Portainer is used via a tool called Matomo. You can disable this option, but we recommend leaving it activated. This will help us understand how our users use Portainer and improve it. You can read more about our privacy policy here You can enable or disable this using the checkbox shown: This can be changed at any time via the Portainer Settings screen Connect Portainer to the container environment If you installed Portainer in Kubernetes you would choose Kubernetes, but if you installed in Docker , you may want choose manage the local Docker environment. Once the appropriate option is selected, click connect. If everything works as expected, You will then be shown the Portainer home page. Notes Contribute to these docs","title":"Initial Setup"},{"location":"v2.0/deploy/linux/","text":"Deploy Portainer in Linux environments Deploy Portainer in Kubernetes To deploy Portainer within a Kubernetes cluster, you can either use our HELM chart, or our provided manifests. Pre-Req Note: Portainer requires data persistence, and as a result needs at least one storage-class available to use. Portainer will attempt to use the \"default\" storage class during deployment. If you do NOT have a storage class tagged as \"default\" the deployment will likely fail. You can check if you have a default storage class by running: > kubectl get sc and looking for a storage class with (default) after its name: If you want to make a storage class the default, you can type the command: >kubectl patch storageclass -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' and replace with the name of your storage class (eg: kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Alternatively, if you are using HELM you can use: --set persistence.storageClass= Using Helm Ensure you're using at least helm v3.2, which includes support for the --create-namespace argument. First, add the Portainer helm repo running the following: helm repo add portainer https://portainer.github.io/k8s/ helm repo update For NodePort Using the following command, Portainer will run in the port 30777 helm install --create-namespace -n portainer portainer portainer/portainer For Load Balancer Using the following command, Portainer will run in the port 9000. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set service.type=LoadBalancer For Ingress helm install --create-namespace -n portainer portainer portainer/portainer \\ --set service.type=ClusterIP Using YAML Manifest For NodePort Using the following command, Portainer will run in the port 30777 kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Note about Persisting Data The charts/manifests will create a persistent volume for storing Portainer data, using the default StorageClass. In some Kubernetes clusters (microk8s), the default Storage Class simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, \"leaving\" all the persistent data behind and starting the pod with an \"empty\" volume. While this behaviour is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively \"pins\" the portainer pod to a particular node. The nodeSelector can be added in the following ways: Edit your own values.yaml and set the value of nodeSelector like this: nodeSelector: kubernetes.io/hostname: \\<YOUR NODE NAME> Explicictly set the target node when deploying/updating the helm chart on the CLI, by including --set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME> If you've deployed Portainer via manifests, without Helm, run the following one-liner to \"patch\" the deployment, forcing the pod to always be scheduled on the node it's currently running on: kubectl patch deployments -n portainer portainer -p '{\"spec\": {\"template\": {\"spec\": {\"nodeSelector\": {\"kubernetes.io/hostname\": \"'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'\"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1) Deploy Portainer in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine or within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Note that the recommended deployment mode when using Swarm is using the Portainer Agent. By default, Portainer will expose the UI over the port 9000 and expose a TCP tunnel server over the port 8000. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To see the requirements, please, visit the page of requirements . Docker Standalone Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see Portainer and agent scenario below): docker volume create portainer_data docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Docker Swarm Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Note : By default this stack doesn't enable Host Management Features, you need to enable from the UI of Portainer. Portainer Agent Deployments Only Docker Standalone Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Note: --tlsskipverify has to be present when deploying an agent, since injecting valid, signed certs in the agent is not a supported scenario at present. Docker Swarm Deploy Portainer Agent on a remote LINUX Swarm Cluster as a Swarm Service, run this command on a manager node in the remote cluster. First create the network: docker network create portainer_agent_network The following step is deploy the Agent: docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mode global --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes --mount type=bind,src=/,dst=/host portainer/agent Note: --tlsskipverify has to be present when deploy an agent and the certs in the agent is not a supported scenario at this moment. Notes Contribute to these docs","title":"Deploy Portainer in Linux environments"},{"location":"v2.0/deploy/requirements/","text":"Requirements Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine. By default, Portainer will expose the UI over the port 9000 and expose a TCP tunnel server over the port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. Every single release of Portainer goes through an extensive testing process (functional tests, release tests, post release tests) to ensure that what we are creating actually works as expected. Obviously though, we cannot possibly test Portainer against every single configuration variant out there, so we have elected to test against just a subset. To try and alleviate confusion as to what we test against, we have documented the configurations that we personally validate as \"functional\"; any other variant is not tested (this does not mean it won't work, it just means its not tested). Validated Configurations Portainer Version Release Date Docker Version Kubernetes* Version Architectures Community 2.6.1 (latest) July 12, 2021 20.10.5 / 20.10.6 1.19 1.20.2 1.21 ARM64, x86_64 Community 2.6.0 June 25, 2021 20.10.5 / 20.10.6 1.19 1.20.2 1.21 ARM64, x86_64 Community 2.5.1 May 18, 2021 20.10.5 / 20.10.6 1.19 1.20.2 1.21 ARM64, x86_64 Community 2.5.0 May 18, 2021 20.10.5 1.19 1.20.2 1.21 ARM64, x86_64 Community 2.1.x Feb 2, 2021 20.10.2 1.20.0 ARM64, x86_64 Community 2.0.1 Jan 7, 2021 20.10.0 1.17.13 1.18.9 1.19.3 1.20.0 ARM64, x86_64 Community 2.0 Aug 31, 2020 19.03.12 1.17.13 1.18.6 1.18.9 1.19.3 ARM64, x86_64 1.24.1. July 23, 2020 19.03.12 N/A ARM32, ARM64, x86_64 1.24.0 June 2, 2020 19.03.10 N/A ARM32, ARM64, x86_64 1.23.2 March 25, 2020 19.03.6 N/A ARM32, ARM64, x86_64 *RBAC needs to be enabled on Kubernetes for Portainer Access Control Notes If you report a bug for a configuration that is not on the list above, we will ask you to first update your environment to match a validated configuration before continuing. Business Edition Validated Configurations can be found here Contribute to these docs","title":"Requirements"},{"location":"v2.0/deploy/roles/","text":"Description of Roles Portainer Business come with Role-Based Access Control features that refines the access privileges available natively within Portainer. The RBAC feature allows you to create fine-grained access for users across all resources and all endpoints defined within Portainer. Basics Understanding Role is a predefined set of privileges. Privileges define rights to perform actions. Users are assigned roles and each role has specific privileges. To assign privileges, you pair a user or team with a role and associate that pairing with an endpoint or endpoint group. A single user or team can have different roles for different endpoints in the Portainer inventory. Describing Roles There are four types of roles: Endpoint Administrator: has complete control over the resources deployed within a given endpoint, but is not able to make any changes to the infrastructure that underpins an endpoint (i.e. no host management), nor are they able to make any changes to Portainer internal settings. Helpdesk: has read-only access over the resources deployed within a given endpoint but is not able to make any changes to any resource, nor open a console to a container, or make changes to a container\u2019s volumes. Standard User: has complete control over the resources that a user deploys, or if the user is a member of a team, complete control over the resources that users of that team deploy. Read-Only User: has read-only access over the resources they are entitled to see (resources created by members of their team, and public resources). The Administrator role sits outside of these four roles, and effectively acts as a \u201cGlobal Admin\u201d. A user assigned this role has complete control over Portainer settings, and all resources on every endpoint under Portainer control. Notes Contribute to these docs","title":"Description of Roles"},{"location":"v2.0/deploy/singleinstalldocker/","text":"Deploying Portainer in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine or within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Note that the recommended deployment mode when using Swarm is using the Portainer Agent. By default, Portainer will expose the UI over the port 9000 and expose a TCP tunnel server over the port 8000. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To see the requirements, please, visit the page of requirements . Portainer Deployment Docker on Linux Portainer Server Deployment Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see Portainer and agent scenario below): docker volume create portainer_data Community Edition docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Business Edition docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. Community Edition docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Business Edition docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.0.0 Docker on Windows WSL Before you can deploy Portainer in Docker Standalone running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see portainer and agent scenario below): Portainer Server Deployment docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Docker on Windows Container Service To run Portainer in a Windows Server/Desktop Environment, you need to create exceptions in the firewall. These, can be easy added trough PowerShell, running the following commands: netsh advfirewall firewall add rule name = \"cluster_management\" dir = in action = allow protocol = TCP localport = 2377 netsh advfirewall firewall add rule name = \"node_communication_tcp\" dir = in action = allow protocol = TCP localport = 7946 netsh advfirewall firewall add rule name = \"node_communication_udp\" dir = in action = allow protocol = UDP localport = 7946 netsh advfirewall firewall add rule name = \"overlay_network\" dir = in action = allow protocol = UDP localport = 4789 netsh advfirewall firewall add rule name = \"swarm_dns_tcp\" dir = in action = allow protocol = TCP localport = 53 netsh advfirewall firewall add rule name = \"swarm_dns_udp\" dir = in action = allow protocol = UDP localport = 53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. After it has restarted, you're ready to deploy Portainer. Portainer Server Deployment docker volume create portainer_data docker run -d -p 9000 :9000 --name portainer --restart always -v \\\\ . \\p ipe \\d ocker_engine: \\\\ . \\p ipe \\d ocker_engine -v portainer_data:C: \\d ata portainer/portainer-ce Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Portainer Agent Only Deployment To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v \\\\ . \\p ipe \\d ocker_engine: \\\\ . \\p ipe \\d ocker_engine portainer/agent Advanced Options CLI Configuration Options Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command if you have installed apache2-utils package: htpasswd -nb -B admin \"your-password\" | cut -d \":\" -f 2 If your system does not have the mentioned command, you can run a container to run the command: docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"your-password\" | cut -d \":\" -f 2 To specify the admin password from the command line, start Portainer with the --admin-password flag: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --admin-password = '$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: Add your password to a file running the following command: echo -n mypassword > /tmp/portainer_password Now you can start the Portainer container by running: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ce --admin-password-file /tmp/portainer_password This works well with Docker Swarm and Docker secrets too: echo -n mypassword | docker secret create portainer-pass - docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000 :9000 \\ --publish 8000 :8000 \\ --replicas = 1 \\ --constraint 'node.role == manager' \\ --mount type = bind,src = /var/run/docker.sock,dst = /var/run/docker.sock \\ portainer/portainer-ce \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): docker run -d --label owner = acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme Note that the -l flag can be repeated multiple times to specify multiple labels: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme -l service = secret Use your own logo You do not like our logo? Want to make Portainer more corporate? Don\u2019t worry, you can easily switch for an external logo (it must be exactly 155px by 55px) using the --logo flag : docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" This can also be completed via the GUI in the Portaner Settings menu Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you\u2019ll need to clear any existing templates (default templates) via the HTTP API. Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --templates http://my-host.my-domain/templates.json Suggestion: You can host your template files in Github Available flags The following CLI flags are available: --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind, -p : Address and port to serve Portainer (default: :9000) --data, -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --edge-compute : Automatically enable edge-compute features --hide-label, -l : Hide containers with a specific label in the UI --host, -H : Docker daemon endpoint --logo : URL to a picture to be displayed as a logo in the UI, use Portainer logo if not specified --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s, 5m, 1h\u2026 as supported by the time.ParseDuration method (default: 5m) --ssl : Secure Portainer instance using SSL (default: false) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt, C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key, C:\\certs\\portainer.key on Windows) --templates, -t : URL to templates (apps) definitions --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem, C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem, C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001 Notes Contribute to these docs","title":"Combined Instructions Example"},{"location":"v2.0/deploy/ssl/","text":"Secure Portainer using SSL By default, Portainer\u2019s web interface and API is exposed over HTTP. This is not secure, Portainer recommends enabling SSL, particularly in a production environment. Securing Portainer using SSL with Docker To do so, you can use the following flags --ssl , --sslcert and --sslkey : $ docker run -d -p 443:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v ~/local-certs:/certs -v portainer_data:/data portainer/portainer-ce --ssl --sslcert /certs/portainer.crt --sslkey /certs/portainer.key Note Portainer expects the certificate in PEM format. Now, you can navigate to https://$ip-docker-host Securing Portainer using SSL with Docker Swarm Securing Portainer on Docker Swarm is fairly simple. The following example takes in to asumption that you have an external overlay network and external secrets. If you do not, simply create them: Create the overlay network docker network create --driver overlay portainer Create the secrets docker secret create portainer.example.cer portainer.example.cert docker secret create portainer.example.key portainer.example.key More on Docker Networks: https://docs.docker.com/engine/reference/commandline/network_create/ More on Docker Secrets: https://docs.docker.com/compose/compose-file/#secrets version: '3.2' services: agent: image: portainer/agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - portainer deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ce command: -H tcp://tasks.agent:9001 --tlsskipverify --ssl --sslcert /run/secrets/portainer.example.com.cer --sslkey /run/secrets/portainer.example.com.key ports: - \"9000:9000\" - \"8000:8000\" volumes: - /data/portainer:/data networks: - portainer deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] secrets: - portainer.example.com.cer - portainer.example.com.key networks: portainer: external: true secrets: portainer.example.com.cer: external: true portainer.example.com.key: external: true Notes Contribute to these docs","title":"Using SSL with Portainer"},{"location":"v2.0/deploy/windows10/","text":"Deploy Portainer in Windows 10 Deploy Portainer in Kubernetes through Docker Desktop. You can deploy Portainer in a Kubernetes environment in Windows using Docker Desktop. Note: This scenario is for testing purpose only. Enable Kubernetes in Docker Desktop To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right click the Docker icon in the system tray and click \"dashboard\" Click Settings: Select Kubernetes 2. Select 'Enable Kubernetes' 3. Click 'Apply and Restart'. After a few minutes, you will see that Kubernetes is running: Deploy Portainer using YAML Manifest First create the Portainer namespace in your cluster kubectl create namespace portainer For NodePort kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml If everything work as expected, you can navigate to Portainer from the browser with the address http://localhost:30777 For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Deploy Portainer in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine or within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Note that the recommended deployment mode when using Swarm is using the Portainer Agent. Please see the requirements page for further info . Docker Standalone in WSL2 Before you can deploy Portainer in Docker Standalone running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see portainer and agent scenario below): docker volume create portainer_data docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce Docker Swarm in WSL2 Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploys the Portainer Agent as a global service on every node in your cluster. Remember to initiate the Docker Swarm mode when you use Docker Desktop. You can do this running the following command: docker swarm init The terminal will reply with this: Swarm initialized: current node (15gbf4d66mvzk3die00sgirpf) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-096qbnf2b9yywagu5ht3731zlpkeqazgctffolntsiljfp0m34-c4snnxplgwq2bd1ohta8k48b9 192.168.65.3:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. Once this is done, you can continue with the installation running the following command: curl -L https://downloads.portainer.io/portainer-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Docker Standalone using Windows Containers Another scenario is running Docker in Windows is running Windows Containers. This is a feature that has to be enabled. To do this, open a PowerShell window as administrator and run: Enable-WindowsOptionalFeature -Online -FeatureName containers -All Once this is done, you need to open a PowerShell console and run the following commands: docker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine -v portainer_data:C:\\data portainer/portainer-ce Now, you can navigate to http://localhost:9000 and start using Portainer. Docker Swarm using Windows Containers You can use our YML manifest to run Portainer in Windows using Windows Containers. In a Powershell windows, you must run: curl https://downloads.portainer.io/portainer_windows_stack.yml -o portainer_windows_stack.yml docker stack deploy --compose-file=portainer_windows_stack.yml portainer Deploy Portainer Agent in Windows running WSL Docker Standalone Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Docker Swarm Deploy Portainer Agent on a remote LINUX Swarm Cluster as a Swarm Service, run this command in a manager node in the remote cluster. docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mode global --mount type=bind src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \u2013-mount type=bind,src=/,dst=/host portainer/agent Deploy Portainer Agent in Windows using Windows Containers. Docker standalone To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001:9001 --name portainer_agent --restart=always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine portainer/agent Notes These deployments were tested in Windows 10 Pro 2004 edition. To use Windows Containers, you need to run Windows 10 ver 1803 or newest. Contribute to these docs","title":"Deploy Portainer in Windows 10"},{"location":"v2.0/deploy/windowsserver/","text":"Deploy Portainer in Windows Server To run Portainer in a Windows Server Environment, you need to create exceptions in the firewall. These, can be easy added trough PowerShell, running the following commands: netsh advfirewall firewall add rule name=\"cluster_management\" dir=in action=allow protocol=TCP localport=2377 netsh advfirewall firewall add rule name=\"node_communication_tcp\" dir=in action=allow protocol=TCP localport=7946 netsh advfirewall firewall add rule name=\"node_communication_udp\" dir=in action=allow protocol=UDP localport=7946 netsh advfirewall firewall add rule name=\"overlay_network\" dir=in action=allow protocol=UDP localport=4789 netsh advfirewall firewall add rule name=\"swarm_dns_tcp\" dir=in action=allow protocol=TCP localport=53 netsh advfirewall firewall add rule name=\"swarm_dns_udp\" dir=in action=allow protocol=UDP localport=53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. After it has restarted, you're ready to deploy Portainer. Deploy Portainer Docker Standalone docker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine -v portainer_data:C:\\data portainer/portainer-ce Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Docker Swarm using Windows Containers You can use our YML manifest to run Portainer in Windows using Windows Containers. In Powershell, run: curl https://downloads.portainer.io/portainer_windows_stack.yml -o portainer_windows_stack.yml docker stack deploy --compose-file=portainer_windows_stack.yml portainer Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Deploy Portainer Agent Only Docker standalone To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001:9001 --name portainer_agent --restart=always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine portainer/agent Docker Swarm curl -L https://downloads.portainer.io/agent-stack-windows.yml -o agent-stack-windows.yml && docker stack deploy --compose-file=agent-stack-windows.yml portainer-agent Then you just connect to one IP of the remote cluster on port 9001. Notes These deployments were tested in Windows Server 2019 2004 edition. To use Windows Containers, you need to run Windows Server 2019 ver 1803 or newest. Contribute to these docs","title":"Deploy Portainer in Windows Server"},{"location":"v2.0/edge/groups/","text":"Edge Groups Edge Groups allows you to create groups of Edge endpoints based on a manual selection or synamically through tags . This feature is very useful when you manage multiple Edge Endpoints in multiple zones. To create a group, 1. go to Edge Groups and then 2. click Add Edge Group . Enter a Name and then 2. select either Static or Dynamic . Static Select the Endpoints you want to add to that group 4. These should then appear in the table on the right and finally 5. Click Add edge group Dynamic If you choose Dynamic you must choose between two options to match via Tags your Edge endpoints: Partial Match: Associate any endpoint matching at least one of the selected tags. (Each endpoint can have multiple tags). Full Match: Associate any endpoint matching all of the selected tags. Type the tag and endpoints with that tag will appear in the screen. Finally, click Add edge group Notes Contribute to these docs","title":"Managing Edge Groups"},{"location":"v2.0/edge/stacks/","text":"Deploy an Edge Stack This feature allows the deployment of multiple applications to multiple endpoints from a single screen and multiple sources. Edge stacks lets you deploy an app to all selected edge endpoints concurrently, regardless of their current state (online, disconneted, new). Deploying an Edge Stack Select Edge Stacks and then 2. Click Add stack . Next 1. Name your stack and 2. select one or more Edge Groups . In the Build Methond you need to define how to deploy your app from one of these options: Web Editor: You can use our web editor to write or paste a docker-compose file. Upload: Upload a docker-compose.yml file from your computer Repository: Use a git repository where the compose file is. Template: Use an Edge stack template. Once complete, click Deploy stack Notes Contribute to these docs","title":"Add a Stack"},{"location":"v2.0/edge/jobs/add/","text":"Add an Edge Job Adding an Edge Job is an excellent way to schedule jobs in your Edge hosts. This can be used to run any scripts you need, for example, run a backup in a determined period of time. Note : This is a beta feature. Note 2 : Computing features needs to be enabled. Take a look at this section in our admin guide . Adding an Edge Job To add a job, click Edge Jobs and then Add Edge job . Then 1. Name your job and 2. Choose between the following two options: Basic Configuration: Select a date from a calendar Advanced Configuration: Write your own CRON rule. Select if this job is a recurring job and enter the job time. You can then use the web editor to write or paste the script. Select the target endpoints. To create and run the job click Create edge job. Notes Contribute to these docs","title":"Add a Job"},{"location":"v2.0/endpoints/access/","text":"Manage Endpoint Access Portainer can manage endpoint access. Depending on your needs, this can be broad or granular. Teams and/or users can be added to manage an Endpoint. Access tagged as inherited relies on the group access rules. They cannot be removed or modified at the endpoint level but they can be overridden. Access tagged as override are overriding the group access for the related users/teams. Adding a Team or User To Add access to a Team or User click 1. Endpoints 2. Select the desired Endpoint and 3. Click Manage Access . Next select the team you want to give access to one by one. Once the team is selected click Create Access Once added, you will see the User/Team listed in the access section: Notes Contribute to these docs","title":"Managing Endpoints Access"},{"location":"v2.0/endpoints/aci/","text":"Add an Azure Container Instance Endpoint Portainer CE allows you to deploy and manage apps in Azure Container Instances quickly and easily and like no other tool. There is no need to type commands via CLI or go to the Azure Portal to manage your containers; Portainer does it all. Simply deploy Portainer in an Azure container and manage it like any other node. Constraints The following scenarios are not supported * ACI Persistent storage * Private networks Requirements Before connecting to your Azure Subscription, you need to create an Azure AD Application. For more information see the Microsoft Documentation . Adding an ACI Endpoint To add an ACI Endpoint you will need the following information: Name: Choose a name to identify this endpoint. Application ID: This value is from the application you created in Azure. Tenant ID: You can get your tenant ID from Azure Subscription page Authentication ID: This value is from the process of Application creation in Azure. Once you have these values, you can start to add an ACI Endpoint to Azure. Go to Endpoints 2. Click Add Endpoints Select Azure 4. Complete Application and Azure Subscription 5. Click Add Endpoint Is everything works as expected, you will the following pop up Notes Contribute to these docs","title":"Add ACI Endpoint"},{"location":"v2.0/endpoints/api/","text":"Create/Add a new endpoint through Portainer API In this help article, you will learn how to add the following type of endpoints trough our API: Local endpoint using Docker socket communication Remote endpoint using TCP communication Remote endpoint using TCP communication secured via TLS The API documentation is available here . WARNING: This documentation is valid for Portainer >= 1.18.0. NOTE: We're using httpie to execute HTTP queries from the CLI. Once you have deployed portainer (see Deploying Portainer ) you need to initialize your admin user. Initialize the admin password http POST :9000/api/users/admin/init Username=\"admin\" Password=\"adminpassword\" Authenticate against the API using the admin account http POST :9000/api/auth Username=\"admin\" Password=\"adminpassword\" The response is a JSON object containing the JWT token inside the jwt field: { \"jwt\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" } You need to retrieve this token and pass it into the Authorization header when executing an authentication query against the API. The value of the Authorization header must be of the form Bearer JWT_TOKEN . Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE NOTE: This token has an 8 hour validity, you'll need to generate another token to execute authenticated queries once this one expires. Local endpoint via the Docker socket This query will create an endpoint called test-local and will use the Docker socket to communicate with this environment. NOTE: This example requires to you bind-mount the Docker socket when running Portainer. Run the following: http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-local\" EndpointCreationType=1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Name\": \"test-local\", \"PublicURL\": \"\", \"Type\": 1, \"TLSConfig\": { \"TLS\": false, \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"unix:///var/run/docker.sock\" } Retrieve the value of the Id property, it will be used to execute queries against the Docker engine for that endpoint. Remote endpoint This query will create an endpoint called test-remote and will communicate with this environment over TCP using the IP address 10.0.7.10 and port 2375 (these are example values, ensure that you're using the correct IP & port). NOTE: The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-remote\" URL=\"tcp://10.0.7.10:2375\" EndpointCreationType=1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Type\": 1, \"Name\": \"test-remote\", \"PublicURL\": \"\", \"TLSConfig\": { \"TLS\": false, \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"tcp://10.0.7.10:2375\" } Retrieve the value of the Id property, it will be used to execute queries against the Docker engine for that endpoint. Remote endpoint secured using TLS This query will create an endpoint called test-remote-tls and will communicate with this environment over TCP (secured with TLS) using the IP address 10.0.7.10 and port 2376 (these are example values, ensure that you're using the correct IP & port). NOTE: The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-remote\" URL=\"tcp://10.0.7.10:2376\" EndpointCreationType=1 TLS=\"true\" TLSCACertFile@/path/to/ca.pem TLSCertFile@/path/to/cert.pem TLSKeyFile@/path/to/key.pem The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Type\": 1, \"Name\": \"test-remote\", \"PublicURL\": \"\", \"TLSConfig\": { \"TLS\": true, \"TLSCACert\": \"/data/tls/1/ca.pem\", \"TLSCert\": \"/data/tls/1/cert.pem\", \"TLSKey\": \"/data/tls/1/key.pem\", \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"tcp://10.0.7.10:2376\" } Retrieve this ID, it will be used to execute queries against the Docker engine for that endpoint. Notes Contribute to these docs","title":"Add Endpoint through Portainer API"},{"location":"v2.0/endpoints/docker/","text":"Add Docker Endpoint If you want to manage any standalone Docker Host, you must connect to the Docker API directly. To expose the Docker API to admit remote connections, you need to follow these steps . Once this is complete we can connect the Docker API with and without TLS. Connect to Docker Host API without TLS Go to Endpoints 2. Click Add Endpoint . The next step is choose the environment type and select Docker . In the following section (Environment Details), you need to specify the following information: Name: This a descriptive name that will help you to identify this endpoint in the future. Endpoint URL: Is the name or IP address to connect to the Docker Host. Don't forget to specify the port. When you set Docker to use TLS, the default port is 2376 Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. TLS: Enable this option if you need to connect to the Docker endpoint with TLS. Once all this has been specified, you can click Add Endpoint button If successful, you will see a pop up confirming that the Endpoint was added successfully: Connect to Docker Host API with TLS Portainer is able to connect to the Docker Host API using TLS. To use this option, the Docker environment must be protected already. You can find out more information about how to protect a Docker environment with TLS in the Docker documentation To connect directly to a Docker host API TLS: 1. Go to Endpoints and 2. Click in the Add Endpoint . The next step is choose the environment type and select Docker . In the following section (Environment Details), you need to specify the following information: Name: Name: This a descriptive name that will help you to identify this endpoint in the future. Endpoint URL: Is the name or IP address to connect to the Docker Host. Don't forget to specify the port. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. TLS: Enable this option if you need to connect to the Docker endpoint with TLS. TLS CA Certificate: Define your CA Cerficate. TLS Certificate: Define your certificate. TLS Key: Define your certificate key. Once all this has be specified, you can click in the Add Endpoint button. Scroll down to the bottom of the page and click Add Endpoint . Notes Contribute to these docs","title":"Add Docker Endpoint"},{"location":"v2.0/endpoints/edge/","text":"Add Edge Endpoint. The edge agent was created as a way to manage an edge compute environment where devices typically lack the networking capability to run the traditional Portainer agent. Expose port 8000. This scenario only applies when Portainer is running in a Docker or Docker Swarm environment. Portainer communicates with the edge agent over port 8000; through this port the edge agent can poll the Portainer instance, connect to Portainer, see when it is needed & initiate a tunnel or receive config updates. Without port 8000 exposed on Portainer, you cannot access the edge endpoint. If you already have Portainer deployed, you need to redeploy with port 8000 exposed alongside the port used to access Portainer. Using the CLI flag --tunnel-port you are able to set a different port if 8000 is already in use. For more information see CLI options . Recommended Portainer deployment methods. Portainer with TLS: If your Portainer instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. This is the recommended approach. Portainer with self-signed certs: If you are using a self-signed Portainer instance, the edge agent must be deployed with the flag: -e EDGE_INSECURE_POLL=1 . If you do not deploy Portainer with this flag, then the agent will not be able to communicate with Portainer. This option is less secure than TLS. Portainer fallback to HTTP: If Portainer is not configured with either of the above options, it will fallback to using HTTP for the agent polling. This option is no longer recommended, as it is insecure. Deploying Edge agent in Docker Standalone environment. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Standalone in the tabbed Information section and then 2. Copy Command This command needs to be run in the Docker Standalone. Running docker ps should result in something similar to: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b9e27f356de8 portainer/agent \"./agent\" 12 seconds ago Up 12 seconds portainer_edge_agent Next, in the Configuration section, 1. Define the IP address of the node you want to manage 2. Click Update Endpoint . You should then see the following pop up. Deploying Edge agent in Docker Swarm environment. Adding a Docker Swarm environment with Edge Agent is very similar to the scenario with Docker Standalone. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Swarm in the tabbed Information section and then 2. Copy Command Run the command in the Docker Swarm node, expected results should look similar to: cp2v1mqzkjpcroo3ama8wsve1 overall progress: 1 out of 1 tasks okei8p76rf6k: running [==================================================>] verify: Service converged Running docker service ls you should see: ID NAME MODE REPLICAS IMAGE PORTS cp2v1mqzkjpc portainer_edge_agent global 1/1 portainer/agent:latest Next, in the Configuration section, 1. Define the IP address of the node you want to manage 2. Click Update Endpoint . You should then see the following pop up: Deploying Edge agent in Kubernetes environment. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Swarm in the tabbed Information section and then 2. Copy Command . You need to run this command in the Kubernetes host and the expected results is the following: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3190 100 3190 0 0 1249 0 0:00:02 0:00:02 --:--:-- 1248 Downloading agent manifest... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 2070 100 2070 0 0 1582 0 0:00:01 0:00:01 --:--:-- 1582 Creating Portainer namespace... namespace/portainer created Creating agent configuration... configmap/portainer-agent-edge-id created Creating agent secret... secret/portainer-agent-edge-key created Deploying agent... Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply namespace/portainer configured serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin unchanged service/portainer-agent created deployment.apps/portainer-agent created Portainer Edge agent successfully deployed You can validate if the Edge Agent is running in your host executing the following command: kubectl get pods --namespace=portainer After running the command, you can enter the IP address of the host and click in Update Endpoint button. You should then see the following pop up: ||||| SPACE FOR POP UP ||||| Notes Contribute to these docs","title":"Add Edge Endpoint"},{"location":"v2.0/endpoints/groupstags/","text":"Endpoints Groups and Endpoint Tags In Portainer, you will able to set up Groups and Tags to organize your endpoints. For example, you can set up a group for Development, Stage or Production and use the Tags to identify to which department is the resource \"owner\" or where it is located. Add a Endpoint Group Adding an Endpoint Group is very easy in Portainer. Once logged in 1. Click Endpoints and then 2. Groups Next, define the Group: 1 - Name: Define the name of your group. 2 - Description: Add a description to your group. (Optional) 3 - Select the endpoints for that group 4 - You will see the endpoints associated to that group. 5 - Once is defined, do a click in Create The Group. Once groups have been created you should see this: Add Endpoint Tags Use tags to define node or resource metadata. E.g. Add tag \"LA\" for a node located in Los Angeles, you can set a tag to that node to have more visibility when looking for nodes running in Los Angeles. The same concept for department or \"owners\" of those resources. Click Endpoints 2. Select Tags 3. Define Tag names and 4. Click Create Tag . All tags will then be shown in a table: Adding a Tag to an Endpoint To add a Tag to an Endpoint. 1. Go to Endpoints and 2. Select the desired endpoint. Select the desired tag and click Update Endpoint Once complete the Home Page shows the Endpoints and their associated tags. Notes Contribute to these docs","title":"Creating Endpoints Groups and Endpoint Tags"},{"location":"v2.0/endpoints/kubernetes/","text":"Add Kubernetes Endpoint Adding Kubernetes endpoints to Portainer CE 2.0 is very straightforward. As a requirement you need to define if you are going to deploy the Agents for Kubernetes via NodePort or Load Balancer. In this guide, you will see how to deploy in both scenarios. You can view the supported Kubernetes versions in this page . For more information on supported Kubernetes Versions please view the Requirements page. Add Kubernetes Endpoint via NodePort. Deploying the Agent. Once logged into Portainer go to 1. Endpoints 2. Select Agent from Environment Type section. 3. Select Kubernetes via Node Port in the tabbed Information section, 4. Copy the command. Note: It is important to fill the environment details by first running the command in the Kubernetes node. This command is the same each time you want to add a new Kubernetes Endpoint via NodePort: curl -L https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml Once is running in the Kubernetes host, the terminal is going to reply with something like this: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1617 100 1617 0 0 846 0 0:00:01 0:00:01 --:--:-- 845 namespace/portainer created serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin created service/portainer-agent created service/portainer-agent-headless created deployment.apps/portainer-agent created To validate if the Agent is running, you can run the following command: kubectl get pods --namespace=portainer The result of that command should be something like this: NAME READY STATUS RESTARTS AGE portainer-agent-5988b5d966-bvm9m 1/1 Running 0 15m Now, we're ready to move on to the next step. Finishing the configuration. Once the Agent is running in the Kubernetes host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Kubernetes host) and specify the port (30778) if this is needed. This field is required. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metadata section, you can define a group and tags for this endpoint. See the following screenshot for reference. Once everything is set click Add Endpoint . You will then see the final configuration screen (below). In this screen, you can set the following options: Allow users to use external load balancer: Enabling the load balancer feature will allow users to expose an application they deploy over an external IP address assigned by cloud provider. Ingress controller: Adding ingress controllers will allow users to expose an application they deploy over an HTTP route. Enable features using metrics server: Enabling this feature will allow users to use specific features that leverage the metrics server component. Available storage options: Select which storage options will be available for use when deploying applications. Have a look at your storage driver documentation to figure out which access policy to configure and if the volume expansion capability is supported. The options in the sections are: Local-path: In this scenario your applications will be stored in the node. Shared Access Policy: RWO or RWX Volume Expansion: Enable the option to expand the persistent storage of the pods. You can find more information about access modes in the official Kubernetes documentation . See the following screenshot for reference: Once this has all been set, click Save Configuration . Congratulations! Your Kubernetes endpoint was added. Add Kubernetes Endpoint via Load Balancer Deploying the Agent. Once you login to Portainer, you need go to Endpoints and pick in the environment type section, Agent . In the tab below to the information section, you need pick Kubernetes via Load Balancer and copy the command displayed in the page. Note: Is important run the command in the Kubernetes node before to fill the environment details. The command in this scenario is the same of each time you want to add a new Kubernetes Endpoint via Load Balancer to Portainer. The command is the following: curl -L https://downloads.portainer.io/portainer-agent-k8s-lb.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml Once is running in the Kubernetes host, the terminal is going to reply with something like this: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1617 100 1617 0 0 846 0 0:00:01 0:00:01 --:--:-- 845 namespace/portainer created serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin created service/portainer-agent created service/portainer-agent-headless created deployment.apps/portainer-agent created To validate is the Agent is running, you can run the following command: kubectl get pods --namespace=portainer The result of that command should be something like this: NAME READY STATUS RESTARTS AGE svclb-portainer-agent-52xrp 1/1 Running 0 2m26s Now, we're ready to move on to the next step. Finishing the configuration. Once the Agent is running in the Kubernetes host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Kubernetes host) and specify the port (9001) if this is needed. This field is requiered. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metada section, you can define a group and tags for this endpoint. See the following screenshot for reference. When everything is set, you only need to click in Add Endpoint button. If everything work as expected, you will see the last screen for configuration. In this screen, you can set the following options: Allow users to use external load balancer: Enabling the load balancer feature will allow users to expose application they deploy over an external IP address assigned by cloud provider. Ingress controller: Adding ingress controllers will allow users to expose application they deploy over a HTTP route. Enable features using metrics server: Enabling this feature will allow users to use specific features that leverage the metrics server component. Available storage options: Select which storage options will be available for use when deploying applications. Have a look at your storage driver documentation to figure out which access policy to configure and if the volume expansion capability is supported. The options in the sections are: Local-path: In this scenario your applications will be storaged in the node. Shared Access Policy: RWO or RWX Volume Expansion: Enable the option to expand the persistent storage of the pods. You can find more information about access modes in the official Kubernetes documentation . See the following screenshot for reference: Once all is set, you must click in Save Configuration button. Congratulations. You Kubernetes endpoint via Load Balancer was added. Notes Contribute to these docs","title":"Add Kubernetes Endpoint"},{"location":"v2.0/endpoints/local/","text":"Add Local Endpoints You can only add a local endpoint during the creation of the Portainer container. You cannot add a local endpoint after Portainer was deployed. You can view how to install Portainer (including adding a local endpoint) in the following articles: Deploy Portainer in Linux To learn more go to Deploy Portainer in Linux Environments. Deploy Portainer in Windows 10 and Windows Server To learn more go to Deploying on Windows 10 or Deploying on Windows Server . Initial Setup Adding a local endpoint must be done in the initial setup. To learn more see initial setup Notes Contribute to these docs","title":"Add Local Endpoint"},{"location":"v2.0/endpoints/swarm/","text":"Add a Docker Swarm Endpoint Add a Docker Swarm Endpoint is very straighforward in Portainer CE 2.0. Deploy the Agent. Once logged into Portainer, go to Endpoints and select Agent as the Environment Type . In the tabbed section below titled Information , select Docker Swarm and copy the command. Note: It is important run the command in the Docker Swarm host before to fill the environment details. Use this same command each time you want to add a new Docker Swarm endpoint: curl -L https://downloads.portainer.io/agent-stack.yml -o agent-stack.yml && docker stack deploy --compose-file=agent-stack.yml portainer-agent Once running in the Docker Swam host, the terminal will reply with something similar to: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 484 100 484 0 0 249 0 0:00:01 0:00:01 --:--:-- 249 Creating network portainer-agent_portainer_agent Creating service portainer-agent_agent To validate is the Agent is running, you can run the following command: docker service ls The result of that command should be something like this: ID NAME MODE REPLICAS IMAGE PORTS tshb6ee2710s portainer-agent_agent global 1/1 portainer/agent:latest Now, we're ready to move on to the next step. Finishing the configuration Once the Agent is running in the Docker Swarm host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Docker Swarm Host) and specify the port (9001) if this is needed. This field is requiered. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metadata section, you can define a group and tags for this endpoint. See the following screenshot for reference. When everything is set, you can click Add Endpoint . If successful, you will see this pop up at the top right corner. Notes Contribute to these docs","title":"Add Docker Swarm Endpoint"},{"location":"v2.0/images/build/","text":"Build Image Portainer allows you to create/build new images from a friendly UI. You can define your build in three ways: Web Editor: You can use our web editor to build your image. Upload: If you already have a dockerfile, you can upload to Portainer to build that image. URL: If the dockerfile is hosted in Internet, you can download directly to Portainer and build the image. Building an Image using our web editor Go to Images and click Build a new image . In the next screen, you need to define a name for your image and start to write your dockerfile in the editor. Note : You can define multiple names for you image. When you're ready, scrolldown, select the node you going to save the image to and click Build the image When the building process is complete, you need to click in the tab Output and you will see the build history and the result. If everything works as expected, you will see a similar output to this: Notes Contribute to these docs","title":"Build images"},{"location":"v2.0/images/export/","text":"Export Images Portainer allows you to export any Docker image that is stored in any node. This is useful when you need to move a container from a one host to another or simply make backup of the images. Note : Be advised that when you export a container to a tar file, the volumes are not exported with it. You need to save the data from those volumes in a another way. Exporting Images To export images, click Images , select the image you want to export and click Export . You will see a pop up warning you about that the export may take several minutes, this time depends of the size of your image. Click Continue . When the process is ready you will see a pop up at the top right corner and you will see that your image is downloading: Notes Contribute to these docs","title":"Export images"},{"location":"v2.0/images/import/","text":"Import Images Portainer allows you to import the images that you have created in another Portainer instance or in the CLI of Docker and Docker Swarm. Importing Images To import an image using Portainer, go to Images and then click Import . Select your image , select the node where you will save the image and click Upload . Once the images have uploaded, you will see the following pop up: Notes Contribute to these docs","title":"Import images"},{"location":"v2.0/images/pull/","text":"Pull Images You can pull images from any registry already added to Portainer, see how to add new registries to Portainer for more information. This option is currently only available, when you manage Docker and Docker Swarm environments. Pulling Images Pulling in Simple Mode To pull images from Docker Hub or another registry that you have connected before you must do the following: Go to Images and then type the name of the image, select the node that will download the image and click Pull the Image . When the image is sucessfully downloaded, you will see a pop up at the right top corner. Pulling in Advanced Mode Using Advanced Mode you can define a custom registry URL , port and image . This use case is ideal when you run your own private registry. To pull images, go to Images click in Advanced Mode and then, define your registry , port , image , and specify the node where the image is going to be downloaded and click Pull the Image You will see an animation in the button while the imeage is downloading: When the image is sucessful downloaded, you will see a pop up at the right top corner. Notes Contribute to these docs","title":"Pull images"},{"location":"v2.0/kubernetes/applications/create/","text":"Deploy New Applications From Portainer, you can deploy new applications in your Kubernetes cluster without the need to learn complex CLI commands or edit large YML files. In this help article, you will learn how to deploy an App into a Kubernetes cluster using Portainer. Deploying an application Deploying an application in Portainer to Kubernetes is very easy and very customizable depending on your need. To deploy a new application, you need to choose your Kubernetes Cluster, click Applications and then Add Application . After that, you will see a form to complete according to your needs. The options available are: Name: Name of your Container. Image: This is the image you want to use to deploy your container. Namespace/Resource Pool: This is the namespace where your container is going to live. To add a new Namespace/Resource Pool, see this help article . Stack: Portainer can automatically bundle multiple applications inside a stack. Enter a name of a new stack or select an existing stack in the list. Leave empty to use the application name. Environment Variables: Fill the environment that your app needs, this is optional and only depends of the configuration supported by your app. Configurations: If you created configuration files before using Portainer, you can select that configuration in this space. Persisting Data: Define what folder of the container needs to be persisted. Data Access Policy: Here you need to specify how the data will be used across instances. The options are the following: Shared: All the instances of this application will use the same data. Isolated: Every instance of this application will use their own data. Resource Reservations: Define what resources can be used by your application. Deployment: Select how you want to deploy your application inside the cluster. The options are the following: Replicated: Run one or multiple instances of this container. Global: Deploy an instance of this container on each node of the cluster. Auto Scaling: Select this to enable the auto scaling of your application and define how many instances need to scale and under what conditions. Placement rules: Deploy this application on nodes that respect ALL of the following placement rules. Placement rules are based on node labels. Placement Policy: Specify the policy associated to the placement rules. This can be any of two options: Preferred: Schedule this application on nodes that match the rules if possible. Mandatory: Schedule this application ONLY on nodes that match ALL Rules. Publish Application: Select how you want to publish your application. This can be one of two options: Internal: Internal communications inside the cluster only. Cluster: Publish this application via a port on all nodes of the cluster. Publish Ports: Only applicable if you have selected Cluster above. When everything was set up, click Deploy application . Notes Contribute to these docs","title":"Deploy a new application"},{"location":"v2.0/kubernetes/applications/delete/","text":"Delete an Application You can remove/delete applications using the Portainer GUI. Deleting an Application To delete an Application, click Applications , select the Application you want to delete and then click Remove . Notes Contribute to these docs","title":"Delete an Application"},{"location":"v2.0/kubernetes/applications/inspect/","text":"Inspect Application. From Portainer, you can see a lot of details about your application running in a cluster. To access to this information click Applications and then click the application you want to inspect. Application information In the tab Application , you can find the following information: Name: Name of the application. Stack: Name of the stack that this container belongs. Namespace/Resource Pool: In what resouce pool / Namespace this application in running. Application Type. Status: See if the application is running. Creation: Information about who and when the application was created. You can also find specific configuration of this application: Port published: Show what port is published from this container. Auto Scaling: Show if this application has an auto scaling policy defined. Configuration: Here, we can see if the application has a special configuration defined. Data Persistence: Here we can see what directories are persitent. In the Application container section you can see the pod that runs your application, what the image is using, status, node and information about when it was created. Also, you can access the logs or the console of this Pod. Placement In this tab, you will find information what node your application is running in. Events This shows find information about the events related of your container. YML In this section, you can find the YML generated from the deployment of your application using Portainer. This is very useful to create \"backups\" of your configuration. Notes Contribute to these docs","title":"Inspect an Application"},{"location":"v2.0/kubernetes/applications/manifest/","text":"Deploy an App from a manifest In Portainer you can launch new applications using your current manifest in YML for K8s or convert from a docker-compose file format. Note : Portainer uses Kompose to convert your Compose manifest to a Kubernetes compliant manifest. Be wary that not all the Compose format options are supported by Kompose at the moment. Deploying an App from a Kubernetes Manifest. To start, click Applications and then Advanced Deployment . Here you have the option to use a manifest file that is in a git repo or enter the YAML manifest using the web editor. Manifest from git Select the Namespace to deploy the application to, Select Kubernetes or Compose based on the format of your manifest. Select Git Repository , enter the details for your git repo. Toggle on and enter Authentication details if required for the repo. Finally, Click Deploy . If everything works as expected you will see this pop up: Manifest using Web editor In this section, you need to define the Namespace/Resource Pool where your applications are going to be deployed and start to write or paste your Kubernetes Manifest. Once this is done, click Deploy . If everything works as expected you will see this pop up: Notes Contribute to these docs","title":"Deploy from a Kubernetes Manifest"},{"location":"v2.0/kubernetes/cluster/inspect/","text":"Inspect the Cluster From Portainer, you can inspect Kubernetes Clusters. Inspecting the cluster Click Cluster and you will see information about this cluster. Memory Reservation: Memory used and available for this cluster. CPU Reservation: How much CPU reserved is used. Client Satus: View if the components are healthy or they have some any issues. Leader Status: You will see if this node is a Leader or not. At the bottom of the page, you will see information about the nodes that are part of this cluster. Name, Role, CPU, Memory, Version of Kubernetes, IP Address. Inspecting nodes Node When you click in a node, you can inspect it. You will find the following information: Hostname Kubernetes API Por Role Kubelet Version Creation date Status Labels Applications running on this node Events In the events tab, you will see information about the events related to your node. YAML Here you will find the configuration of your node in YAML format. You can copy the content and save it to mantain a backup of the node configuration. Notes Contribute to these docs","title":"Inspect cluster"},{"location":"v2.0/kubernetes/configurations/create/","text":"Create a configuration From Portainer you can create Configurations files outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Creating a configuration To create a configuration, click Configurations and then click Add configuration . In the next screen, you need to define the following: Name: Name your configuration. Namespace/Resource Pool: Where the configuration is going to be saved. Configuration Type: Non-sensitive: This configuration holds non-sensitive information. Sensitive: This configuration holds sensitive information like passwords or certificates In the data section, clicking Advanced Mode allows you to define your configuration in YAML format. If you would prefer not to use advanced mode, you can create entries using the fields below or taking from a file. Once you have set your configuration, click Create configuration Notes Contribute to these docs","title":"Add a configuration"},{"location":"v2.0/kubernetes/configurations/remove/","text":"Delete a configuration From Portainer, you can delete configurations created previously. Deleting a configuration Go to Configurations , select the configuration and then, click Remove . Notes Contribute to these docs","title":"Remove a configuration"},{"location":"v2.0/kubernetes/resource_pools/access/","text":"Manage access to a Namespace/Resource Pool Access Control & RBAC Kubernetres RBAC needs to enabled and working for Access Control to work properly in Portainer. In this help article, you will learn how to manage access to created resource pools. Managing access Click Namespaces/Resource Pools then click Manage Access of the Namespace/Resource Pool you want. Select the user(s) and or team(s) to add and click Create Access . If everything works as expected, you will see this pop up confirming your action. Notes Contribute to these docs","title":"Manage Access"},{"location":"v2.0/kubernetes/resource_pools/create/","text":"From Portainer CE 2.6 on, Resource Pool(s) has been renamed to Namespace(s) to be aligned with Kubernetes lingo. Create a Namespace/Resource Pool The Namespaces/Resource Pools are helpful when multiple teams are using the same cluster and there is potential collision, you can prevent this by using a virtual wall between multiple clusters. In this help article, you will learn how to create a Namespace/Resource Pool using Portainer. Creating a Namespace/Resource Pool Go to Namespaces/Resource Pools and then click Add Namespace/Resource pool . In the next screen, you need to name your resource pool, assign a quota (Optional), set the resource limits of that quota indicating how much memory and CPU is assigned to this Namespace/Resource Pool. When everything is set, click Create resource pool . If everything works as expected, you will see a pop up confirming the creation of this resource pool. Notes Contribute to these docs","title":"Create a Namespace/Resource Pool"},{"location":"v2.0/kubernetes/resource_pools/delete/","text":"Delete/Remove a Namespace/Resource Pool When you have finished your project, you can delete resource pools to free up resources. Removing a Namespace/Resource Pool Click Namespace/Resouce Pools , select the Namespace/Resource pool and click Remove . You need to confirm this action: If everything works as expected, you will see a pop up confirming your action. Notes Contribute to these docs","title":"Delete a Namespace/Resource Pool"},{"location":"v2.0/kubernetes/volumes/inspect/","text":"Inspect a volume In Portainer, you can inspect volumes that you mounted in a Kubernetes Pod. Inspecting a Volume Go to Volumes and then choose the volume you want inspect. In the first view, you will see the following data: Resource pool where this volume was saved Used By: Name of the app that is using the volume Storage: What is the storage Size Created: Information about who and when it was created. After select the volume, you will see three tabs, in the first one, you will information about the volume itself. In the events tab you will see the events related to this volume: And the YAML tab you will see the configuration of this volume in YAML format. From this tab, you can copy and save the content as a backup. Notes Contribute to these docs","title":"Inspect a volume"},{"location":"v2.0/kubernetes/volumes/remove/","text":"Remove a Volume In portainer you can remove volumes, but please note the volume needs to be unattached from any container beforehand. Unattaching a volume from a container To remove the volume that is attached to a container, go to Applications and select the App. Click Edit this application . Scroll down to the section Persisting Data and click the trash basket icon. You will see the volume label with a strikethrough effect. Scroll down anc click Update Application . A warning will pop up. Click Update to confirm. Removing a Volume If your volume is free you can delete it. First click Volumes , select the volume you want delete, and click Remove . You will be asked for confirmation, click Remove to confirm. If everything works as expected, you will see a pop up confirmating this action: Notes Contribute to these docs","title":"Remove a volume"},{"location":"v2.0/kubernetes/volumes/resize/","text":"Increase the volume Using Portainer, you can increase the size of a volume. Note : Is only possible to increase the size of the volume. You cannot reduce the size of a volume. Increasing a volume Go to Volumes and select the volume you want resize. In the tab Volume you will see the current size of your volume. Click Increase size . After that you will able to enter a new size for that volume. Enter the new value and click Update size . You will see a warning if the volume is used by any app at this this time and you will be asked to confirm if you want resize and redeploy the app. Click Redeploy the applications to confirm. If eveything works as expected, you will see a pop up confirming the resize of your volume. Notes Contribute to these docs","title":"Resize a volume"},{"location":"v2.0/networks/add/","text":"Add a Network Portainer allows you to manage networks for your containers environments. You will be able to to create these network types: Bridge: the default network driver. If you don\u2019t specify a driver, this is the type of network you are creating. Bridge networks are usually used when your applications run in standalone containers that need to communicate. Macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host\u2019s network stack. Overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. IPvlan: IPvlan is similar to macvlan with the difference being that the endpoints have the same mac address. ipvlan supports L2 and L3 mode. In ipvlan l2 mode, each endpoint gets the same mac address but different ip address. In ipvlan l3 mode, packets are routed between endpoints, so this gives better scalability. Adding a Network To add a network in Portainer, click Networks and then click Add Network . In the next screen, you need to define the following information: Name: Name your network Driver: Define the type of network that you will use. (See above the description of each driver). IPv4 Network configuration: You can define IP ranges, Subnet, gateway and exclude IP. If this data is not filled, Docker will assign a range automatically. IPv6 Network configuration: You can define IP ranges, Subnet, gateway and exclude IP. If this data is not filled, Docker will assign a range automatically. Labels: Define labels for you network. Restrict External Access to the network: Allows you to isolate the containers inside of that network. Enable manual container attachment: Select the toggle if the users can attach this network to running containers. Deployment: Select the node where this network is going to be created. When everything is set, click Create the Network . Notes Contribute to these docs","title":"Add a Network"},{"location":"v2.0/networks/delete/","text":"Delete a Network Portainer allows you to delete networks. Deleting Networks To delete a network, click Networks , select the network you want to delete, and click Remove . Notes Contribute to these docs","title":"Delete a Network"},{"location":"v2.0/registries/auth-docker-hub/","text":"How to enable Docker Hub authentication In this helpful video, you will learn how to enable Docker Hub authentication in Portainer. Enabling Docker Hub authentication in Portainer Notes Contribute to these docs","title":"Enable Docker Hub Authentication"},{"location":"v2.0/registries/connect/","text":"Add / Connect a new registry Portainer can connect to many of the well known registries including Quay.io, Azure Container Registry, Gitlab Container Registry, and a Custom Registry. Adding a new registry Click Registries and then Add Registry . Select the desired registry and then add your appropriate credentials details. Once complete click Add Registry . How to add a Custom Registry Portainer can connect to custom or 3rd party registries. First select Custom Registry and enter the details there. The required fields are name of the registry and address , if any authentication is required, you must enable the authentication toggle and add your login details. Once all the details are entered, click Add Registry . If successful you will. Notes Contribute to these docs","title":"Connect to a Registry"},{"location":"v2.0/secrets/add/","text":"Add Secrets In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application\u2019s source code. In Docker 1.13 and higher, you can use Docker secrets to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running. You can use secrets to manage any sensitive data which a container needs at runtime but you don\u2019t want to store in the image or in source control, such as: Usernames and passwords TLS certificates and keys SSH keys Other important data such as the name of a database or internal server Generic strings or binary content (up to 500 kb in size) Creating a Secret To create a secret in Portainer, go to Secrets and click Add Secret . In the next screen, you need to set a name for you secret, define the 'secret' , choose if you need to encode that secret, (this is useful when you set a password in plain text) and click Create the secret . Notes Contribute to these docs","title":"Add a new secret"},{"location":"v2.0/secrets/delete/","text":"Delete a Secret It is good practice to delete the secrets that you don't need anymore. Deleting a Secret To delete a secret, go to Secrets , select the secret you want delete and then, click Remove . Notes Contribute to these docs","title":"Delete secrets"},{"location":"v2.0/services/create/","text":"How to Create a new service Services are collections of containers. In this example, ee're going to deploy an NGINX Web Server. Note : This article only covers Docker Swarm environments at present. Creating a new service Click Services from the side menu and then Add Service . Complete the fields: Name: Choose a name for the service Registry & Image: Select where these are located Replicated or Global: Replicated in the same host or deployed Globally with one container in each host Ports: define the ports to expose for that service Further settings are available on this screen, once these have been set appropriately, click Create The Service . If successful, your service will be listed in the table of services. Notes Contribute to these docs","title":"Create a New Service"},{"location":"v2.0/services/logs/","text":"How to view services logs Service logs are incredibly useful for troubleshooting issues and service behaviour. Accessing to Service Logs Click Services and then choose the service you want to view the logs for. Click Service logs . Logs are then displayed with the ability to: Turn off Auto Refresh Wrap Lines Display Timestamps Search or filter logs Increase the number of lines to fetch Copy, Copy Selected or Unselect log lines Notes Contribute to these docs","title":"View Service Logs"},{"location":"v2.0/services/options/","text":"Configure Service Options Before of after you deploy a service, you can configure a wide range of options to your service. In this article, we going to review each option available that you can use from Portainer. To make additions or changes of configuration, you need go to Services and choose the service you want configure. Container Specification Environment Variables The environment variables are useful to set configuration at the same time that the container is created. If you need to add new environment variables after that service was deployed, you can do it. Labels Container labels can be used to leave notes of that container or specify configuration. Mounts You can mount or bind volumes from Portainer. You can also set if that volume needs to set in Read Only . The only thing you need to do is select a created volume, specify the path in container and click Apply Changes . Networks & ports Networks You can define one or more networks for your service; this can even been done after it has been deployed. You only need to create your network and then, select from the dropdown list. Published Ports Here, you can publish ports to access this container from outside the host. You can set new or modify the current ports. Host file entries This is used when you need to manually specify a hostname or url; associat the URL to an internal or external IP Address. Service specification Resource limits and reservations From Portainer, you can set limitations about the resource utilization, like Memory, CPU Reservation, CPU Limit, etc. Placement constraints Use placement constraints to control the nodes a service can be assigned to. Placement preferences While placement constraints limit the nodes a service can run on, placement preferences try to place tasks on appropriate nodes in an algorithmic way (currently, this is only spread evenly). Restart Policy Docker provides restart policies to control whether your containers start automatically when they exit, or when Docker restarts. Restart policies ensure that linked containers are started in the correct order. The options are the following: Any: Restart under any condition (Restarted host or Docker daemon). On Failure: Restart the container if it exits due to an error, which manifests as a non-zero exit code. None: Do not automatically restart the container. You can also adjust Restart Delay, Max Attempts and Restart Window. Update Configuration Updates a service as described by the specified parameters. The parameters are the same as docker service create. Refer to the description there for further information. Normally, updating a service will only cause the service\u2019s tasks to be replaced with new ones if a change to the service requires recreating the tasks for it to take effect. Logging Driver Docker includes multiple logging mechanisms to help you get information from running containers and services. These mechanisms are called logging drivers. Each Docker daemon has a default logging driver, which each container uses unless you configure it to use a different logging driver. Service Labels Add metadata to containers using Docker labels. You can use either an array or a dictionary. It\u2019s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software. Configs Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Secrets In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application\u2019s source code. Notes Contribute to these docs","title":"Configure Service Options"},{"location":"v2.0/services/rollback/","text":"Rollback a Service After make a change to a service in Docker Swarm, you can rollback those changes if your applications are not working as expected. Rollbacking a Service To rollback a service to the last state click Services , choose the service you want to rollback. Then click Rollback the service . You will be asked to confirm this rollback. If successful, a green pop up confirming will show at the top right of screen.","title":"Rollback a Service"},{"location":"v2.0/services/scale/","text":"How to scale a service This is a powerful feature that allows you to scale your services horizontally. Scaling a Service Click Services and then Click scale . Enter the number of replicas you want for this service and click the check box . If successful you will see the green pop up at the top right of screen. Refreshing this page will show you the replicas (3 in this case) running, depending on the size of the containers, you may have a slight delay in seeing this. Notes Contribute to these docs","title":"Scaling a Service"},{"location":"v2.0/services/status/","text":"Service task status Services in a Docker Swarm environment are a collection of tasks (or individuals containers). Portainer allows you to very quickly see the status of the containers are part of a service. Viewing the task of the services Click Services , and then click the dropwdown arrow to the left of the service you want to inspect. This shows the tasks that make up this service. In this example, you can see three running containers that make up the Docker Swarm service. Notes Contribute to these docs","title":"Service Task Status"},{"location":"v2.0/settings/apps/","text":"How to use Templates Template definitions are written in JSON. It must consist of an array with every template definition consisting of one element. Container template definition format A template element must be a valid JSON object. Example of a container template: { \"version\": \"2\", \"templates\": [ { // template1 }, { // template2 }, ... ] } It is composed of multiple fields, some mandatory and some optionals. type Template type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). NOTE: Type 3 (Compose stack) is limited to using the version: \u201c2\u201d stack format, this is a limitation of docker/libcompose. This field is mandatory. type Title of the template. This field is mandatory . description Description of the template. This field is mandatory . image The Docker image associated to the template. The image tag must be included. This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template\u2019s logo. This field is optional . registry The registry where the Docker image is stored. If not specified, Portainer will use the Dockerhub as the default registry. This field is optional . command The command to run in the container. If not specified, the container will use the default command specified in its Dockerfile. This field is optional . Example: { \"command\": \"/bin/bash -c \\\"echo hello\\\" && exit 777\" } env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } network A string corresponding to the name of an existing Docker network. Will auto-select the network (if it exists) in the templates view. This field is optional . Example: { \"network\": \"host\" } volumes A JSON array describing the associated volumes of the template. Each element in the array must be a valid JSON object that has a required container property. For each element in the array, a Docker volume will be created and associated when starting the container. If a bind property is defined it will be used as the source of a bind mount. If a readonly property is is defined and true, the volume will be mounted in read-only mode. This field is optional . Example: { \"volumes\": [ { \"container\": \"/etc/nginx\" }, { \"container\": \"/usr/share/nginx/html\", \"bind\": \"/var/www\", \"readonly\": true } ] } ports A JSON array describing the ports exposed by template. Each element in the array must be a valid JSON string specifying the port number in the container and the protocol. It can be optionally prefixed with the port that must be mapped on the host in the port: form. If the host port is not specified, the Docker host will automatically assign one when starting the container. This field is optional . Example: { \"ports\": [\"8080:80/tcp\", \"443/tcp\"] } labels A JSON array describing the labels associated to the template. Each element in the array must be a valid JSON object with two properties name and value. This field is optional . Example: { \"labels\": [ { \"name\": \"com.example.vendor\", \"value\": \"Acme\" }, { \"name\": \"com.example.license\", \"value\": \"GPL\" }, { \"name\": \"com.example.version\", \"value\": \"1.0\" } ] } privileged Should the container be started in privileged mode. Boolean, will default to false if not specified. This field is optional . { \"privileged\": true } interactive Should the container be started in foreground (equivalent of -i -t flags). Boolean, will default to false if not specified. This field is optional . { \"interactive\": true } restart_policy Restart policy associated to the container. Value must be one of the following: no unless-stopped on-failure always This field is optional. Will default to always if not specified. { \"restart_policy\": \"unless-stopped\" } hostname Set the hostname of the container. This field is optional . Will use Docker default if not specified. { \"hostname\": \"mycontainername\" } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to linux or windows. This will display a small platform related icon in the Portainer UI. This field is optional . { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Stack template definition format A template element must be a valid JSON object. Example of a stack template: { \"type\": 2, \"title\": \"CockroachDB\", \"description\": \"CockroachDB cluster\", \"note\": \"Deploys an insecure CockroachDB cluster, please refer to CockroachDB documentation for production deployments.\", \"categories\": [\"database\"], \"platform\": \"linux\", \"logo\": \"https://cloudinovasi.id/assets/img/logos/cockroachdb.png\", \"repository\": { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } } It is composed of multiple fields, some mandatory and some optionals. type emplate type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). A Swarm stack will be deployed using the equivalent of docker stack deploy whereas a Compose stack will be deployed using the equivalent of docker-compose. NOTE : Type 3 (Compose stack) is limited to using the version: \u201c2\u201d stack format, this is a limitation of docker/libcompose. This field is mandatory . type Title of the template. This field is mandatory . description Description of the template. This field is mandatory . repository A JSON object describing the public git repository from where the stack template will be loaded. It indicates the URL of the git repository as well as the path to the Compose file inside the repository. Element format: { \"url\": \"URL of the public git repository (mandatory)\", \"stackfile\": \"Path to the Compose file inside the repository (mandatory)\", } Example: { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template\u2019s logo. This field is optional . env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to Linux or Windows . This will display a small platform related icon in the Portainer UI. This field is optional. { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Build and host your own templates The simplest way to use your own templates is to bind mount your own template file directly into the Portainer container, see Configuration. You can also build your own container that will use Nginx to serve the templates definitions. Clone the Portainer templates repository , edit the templates file, build and run the container: $ git clone https://github.com/portainer/templates.git portainer-templates $ cd portainer-templates # Edit the file templates.json $ docker build -t portainer-templates . $ docker run -d -p \"8080:80\" portainer-templates Now you can access your templates definitions at http://docker-host:8080/templates.json . You can also mount the templates.json file inside the container, so you can edit the file and see live changes: $ docker run -d -p \"8080:80\" -v \"${PWD}/templates.json:/usr/share/nginx/html/templates.json\" portainer-templates Notes Contribute to these docs","title":"App Templates"},{"location":"v2.0/settings/edge/","text":"Enable Edge Computing features In today\u2019s world you can easily have hundreds - if not thousands - of Docker-enabled devices in your environment. Most of these systems run without any form of clustering or run a lean orchestrator such as Docker Swarm or Kubernetes. Remote devices may be distributed across multiple sites and/or across many different networks, some may even be attached to the internet using mobile data or satellite. To be managed effectively, engineers need a way to control distributed instances centrally, which is exactly what Portainer does with Edge Computer Features. Enabling Edge Compute Features First you must enable Edge Compute in the Portainer Settings. Click Settings and scroll down to Edge Compute section. Enable the toggle and 3. click Save Settings After that, you will see that a few options appear in the side menu. More Resources Take a look to the Edge section in the User Guide to see how to use it. Deploy an Stack Add a Job Managind Edge Groups Notes Contribute to these docs","title":"Enable Edge Computing"},{"location":"v2.0/settings/host_management/","text":"Enable Host Management features From Portainer, you can enable Host Management Features. The benefit of enabling this setting is to do Host system browsing, understand what PCI devices, and physical disk are present in the node. To get access to this data from Portainer, you need to run the agent with the following environment variable CAP_HOST_MANAGEMENT: 1 . The following features are disabled by default for security reasons: Ability to manage the filesystem of the host where the agent is running Ability to retrieve hardware information about the host where the agent is running (PCI devices/disks) In order to enable these features, the agent must be configured properly by: Enabling the host management features via the CAP_HOST_MANAGEMENT environment variable Bind-mounting the root of the host in the agent container (must be bind-mounted in /host) Deploy Portainer Agent Docker Swarm To deploy a new agent with this setting enable, you must run the following: docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent -e CAP_HOST_MANAGEMENT=1 --mode global --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes --mount type=bind,src=/,dst=/host portainer/agent Deploying via stack file: version: '3.2' services: agent: image: portainer/agent environment: CAP_HOST_MANAGEMENT: 1 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true . Notes Contribute to these docs","title":"Enable Host Management Features"},{"location":"v2.0/settings/lb/","text":"Enable external Load Balancer usage Enabling the load balancer feature will allow users to expose applications they deploy over an external IP address assigned by Cloud provider. Note : Ensure that your cloud provider allows you to create load balancers if you want to use this feature. Might incur costs. Enabling usage of External Balancer To do this, you need to open Portainer, go to Cluster and the to Setup . After that, you need to enable the toggle Allow users to use external load balancer . After you enabled the toggle, scroll down and do a click in Save Configuration . Starting now, when you create a resource pool, you can define an external load balancer quota. Notes Contribute to these docs","title":"Enable use of external load balancer"},{"location":"v2.0/settings/security/","text":"Security Options Portainer allows various configuration options to add secuirty to your environment. In this help article, we going to review the security options that you can find under Host/Cluster --> Setup . Docker Endpoint Security Options Disable bind mounts for non-administrators : This security setting blocks the ability for non-admin users within Portainer to use bind mounts when creating containers and/or services/stacks. When this is enabled, the option to attach to a host file system path is removed. Disable privileged mode for non-administrators : This security setting blocks the ability for non-admin users within Portainer to elevate the privilege of a container to bypass SELinux/AppArmour. When this is enabled, the option to select \"Privileged\" mode when creating a container is removed. Disable the use of host PID 1 for non-administrators : This blocks the ability for non-admin users within Portainer to request that a deployed container operates AS the host PID. This is a security risk if used by a non-trustworthy authorized user as when they operate as PID1, they are in effect able to run any command in the container console as root on the host. Disable the use of Stacks for non-administrators : This is a \"sledgehammer\" method to remove any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer have provided the ability to disable some of the more common exploits, we cannot possibly block them all as there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry-points. Disable device mappings for non-administrators : This blocks the ability for users to map host devices into containers. Whilst the ability to map devices is generally used for good (eg mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount /dev/sda1 into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By enabling this feature, Portainer blocks the ability for non-admins to map ANY devices into containers. Disable container capabilities for non-administrators : Enabling the setting will hide the container capabilities tab for non-administrators when they are creating a container. Disable sysctl settings for non-administrators : Enabling this setting will remove ability for non-admin users to use sysctl options. Non-admin users will not be able to recreate/duplicate/edit any containers when this setting is toggled on. Notes Contribute to these docs","title":"Security Options"},{"location":"v2.0/stacks/create/","text":"How to create a new Stack Stacks are collections of services running in a Docker Swarm environment. Deploying a new stack You can deploy a new stack from Portainer using the following options: Web editor: Using our Web Editor, you will capable to define the services for this stack using a docker-compose format. Upload: If you're already have a stack.yml file, you can upload from your computer to deploy that stack. Git Repository: You can use a docker-compose format file hosted in Github. Custom Template: If you already created a template of stacks, you can deploy from this option. Web Editor To use our web editor, you need to Select Stacks , name the stack, select Web Editor and you can start to define your services using the editor. You can also define Environment Variables if needed. When you set up everything, click Deploy the Stack . Uploading a stack file In Portainer, you can create Stacks from compose YML files. To achieve this. Click Stacks , then Add Stack . Now Name your new stack, select Upload and choose your compose file from your computer, add environment variables if needed and then click Deploy the Stack . Deploy from Github Repository If you have your compose file hosted in Github, you can deploy from there. Select Stacks , then Add Stack , select Git Repository . Name your stack, and then, you need to define information about your Github repository : Repository URL: Here, you need to set the URL of your Github Repository. Repository Reference: Here, you need to define your branch. Compose Path: Here, you need to define the path to your compose file from the root of the repository. If you need authenticate, define your user and password. NOTE : If you have a 2FA configured in Github, your passcode is your password. Set environment variables if needed and then click Deploy the Stack . The docker-compose.yml file is only pulled once from GitHub for the creation of you stack. After creation, you cannot (auto-)update the stack based on changes in or commits to the file on GitHub. You can make local changes in the Editor tab like for stacks deployed from the Web editor but this won't affect the GitHub hosted file. See for the current status of a feaure request Add the ability to update and redeploy a stack created from a git repository #1753 Notes Contribute to these docs","title":"Add/Create a Stack"},{"location":"v2.0/stacks/duplicate_migration/","text":"Migrate a Stack to another Swarm Cluster From Portainer, you can migrate your stacks from one cluster to another. In this help article, you will learn how to do it. Migrating a Stack to another Swarm Cluster In this case, we have a local Swarm Cluster and we want to move 'my-awesome-stack' to another cluster. To do this, go to Stacks , and select your Stack. From the Duplicate/Migrate section, select the endpoint where you want to migrate. Once you selected the endpoint, click Migrate . You will see a pop-up advising about the migration. If you're sure, click Migrate . Once the migration is complete, you will see a pop-up confirming the migration. Notes Contribute to these docs","title":"Duplicate / Migrate Stacks"},{"location":"v2.0/stacks/inspect/","text":"Inspect a Stack In Portainer, you can inspect your stacks to see what is running or access to their logs and stats. Inspecting a Stack To inspect the task associated to your stack, select Stacks and then select the stack you want to inspect. Here you can: * View what services that make up this stack * If they are running or stopped * How many replicas running in each host * Access to logs * Inspect the task stats * Access to the container console Notes Contribute to these docs","title":"Inspect a Stack"},{"location":"v2.0/stacks/template/","text":"Create a template from a deployed Stack In Portainer, you can create an App template from deployed Stacks. This is really useful when you need to deploy the same stack several times. How to creating a Template from a Stack Select Stacks and select the desired and already deployed stack. Then click Create Template from stack . Now define some properties for this new template: Title: Name your new template. Description: Short description about your template. Notes: You can write notes about this template. Icon URL: You can set up a icon from a URL Platform: Here, you need to define if your template is ready for use in Linux or Windows environments. Type: Choose between Swarm and Docker Standalone. You can also upload another compose file from your computer or a Github repository if needed. Once this has been defined, you can add more services to your template. Once complete click create custom template . Notes Contribute to these docs","title":"Create a template from a Stack"},{"location":"v2.0/templates/deploy_container/","text":"Deploy a standalone app (Container) From Portainer, you can deploy a standalone app from the default template list. Deploying an standalone app To deploy a standalone container from the templates, you need to go to App Templates , enable the toggle Show container templates and pick the app you want to deploy. For this example, we will deploy an Apache Web Server. After that, define a name , network , access control if needed, port mapping , volumes and when all is set, do a click in Deploy the Container . You will see an animation in the button while the container is deploying: If everything work as expected, you will see a pop up confirming that the container was deployed. Notes Contribute to these docs","title":"Deploy an App (Container)"},{"location":"v2.0/templates/deploy_stack/","text":"How to deploy a stack from a template Portainer allows you to deploy an entire stack from a template from the template list which includes default and custom templates. Also see creating a template from a Stack . Deploying an Stack To deploy a stack, go to App Templates and choose the template you want to deploy. In this example, I will deploy a CockroachDB cluster. Set a name , define access control (if enabled with the toogle) and click Deploy the Stack You will see an animation in the button while the stack is deploying: If everything work as expected, you will see your new stack deployed. Click the name of your stack to see the details of the deployment: Notes Contribute to these docs","title":"Deploy a Stack"},{"location":"v2.0/troubleshooting/deprecated/","text":"Deprecated and removed features Deprecated features This section lists features and capabilities that have been marked as deprecated, and should no longer be used. Features and capabilities marked as deprecated will no longer receive enhancements or support. The table below provides an overview of deprecated features and capabilities. The Deprecated column contains the release in which the feature was marked deprecated, whereas the Remove column contains a tentative release in which the feature is to be removed. If no release is included in the Remove column , the release is yet to be decided on. Feature Deprecated Remove Disabling analytics via: --no-analytics v2.0 TBD Removed features This section outlines features & capabilities that have been removed from Portainer. Feature Removed Specifying external endpoints via JSON via --external-endpoints v2.0 Setting time between endpoint synchronization requests via --sync-interval v2.0 Disabling Portainer internal authentication via --no-auth v2.0 Specifying a templates file to load on first run via --templates-file v2.0 Preventing Portainer from running a snapshot of endpoints via --no-snapshot v2.0 Notes Contribute to these docs","title":"Deprecated and Removed Features"},{"location":"v2.0/troubleshooting/troubleshooting/","text":"Portainer Deployment Troubleshooting If you are still experiencing issues after reading this FAQ, feel free to contact us via any one of the following channels: Slack for community support GitHub to log an issue if you've found a bug Youtube for guided tutorials and updates Portainer.io or the contact us tool at the bottom right of screen Email support@portainer.io How do I reset my Portainer password? You can ask another Portainer admin to reset the password for you, or alternatively if it is for the default admin account (from when Portainer was initialized), you can try our password reset helper tool . There is an open feature request to bring this functionality inside Portainer, which can be tracked on our GitHub repository here . Why does my version number not match the latest version? If you have recently updated your version of Portainer, this usually indicates your browser has cached the page. To properly clear your cache, you will need to go into the browser settings and empty the cache. Note: You can use Ctrl + Shift + R on most browsers to load the specific page without cache, however you will need to repeat this on each page of Portainer to load the changes. Please also check you have pulled from the latest repo url. Users have access to an endpoint, but they cannot see anything. By default all resources inside an endpoint are assigned to administrator only for security reasons. To give non-admin users access you can use the access control widget within each resource to assign users ownership, or you can make the resource public to give all users access. Portainer lost it\u2019s configuration, why? Portainer as a Container: If you have not created a persistent volume for your Portainer container, then Portainer data will be stored inside the Docker container. If the container is then restarted, you will lose all of your data. Portainer as a Service: If you have not created a persistent volume for your Portainer service, then Portainer data will be stored inside the Docker container created by the service. If the service is updated, you may lose your Portainer configuration. See Deployment on how to create a persistent volume. If you have a persistent volume, then the issue may be that Portainer is not constrained to the node where the data is persisted. See the below section for more info. External endpoints are not working in the latest Portainer version, is this a bug? We are aware that the --external-endpoint feature is not working in some of the latest versions of Portainer. If you require use of external endpoints, we recommend rolling back to Portainer version 1.21.0 until a fix has been released. My host is using SELinux, can I use Portainer? If you want to manage a local Docker environment with SELinux enabled, you\u2019ll need to pass the --privileged flag to the Docker run command when deploying Portainer: docker run -d --privileged -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce You can also have a look at this helper . How can I use Portainer behind a proxy? With Portainer behind a proxy, some features requiring access to the Internet (such as Apps Templates) might be unavailable. When running Portainer as a container, you can set the HTTP_PROXY and HTTPS_PROXY env vars to specify which proxy should be used: docker run -d -p 9000:9000 -p 8000:8000 -e HTTP_PROXY=my.proxy.domain:7777 portainer/portainer-ce For examples on how to configure a reverse proxy to work with Portainer, you can refer to our example repo here . Note: these are in no way production-ready, and are intended solely for demonstration purposes. Exposed ports in the container view redirects me to 0.0.0.0, what can I do? You can \"fix\" this in two ways. In order for Portainer to be able to redirect you to your Docker host IP address and not the 0.0.0.0 address, you will have to change the configuration of your Docker daemon and add the --ip option. Note: that you will have to restart your Docker daemon for the changes to be taken in effect. Recommended : Go to Endpoints , select your endpoint and introduce the IP of the host in the field Public IP . Do a click in Update Endpoint . TLS Settings in local Kubernetes endpoint We're addressing a bug in the endpoint details view of a Kubernetes endpoint, TLS settings, and information about Docker TLS is incorrectly shown. Changing the TLS settings does not affect. The expected behavior is don't show TLS settings and Docker TLS message. These options are no needed, and no make any effect in the configuration of local Kubernetes endpoints. You can view more information about this bug and the progress for your resolution here . Notes Contribute to these docs","title":"Portainer Deployment Troubleshooting"},{"location":"v2.0/upgrade/updBE/","text":"Switching from CE to Portainer Business Full instructions on how to switch your environment from Portainer CE to Portainer Business are here. These steps should be followed where you have bought the product or you are running a Free Trial. Switching on Docker Assuming you've used our recommended deployment scripts: when upgrading to the Business version of Portainer, use the following commands: docker stop portainer docker rm portainer Those 2 commands will stop and remove the container respectively. Doing this will NOT remove your other applications/containers/etc. Now that you have stopped and removed the old version of Portainer, you can run this command docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always --pull = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest That will deploy the newest version of Portainer Business on your system. Now you can return to Portainer and login (you might need to log out first). When you login for the first time you will be prompted to enter your License Key. Copy this from the email you received and paste it into the dialogue box. You should notice that the bottom left corner now contains the words \"Business Edition\" Switching on Docker Swarm Assuming you've used our recommended deployment scripts: when upgrading to the Business version of Portainer, use the following commands: docker service update --image portainer/portainer-ee --force portainer_portainer That will deploy the newest version of Portainer Business on your Swarm Cluster. Now you can return to Portainer and login (you might need to log out first). When you login for the first time you will be prompted to enter your License Key. Copy this from the email you received and paste it into the dialogue box. You should notice that the bottom left corner now contains the words \"Business Edition\" Switching on Kubernetes Upgrade method depends on the original install method used. Choose the original deployment method tab used for instructions. Helm Charts Run the following command to update helm repo helm repo update Run the following command to deploy Portainer Business using all the previous settings used in Helm deployment helm upgrade -n portainer portainer portainer/portainer --reuse-values --set enterpriseEdition.enabled = true YAML Manifests Choose the right YML Manifest based on your original deployment NodePort kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml LoadBalancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml That will deploy the newest version of Portainer Business on your Kubernetes Cluster. Now you can go return to Portainer and login (you might need to log out first). When you login for the first time you will be prompted to enter your License Key. Copy this from the email you received and paste it into the dialogue box. You should notice that the bottom left corner now contains the words \"Business Edition\" How to Downgrade Full steps on how to downgrade from Portainer Business to CE are found here. Notes Contribute to these docs","title":"Upgrade CE to Business"},{"location":"v2.0/upgrade/upddocker/","text":"Upgrade a Standalone Docker Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Docker Standalone Assuming you've used our recommended deployment scripts: when upgrading to the latest version of Portainer, use the following commands: docker stop portainer docker rm portainer Those 2 commands will stop and remove the container respectively. Doing this will NOT remove your other applications/containers/etc. Now that you have stopped and removed the old version of Portainer, you can run this command docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce That will deploy the newest version of Portainer on your system, using the persistent data and upgrade the DB Now you can go to http://your-server-address:9000 and login. You should notice that the bottom left corner looks different than it did before. There is no more update nag and the version is no longer shown next to the Portainer logo. Upgrading from Version <1.24.1 Upgrades from versions prior to version 1.24.1 require an intermediate upgrade to portainer/portainer:1.24.1 prior to upgrading to the current release. Similar to the steps above, we stop and remove the container and run the 1.24.1 release of portainer. docker stop portainer docker rm portainer docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer:1.24.1 At this point, you are running version 1.24.1 which can be verified by to http://your-server-address:9000, logging in and confirming the version number in the lower left. To complete the upgrade, perform the steps defined in the previous section. Agent Only Upgrade When upgrading to the latest version of Portainer Agent, use the following commands: docker stop portainer_agent docker rm portainer_agent Those 2 commands will stop and remove the container respectively. Doing this will NOT remove your other applications/containers/etc. Now that you have stopped and removed the old version of Portainer Agent, you can run this command docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Notes Contribute to these docs","title":"Upgrading on Docker"},{"location":"v2.0/upgrade/updk8s/","text":"Upgrade Kubernetes Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Steps to upgrade Portainer and or Portainer agent deployed into Kubernetes. Upgrade method depends on the original install method used. Using Helm Add Portainer helm repo running the following, ignore any warning about the repo being there already. helm repo add portainer https://portainer.github.io/k8s/ helm repo update Run the command below to upgrade to latest version of Portainer helm upgrade -n portainer portainer portainer/portainer --reuse-values Using YAML Manifest Method 1: Easiest way to upgrade is to use Portainer UI and use manifest files.. Copy the contents of manifest file from For NodePort https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml Agent Only https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-nodeport.yaml For LoadBalancer https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Agent Only https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-lb.yaml Login to portainer, in Kubernetes endpoint where portainer is installed go to Applications --> Advanced Deployment. Paste the yaml content. Paste the yaml content and click Deploy. Portainer should come back to a login page in a few seconds. Method 2: For NodePort kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml Agent Only kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-nodeport.yaml For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb.yaml Agent Only kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-lb.yaml Now you can go to portainer url and login. You should notice the new version number at the bottom left of Portainer UI. Force Update If portainer does not update after running the above commands, force the download of latest image by running the following: kubectl -n portainer rollout restart deployment.apps/portainer or for Agent Only kubectl -n portainer rollout restart deployment.apps/portainer-agent Notes Contribute to these docs","title":"Upgrading on Kubernetes"},{"location":"v2.0/upgrade/updswarm/","text":"Upgrade a Docker Swarm Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Docker Swarm Steps to upgrade Portainer and or Portainer agent deployed into Docker Swarm as a service. Run the following on manager node of your docker swarm cluster docker service ls Make note of the service names for Portainer To upgrade Portainer to the latest version, run the command below (You may need to replace Service Name portainer_portainer to match your setup) docker service update --image portainer/portainer-ce --force portainer_portainer To upgrade Portainer Agent to the latest version, run the command below (You may need to replace Service Name portainer_agent to match your setup) docker service update --image portainer/agent --force portainer_agent That will deploy the newest version of Portainer on your system, using the persistent data and upgrade the DB Now you can go to http://your-server-address:9000 and login. You should notice that the bottom left corner looks different than it did before. There is no more update nag and the version is no longer shown next to the Portainer logo. Notes Contribute to these docs","title":"Upgrading on DockerSwarm"},{"location":"v2.0/users/create-team/","text":"Create a new team The Team Management feature means that you can now assign users into teams, authorize teams to access endpoints, enable containers/services/volume management at the team level, and provide fine-grained access control. Creating a Team To create a team in Portainer, select Users . Then 1. select Teams 2.Type the name of Team and 3. click Create Team . All teams created are listed Notes Contribute to these docs","title":"Create a Team"},{"location":"v2.0/users/create/","text":"Create a User Portainer allows the management of users and access. Creating a User Click Users Type the username 2. pick a password (a strong one) and 3. click Create User . List all users Confirmation at the top right shows on completion. Notes Contribute to these docs","title":"Create a User"},{"location":"v2.0/users/promoting/","text":"How to promote a regular user to administrator First click Users and select the user you want to promote. Enable the toggle Administrator in the next screen and click Save . Confirmation appears at the top right of screen. The user list now shows the selected user with the administrator role. Notes Contribute to these docs","title":"Promote a User as Admin"},{"location":"v2.0/users/reset-admin/","text":"Reset password for the Admin user It can happen to anyone, admin passwords get forgoteen and lost all the time. If this ever happens to your Portainer admin, you can follow these steps to reset it. Resetting Admin password in Portainer running as container Reset the password for the Admin user can be accomplished using our reset password container helper . First, stop the Portainer container by running: docker stop \"id-portainer-container\" Run the helper with the following command. Be advised that you need to mount the Portainer data volume. docker run --rm -v portainer_data:/data portainer/helper-reset-password If successful, your output should look like this: 2020/06/04 00:13:58 Password successfully updated for user: admin 2020/06/04 00:13:58 Use the following password to login: &_4#\\3^5V8vLTd)E\"NWiJBs26G*9HPl1 Start the Portainer container running and try login with the password generated: docker start \"id-portainer-container\" Resetting Admin password in Portainer running as a stack/service To reset the password of the Admin user in Portainer running as Stack or Service, we need to scale the Portainer service to zero. To do this, you can run the following: docker service scale portainer_portainer=0 Run the helper using the same bind-mount/volume for the data volume: docker run --rm -v portainer_portainer_data:/data portainer/helper-reset-password If successful, your output should look like this: 2020/06/04 00:13:58 Password successfully updated for user: admin 2020/06/04 00:13:58 Use the following password to login: &_4#\\3^5V8vLTd)E\"NWiJBs26G*9HPl1 Start the Portainer service scaling up and try login with the password generated: docker service scale portainer_portainer=1 Notes Contribute to these docs","title":"Reset Administrator Password"},{"location":"v2.0/users/reset-user/","text":"How to change/reset user password Select Users and then select the User who's password you would like to reset. Set the new password (a strong one) and click update password . You will see confirmation at the top right of screen if successful. Notes Contribute to these docs","title":"Reset User Password"},{"location":"v2.0/users/user-team/","text":"Add a user to a team First select Users under settings , then select Teams and choose the team that you want to add users to. Click Add next to the user you want to add to the team. You should now see the user under team members Notes Contribute to these docs","title":"Add a User to a Team"},{"location":"v2.0/volumes/attaching/","text":"Attach an existing Volume to a Container Portainer can attach a new volume to a running container. Be advised that this operation destroys the running container and starts a new one with the volume attached. Backup your data before doing this. Attaching a volume Go to Containers and select the container that you want to attach a volume to. Click Duplicate/Edit. Scroll down to see the options for this container. Select Volumes and click Map an Additional Volume. Next, type the path in the container, in the example below, for an NGINX container, the path to persist is \"/usr/share/nginx/html\". We also need to specify the volume created. Finally, click Deploy The Container . You will receive the following warning: If successful you will see the confirmation pop up at the top right of screen. To confirm the configuration of your container, select it and scroll to the volume configuration, you should see a similar screen to the below: Notes Contribute to these docs","title":"Attach an Existing Volume"},{"location":"v2.0/volumes/browse/","text":"Browse a volume Portainer allows users to view volumes in Docker Swarm nodes. Browsing a Volume Click Volumes from the side menu, and then click browse next to the volume you want to explore. From this screen, you can upload files to this volume and expose it to the container quickly and without using a CLI. Notes Contribute to these docs","title":"Browse a Volume"},{"location":"v2.0/volumes/create/","text":"How to create a new volume Volumes are used to make persistent storage that you can manage from Portainer. Note: Creating a standalone volume is only supported in a Docker Swarm and Docker Standalone endpoints. Creating a LOCAL volume Click Volumes from the side menu and then click Create Volume . Complete the detail fields for this volume: Name: Give your volume with a descriptive name Driver Configuration: Local NFS: For local volumes leave this off CIFS: For local volumes leave this off Once complete, click Create the Volume . Creating an NFS volume In Portainer, you can mount an NFS volume to persist the data of your containers. To achieve this, go to Volumes and then click Create Volume. Complete the detail fields for this volume: Name: Give your volume with a descriptive name Driver Configuration: Local NFS: Enable this toggle Under the NFS Settings section. You will find: Address: Type the hostname or IP address of your NFS Server. NFS Version: Choose the version of NFS that your NFS Server uses. Mount Point: The path where that volume is mounted. E.g. /mnt/nfs01. Options: We recommend leaving the default values in this field. When this is complete click Create the Volume . Creating a CIFS volume In Portainer, you can mount a CIFS volume to persist the data of your containers. To achieve this, go to Volumes and then click Create Volume. Complete the detail fields for this volume: Name: Give your volume with a descriptive name. Driver Configuration: Local NFS: Leave this toggle off CIFS: Enable this toggle In CIFS Settings section. You will find: Address: Type your CIFS Server name or IP Address Share: Type the name of the share resource CIFS Version: Pick the correct version of CIFS that you're using Username: Your defined user to authenticate Password: Your defined password to authenticate When this is complete click Create the Volume . Notes Contribute to these docs","title":"Create a Volume"},{"location":"v2.0/volumes/delete/","text":"Delete a Volume From Portainer you can delete a volume. Note that all the content inside the deleted volume will be erased. Deleting a Volume Go to Volumes , select the volume you want remove, and click Remove . Note: You can't delete volumes attached to a container, to do this, remove the container first and then, try to delete the volume. Notes Contribute to these docs","title":"Delete a Volume"},{"location":"v2.0/webhooks/create/","text":"Webhooks You can use webhooks to trigger an action in a service in response to a push event in a repository. Webhooks are POST requests sent to a URL you define in Docker Hub or another registry. Enable Service Webhook To enable a webhook for a service, go to Services , click on the service you want to set up the Webhook for, and enable the toggle Service Webhook . After you enable the toggle you will see the URL to configure your webhook in Docker Hub or another repository. Click the copy button to get the full URL. Examples Here, you can find a few examples to understand how easy it is to trigger the webhook. Redeploy <form action=\"http://192.168.1.12:9000/api/webhooks/638e6967-ef77-4906-8af8-236800621360\" method=\"post\"> Redeploy with latest image of same tag <input type=\"submit\" /> </form> Update Service with another tag <form action=\"http://192.168.1.12:9000/api/webhooks/638e6967-ef77-4906-8af8-236800621360?tag=latest\" method=\"post\"> Update Service image with different tag <input type=\"submit\" /> </form> Configuring the Webhook in Docker Hub To see how to complete the configuration in Docker Hub, click here . Notes Contribute to these docs","title":"Configure a Webhook"},{"location":"v2.0-be/access/inportainer/","text":"Access Control All docker or docker swarm resources created through Portainer except images have Access Control settings. You can set these at the time of creation or later on as needed. Any resources created through a stack or service will inherit the same access as the parent. Below are examples of different sets of Access Controls you can have. Administrators Only The is an example Create Stack screen, deploys a stack with Access Control Enabled and only Portainer Administrators will have access to the Stack and any Resources created through the stack (eg. Containers/Services/Volumes/Networks/Secrets etc) Public This is an example Create Service Screen, deploys a service with Access Control disabled. All Portainer Users will have access to the service and any resources created through the service (eg. Containers/Volumes/Networks/Secrets etc) Restricted to Specific Groups/Users This is an example Create Container Screen, deploys a Container with Access Control Enabled. Once you select the Restricted option, you may select 'one or more teams' and or 'one or more users' to have access to the Resource. Notes Contribute to these docs","title":"Resources Deployed through Portainer"},{"location":"v2.0-be/access/outofportainer/","text":"Access Control Any resources deployed to docker or docker swarm outside of Portainer will be marked as external and you will have limited control over these resources. You can still enable Access Control on these using Labels. By default any resources deployed outside of Portainer has Administrator Only access. You can control access using Labels: Label Description Notes io.portainer.accesscontrol.public All portainers users have access to the resource(s) Takes precedence over team/user assignments io.portainer.accesscontrol.teams=dev,prod Access restricted to Teams dev and prod only Can be used in conjunction with io.portainer.accesscontrol.users io.portainer.accesscontrol.users=bob,adam Access restricted to users bob and adam only Can be used in conjunction with io.portainer.accesscontrol.teams Examples Deploy a stack using docker-compose and restrict access to Teams dev and prod version : '3.2' services : ltest : image : busybox:latest command : \"ping localhost\" labels : io.portainer.accesscontrol.teams : dev,prod Deploy a stack using docker cli and restrict access to Team testers and Users bob and adam version : '3.2' services : ltest : image : busybox:latest command : \"ping localhost\" labels : io.portainer.accesscontrol.teams : testers io.portainer.accesscontrol.users : bob,adam Deploy a container using docker cli and make it accessible to all Portainer Users docker run -d --label io.portainer.accesscontrol.public nginx:latest Deploy a container using docker cli and restrict access to Teams dev and prod and Users bob docker run -d --label io.portainer.accesscontrol.teams = dev,prod --label io.portainer.accesscontrol.users = bob nginx:latest Notes Contribute to these docs","title":"Resources Deployed outside of Portainer"},{"location":"v2.0-be/aci/aci/","text":"Azure Container Instances Portainer Business allows you to deploy and manage apps in Azure Container Instances quickly and easily and like no other tool. There is no need to type commands via CLI or go to the Azure Portal to manage your containers; Portainer does it all. Simply deploy Portainer in an Azure container and manage it like any other node. Portainer Business 2.0 allows you to manage your container nodes, even in the Cloud. Quickly create new containers in Azure Container Instances. Overall view of the containers running in ACIs from a unique instance of Portainer. Define from one page-to-run name, image, resource groups, and locations. Have you multiple instances and teams? no problem, define one or more instances to one or more teams and control the usage of the different environments. Adding an ACI Endpoint You can view how to add an ACI Endpoint in our Administrator Guide . Notes Contribute to these docs","title":"About ACI"},{"location":"v2.0-be/aci/add_container/","text":"Add a Container Instance From Portainer you can add new containers in your Azure Container Instance service. Adding a New Container Instance From Portainer Home, click in your Azure Container Instance endpoint . Click Container Instances and then Add Container . In the next screen, you need to define the container configuration, these options are available: Subscription: If you have two or more subscriptions attached, you can choose where you want to deploy your container. Resource Group: If you have two or more Resources groups created, you need to define where you want to deploy your container. Location: Here you need to define in which datacenter you want to run your container. Name: Name your container. Image: Type the name of the image you want to deploy. OS: Select the appropriate OS, usually Linux or Windows. Port Mapping: Choose what port you need to publish to the Internet. CPU: Define how much CPU you want for your container. Memory: Define how much memory you want for your container. When everything is set, click Deploy the Container . Meanwhile the deployment is in progress this message will show in the button. After the deployment has completed, Portainer will exit to the container list and you will see your new container deployed in Azure Container Instances. Notes Contribute to these docs","title":"Add New Container"},{"location":"v2.0-be/aci/delete_container/","text":"Delete a Container From Portainer, you can delete your containers running in Azure containers instances. Deleting containers Click Container Instances , select the container you want to delete and click Remove . After removing the container, you will see a pop up confirming that action. Notes Contribute to these docs","title":"Delete a Container"},{"location":"v2.0-be/ad/nginx/rp-nginx/","text":"Deploy Portainer behind NGINX Reverse Proxy Deploying in a Docker Standalone scenario To deploy Portainer behind NGINX Proxy in a Docker standalone scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Server and NGINX Proxy. version: \"2\" services: nginx-proxy: image: jwilder/nginx-proxy restart: always networks: - proxy ports: - \"80:80\" volumes: - \"/var/run/docker.sock:/tmp/docker.sock:ro\" - \"./vhost.d:/etc/nginx/vhost.d:ro\" portainer: image: portainer/portainer-ce:2.0.0 command: -H unix:///var/run/docker.sock restart: always networks: - proxy environment: - VIRTUAL_HOST=portainer.yourdomain.com - VIRTUAL_PORT=9000 ports: - 8000:8000 volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data networks: proxy: volumes: portainer_data: To setup and start working with this recipe, you need to change the VIRTUAL_HOST value. You can then run the following: docker-compose up -d Once complete, you will able to run docker ps and you will see an output similar to this: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 088da047e931 portainer/portainer-ce:2.0.0 \"/portainer -H unix:\u2026\" 32 minutes ago Up 22 minutes 0.0.0.0:8000->8000/tcp, 9000/tcp nginx-port_portainer_1 1ec0594f8a01 jwilder/nginx-proxy \"/app/docker-entrypo\u2026\" 32 minutes ago Up 22 minutes 0.0.0.0:80->80/tcp nginx-port_nginx-proxy_1 Once the deployment is complete you can browse portainer.yourdomain.com . Deploying in a Docker Swarm scenario Deploying Portainer in Docker Swarm behind NGINX has similar steps to the Docker Standalone scenario. First, you need to create a few networks. One for the agent and the communication with Portainer Server, and other to \"expose\" the Portainer container to the same network that the Reverse Proxy. Before deploying, you need to create 2 elements: Networks and volumes. First, create 2 networks for the agent to communicate with Portainer Server and other to \"expose\" the Portainer container to the same network that as the Reverse Proxy docker network create -d overlay proxy docker network create -d agent_network Then create the volume: docker volume create portainer_data Save the below recipe as portainer.yml version: '3.2' services: nginx-proxy: image: jwilder/nginx-proxy networks: - proxy ports: - \"80:80\" volumes: - \"/var/run/docker.sock:/tmp/docker.sock:ro\" - \"./vhost.d:/etc/nginx/vhost.d:ro\" agent: image: portainer/agent environment: # REQUIRED: Should be equal to the service name prefixed by \"tasks.\" when # deployed inside an overlay network AGENT_CLUSTER_ADDR: tasks.agent # AGENT_PORT: 9001 # LOG_LEVEL: debug volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ce:2.0.0 command: -H tcp://tasks.agent:9001 --tlsskipverify volumes: - data:/data environment: - VIRTUAL_HOST=portainer.yourdomain.com - VIRTUAL_PORT=9000 ports: - 8000:8000 networks: - proxy - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] networks: proxy: external: true agent_network: external: true volumes: data: To setup and start working with this recipe, you need to change the VIRTUAL_HOST value. You're now ready to deploy Portainer by executing the following: docker stack deploy portainer -c portainer.yml To check the deployment you can run docker service ls and you will see an output similar to the following: ID NAME MODE REPLICAS IMAGE PORTS gy2bjxid0g4p portainer_agent global 1/1 portainer/agent:latest jwvjp5bux4sz portainer_nginx-proxy replicated 1/1 jwilder/nginx-proxy:latest *:80->80/tcp 5nflcvoxl3c7 portainer_portainer replicated 1/1 portainer/portainer-ce:2.0.0 *:8000->8000/tcp Once the services are running, you can browse the url specified (e.g. portainer.yourdomain.com) to access Portainer. Deploying in a Kubernetes scenario WIP Notes Contribute to these docs","title":"Nginx"},{"location":"v2.0-be/ad/traefik/rp-traefik/","text":"Deploy Portainer behind Traefik Proxy Traefik Proxy is a reverse proxy and load balancing solution focused on micro services. Deploying in a Docker Standalone scenario To deploy Portainer behind Traefik Proxy in a Docker standalone scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Traefik with SSL support and Portainer Server. version: \"3.3\" services: traefik: container_name: traefik image: \"traefik:latest\" command: - --entrypoints.web.address=:80 - --entrypoints.websecure.address=:443 - --providers.docker - --log.level=ERROR - --certificatesresolvers.leresolver.acme.httpchallenge=true - --certificatesresolvers.leresolver.acme.email=your-email #Set your email address here, is for the generation of SSL certificates with Let's Encrypt. - --certificatesresolvers.leresolver.acme.storage=./acme.json - --certificatesresolvers.leresolver.acme.httpchallenge.entrypoint=web ports: - \"80:80\" - \"443:443\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock:ro\" - \"./acme.json:/acme.json\" labels: - \"traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)\" - \"traefik.http.routers.http-catchall.entrypoints=web\" - \"traefik.http.routers.http-catchall.middlewares=redirect-to-https\" - \"traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https\" portainer: image: portainer/portainer-ce:2.0.0 command: -H unix:///var/run/docker.sock restart: always volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data labels: # Frontend - \"traefik.enable=true\" - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.frontend.entrypoints=websecure\" - \"traefik.http.services.frontend.loadbalancer.server.port=9000\" - \"traefik.http.routers.frontend.service=frontend\" - \"traefik.http.routers.frontend.tls.certresolver=leresolver\" # Edge - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" - \"traefik.http.routers.edge.entrypoints=websecure\" - \"traefik.http.services.edge.loadbalancer.server.port=8000\" - \"traefik.http.routers.edge.service=edge\" - \"traefik.http.routers.edge.tls.certresolver=leresolver\" volumes: portainer_data: Before you run this file in Docker you will need to create the acme.json file that will store the SSL certificates. Once it has been created you need to define the path of that file in the following sections: In the volume and command section of the Traefik Proxy container - \"./acme.json:/acme.json\" - --certificatesresolvers.leresolver.acme.storage=./acme.json You need to setup your email address for the registration with Let's Encrypt. - --certificatesresolvers.leresolver.acme.email=your-email Next, need to customize some labels in the Traefik container. The following labels need to be modified with the url that you want use to access Portainer. - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" After all this setup, you're ready to deploy Portainer: docker-compose up -d After the images have been downloaded and deployed you will able to access Portainer in the URL you defined earlier. Eg: https://portainer.yourdomain.com This file also exists in our repository on Github . Deploying in a Docker Swarm scenario To deploy Portainer behind Traefik Proxy in a Docker Swarm scenario we will use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the Portainer Traefik with SSL support and Portainer Server. Before deploying, you need to create 2 elements: Networks and volumes. First, create 2 overlay networks: docker network create -d overlay agent_network docker network create -d overlay public Then create the volume: docker volume create portainer_data Save the below recipe as portainer.yml version: '3.2' services: traefik: image: \"traefik:latest\" command: - --entrypoints.web.address=:80 - --entrypoints.websecure.address=:443 - --providers.docker=true - --providers.docker.swarmMode=true - --providers.docker.exposedbydefault=false - --providers.docker.network=public - --api - --log.level=ERROR ports: - \"80:80\" - \"443:443\" networks: - public volumes: - \"/var/run/docker.sock:/var/run/docker.sock:ro\" agent: image: portainer/agent environment: # REQUIRED: Should be equal to the service name prefixed by \"tasks.\" when # deployed inside an overlay network AGENT_CLUSTER_ADDR: tasks.agent # AGENT_PORT: 9001 # LOG_LEVEL: debug volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ce:2.0.0 command: -H tcp://tasks.agent:9001 --tlsskipverify volumes: - data:/data networks: - public - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] labels: - \"traefik.enable=true\" - \"traefik.http.routers.portainer.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.portainer.entrypoints=web\" - \"traefik.http.services.portainer.loadbalancer.server.port=9000\" - \"traefik.http.routers.portainer.service=portainer\" # Edge - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" - \"traefik.http.routers.edge.entrypoints=web\" - \"traefik.http.services.edge.loadbalancer.server.port=8000\" - \"traefik.http.routers.edge.service=edge\" networks: public: external: true agent_network: external: true volumes: data: Before you can deploy, you need to customize these labels to match the URL that you want. - \"traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)\" - \"traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)\" You're now ready to deploy Portainer by executing the following: docker stack deploy portainer -c portainer.yml To check the deployment you can run docker service ls and you will see an output similar to the following: ID NAME MODE REPLICAS IMAGE PORTS lt21zrypsll6 portainer_agent global 1/1 portainer/agent:latest m6912ynwdcd7 portainer_portainer replicated 1/1 portainer/portainer-ce:2.0.0 tw2nb4i640e4 portainer_traefik replicated 1/1 traefik:latest *:80->80/tcp, *:443->443/tcp Once the services are running, you can browse the URL specified (e.g. portainer.yourdomain.com) to access Portainer. Deploying in a Kubernetes scenario WIP Notes Contribute to these docs","title":"Traefik"},{"location":"v2.0-be/auth/ad/","text":"Enable Microsoft Active Directory authentication Portainer Business Edition, offer you the posibility to connect to a existent Microsoft Active Directory to manage your authentication settings in Portainer. In this help article, we going to explan how to configure it. Configuring Active Directory in Portainer AD Configuration To start to configure Active Directory authentication, go to Settings > Authentication and select Microsoft Active Directory . Now, you can start to configure your Active Directory. To start, you need to define a few details: AD Controller: Here, you can enter the FQDN or IP address of your Domain Controller. Service Account: Witch would be the account that we handle the connection with AD and search users. Service Account Password: Password for this account. AD Connectivity Security Here, you can define, the following options: Use StartTLS: Enable this option if want to use StartTLS to secure the connection to the server. Ignored if Use TLS is selected. Use TLS: Enable this option if you need to specify TLS certificates to connect to the LDAP server. Skip verification of server certificate: Skip the verification of the server TLS certificate. Not recommended on unsecured networks. User search configurations In this section, you can configure the Username format . This is how your users will log in to Portainer, the options are using Username or a full username user@domain.com Root Domain: Will use the domain of the address to the Domain Controller. User Search Path (optional): Here you can define differents OU or Folder. Allowed Groups (optional): You can specify specific groups of the directory to access to Portainer. User Filter: Is filled by default according to OpenLDAP configuration. Teams auto-population configurations Group Search Path (optional): Here you can define differents OU or Folder. Group Base DN: Will be used the DN used when you authenticate to the Domain Controller. Groups: Here you can define differents OU or Folder. Group Filter: Is filled default according to OpenLDAP configuration. Test Login If you want to know if your configuration is valid, you can run a test login from the configuration of Active Directory settings. Scroll down to Test Login Section, fill with a valid user and password and do a click in Test . If everything is work as expected, you will see a check beside of the button. Notes Contribute to these docs","title":"Active Directory"},{"location":"v2.0-be/auth/auto/","text":"Automatic User Provisioning When you configure any external authentication method in Portainer Business Edition, Portainer will create user(s) automatically with the standard user role. If disabled, users must be created beforehand in Portainer in order to login. Enabling Automatic Provisioning To enable Automatic Provisiong go to settings > Authentication and when you select your preferred external authentication type technology, enable the toggle Automatic User Provisioning , after that, you need to specify a team where the users from this external authentication source going to be saved. Notes Contribute to these docs","title":"Automatic User Provisioning"},{"location":"v2.0-be/auth/internal/","text":"Local Authentication When using internal authentication, Portainer will encrypt user passwords and store credentials locally. Notes Contribute to these docs","title":"Internal"},{"location":"v2.0-be/auth/ldap/","text":"LDAP/AD Authentication Portainer can be configured to accept Lightweight Directory Access Protocol (LDAP) authentication if your organization has implemented LDAP or Active Directory authentication. When users attempt to log into Portainer, the application will authenticate them against your LDAP directory or Active Directory. If authentication is successful, the user is allowed to log into Portainer. In order to configure Portainer LDAP authentication, you first need to add a user to your directory service for the purpose of authenticating from Portainer to read the LDAP. The user should be a service account that needs read-only access to LDAP/Active Directory. Enabling LDAP Log into Portainer as an administrator and navigate to Settings > Authentication. Select the \u2018LDAP Authentication' option. You will see two options: Custom where you can define a custom/third party LDAP Server to use and OpenLDAP where you will capable to enter all the data needed to connect with OpenLDAP. Custom LDAP Enter in the IP address/FQDN and the port number of your LDAP server, and then select to either connect anonymously (your LDAP server must support this), or enter a user account that has READ access to the directory. Click \"Test Connectivity\" to validate you can connect. A configuration with Anonymous mode on (must be supported) A configuration defining Reader DN and Password . Explanation of Settings Here is an explanation of the above settings: LDAP Security Use StartTLS: After initial connection, elevate the insecure connection to secure. Use TLS: Initiate a connection to LDAP using TLS. Skip Verification of Certificate: If you do not have access to the certificate of the LDAP server, skipping verification enables encrypted communications, but you must manually ensure that you are talking to the intended LDAP server that you gave in your URL. If that gets maliciously redirected then you could be talking to a different server. Use with caution. TLS CA Certificate: Upload your CA Certificate for the secure connection. Connectivity Check:Validate successful connectivity before continuing. Automatic User Provisioning Automatic User Provisioning: Enabling this setting automatically creates users within Portainer once they are successfully authenticated by LDAP. If you do not enable this, you must manually create users with the same username as the corresponding LDAP directory. User Search Configurations Base DN: Enter DC=MYDOMAIN,DC=com to search your entire Directory for the username attempting to login. or OU= ,DC= ,DC= to search for users only within the specified OU, or CN=NAME,DC= ,DC= if your users are only in a container (in AD, the default is that all users are in a container called users; CN=Users). If you have a large number of users in your Domain, you should narrow the scope Portainer searches by using OU's. Username Attribute: For Native LDAP, Enter uid ; For Active Directory, either enter userPrincipalName if your usernames will be in the format of user@mydomain.com enter SAMAccountName if your usernames will be in the format username . Do not use uid with Active Directory as it will not work. Note: These entries are case sensitive. Filter: Enter an criteria to pre-filter the results returned from LDAP to Portainer. Example, to only allow users who are members of a group, which is a group defined within an OU to login, set the Filter to be: (the brackets are important, so copy the entire string below)... (&(objectClass=user)(memberOf=CN= ,OU= ,DC= ,DC= )) The example below shows that in the domain portainer.local, we have an OU called \"Groups\" and within that OU is a group called \"PortainerDevUsers\". This search filter will only allow users to login to Portainer that are members of the PortainerDevUsers LDAP group. Team auto-population configurations Portainer optionally allows you to set a Group Search as well as the User Search. If this is configured, if an LDAP user is a member of an LDAP group, and that LDAP Group corresponds to an identically named Portainer TEAM, then the LDAP user will automatically be placed into the Portainer Team based on their LDAP group membership. This is very useful for automatically granting access to Portainer endpoints via group membership. Group Base DN: Enter DC= ,DC= to search your entire Directory for the list of groups. or OU= ,DC= ,DC= to search for groups only within the specified OU, or CN=NAME,DC= ,DC= if your groups are only in a container (in AD, the default is that all groups are in a container called users; CN=Users). If you have a large number of groups in your Domain, you should narrow the scope Portainer searches by using OU's. Group Membership Attribute: Enter \"member\" as the attribute that determines if a user is a member of a group. Group Filter: If you want to filter the list of groups returned, to say, only return groups that contain the string \"Portainer\" (eg PortainerDev, PortainerProd, PortainerUAT\", you can set the filter as follows: (&(objectclass=group)(cn=*Portainer*)) Optional - if you are NOT enabling user Auto Provisioning - Creating LDAP Users Navigate to User Management. Create a username that matches your LDAP source users with the format defined when enabling LDAP (either \u2018username\u2019 or \u2018username@mydomain.com\u2019). OpenLDAP Enter in the IP address/FQDN and the port number of your LDAP server, and then select to either connect anonymously (your LDAP server must support this), or enter a user account that has READ access to the directory. Click \"Test Connectivity\" to validate you can connect. A configuration with Anonymous mode on (must be supported) A configuration defining Reader DN and Password . Explanation of Settings Here is an explanation of the above settings: LDAP Security Use StartTLS: After the initial connection, elevate the insecure connection to secure. Use TLS: Initiate a connection to LDAP using TLS. Skip Verification of Certificate: If you do not have access to the certificate of the LDAP server, skipping verification enables encrypted communications, but you must manually ensure that you are talking to the intended LDAP server that you gave in your URL. If that gets maliciously redirected then you could be talking to a different server. Use with caution. TLS CA Certificate: Upload your CA Certificate for the secure connection. Connectivity Check:Validate successful connectivity before continuing. Automatic User Provisioning Automatic User Provisioning: Enabling this setting automatically creates users within Portainer once they are successfully authenticated by LDAP. If you do not enable this, you must manually create users with the same username as the corresponding LDAP directory. User Search Configurations Root Domain: Will be used the DN used when you authenticate to the OpenLDAP Server. User Search Path (Optional): Here you can define differents OU or Folder. Allowed Groups (optional): You can specify another group and their path to the directory. User Filter: is filled by default according to OpenLDAP configuration. To check if everything works as expected, click Display Users and you will see a list with the names configured in the directory. Team auto-population configurations Portainer optionally allows you to set a Group Search as well as the User Search. If this is configured, if an LDAP user is a member of an LDAP group, and that LDAP Group corresponds to an identically named Portainer TEAM, then the LDAP user will automatically be placed into the Portainer Team based on their LDAP group membership. This is very useful for automatically granting access to Portainer endpoints via group membership. Group Search Path (optional): Here you can define differents OU or Folder. Group Base DN: Will be used the DN used when you authenticate to the OpenLDAP Server. Group Filter: Is filled default according to OpenLDAP configuration. To check if everything works as expected, click Display Users and Groups and you will see a list with the names configured in the directory. Test Login If you want to know if your configuration is valid, you can run a test login from the configuration of OpenLDAP settings. Scrolldown to Test Login Section, fill with a valid user and password and click Test . If everything works as expected, you will see a check beside of the button. Optional - if you are NOT enabling user Auto Provisioning - Creating LDAP Users Navigate to User Management. Create a username that matches your LDAP source users with the format defined when enabling LDAP (either \u2018username\u2019 or \u2018username@mydomain.com\u2019). Notes Contribute to these docs","title":"LDAP"},{"location":"v2.0-be/auth/oauth-cust/","text":"Custom OAuth Provider Portainer Business Edition can be connected to several OAuth providers. Requirements You will need to have the following info handy before configuring OAuth. Client ID : This is the public identifier of the OAuth application. Client Secret : Here, you need fill with the token access to the OAuth Application. Authorization URL : URL used to authenticate against the OAuth provider. Will redirect the user to the OAuth provider login view. Access Token URL : URL used to authenticate against the OAuth provider. Will redirect the user to the OAuth provider login view. Resource URL : URL used by Portainer to retrieve information about the authenticated user. Redirect URL : URL used by the OAuth provider to redirect the user after successful authentication. Should be set to your Portainer instance URL. User Identifier : Identifier that will be used by Portainer to create an account for the authenticated user. Retrieved from the resource server specified via the Resource URL field. Scopes : Required by the OAuth provider to retrieve information about the authenticated user. Refer to your OAuth provider documentation for more information about this. We will use KeyCloak as an example Provider and steps to obtain these: Login to KeyCloak Administration Console as an Admin Select the applicable authentication \u201cRealm\u201d from the dropdown in the left sidebar Click on \u201cClients\u201d, in the left sidebar, and then click the \u201cCreate\u201d button to define a new app instance. In the \u201cClient ID\u201d enter in (and record) a name for the Portainer App instance you are authorising. Something like portainer-auth. Keep the client protocol as openid-connect, and for the root URL enter in the FDQL of your Portainer instance, as below, and then click \u201cSave\u201d. Now change the \u201cAccess Type\u201d to \u201cconfidential\u201d, and switch \u201cService Accounts Enabled\u201d to \u201cON\u201d, then click \u201cSave\u201d. Note that once you click \u201cSave\u201d a new header menu items appears, called \u201cCredentials\u201d. Click on that menu. Take a note of the Secret ; this will be required later. Now, we assume you already have users defined in your KeyCloak system, but if not, click on \u201cUsers\u201d in the left sidebar and add users as required. Configuration To configure a custom OAuth provider, once you logged to Portainer, click Settings and then authentication . After that, select custom option. In this screen, you need to configure the data that you OAuth provider give you to configure Portainer. The fields are: Automatic User Provisioning: Toggle on these options if you want to create users for each user logged using OAuth. After enable the toggle, you need to define in wich team that users should be created. Client ID Client Secret Authorization URL Access Token URL Resource URL Redirect URL User Identifier Scopes Once that all fields are completed, click Save Settings Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Notes Contribute to these docs","title":"Custom"},{"location":"v2.0-be/auth/oauth-github/","text":"Github OAuth Provider Portainer Business can be connected to Github OAuth provider in an easy way without need to understand complex configuration. Requirements You will need to have the following info handy before configuring OAuth using Github Provider. Client ID : Public identifier of the OAuth Application. Client Secret : The secret of this client. You can obtain these details by following the steps below: Login to Github as an Org Admin, Select \u201cOAuth Apps\u201d from Develop Settings sub menu in the left sidebar Click on \u201cRegister an application\u201d In \u201cApplication Name\u201d enter a friendly name In \u201cHomepage URL\u201d and \u201cAuthorisation callback URL\u201d, text boxes, enter the full URL to your Portainer instance, and then click \u201cRegister Application\u201d Note your Client ID and Client Secret , and record for later use. Configuration To start to configure Github OAuth Provider, once you logged into Portainer, click Settings and then authentication . After that, select OAuth option and then, select Github . Define the following information and click Save settings . Client ID Client Secret Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Notes Contribute to these docs","title":"Github"},{"location":"v2.0-be/auth/oauth-google/","text":"Google OAuth Provider Portainer Business can be connected to Google OAuth provider in an easy way without need to understand complex configuration. Requirements You will need to have the following info handy before configuring OAuth using Google Provider. Client ID : Public identifier of the OAuth Application. Client Secret : The secret of this client. You can obtain these details by following the steps below: Login to your Google Cloud Portal (console.cloud.google.com) as an Admin Click on \u201cSelect Project\u201d, then select your Org, and then select \u201cNEW PROJECT\u201d Give the project a name, such as portainer-login, and then click \u201cCreate\u201d Wait for the project to be created (30 seconds), and then click on the navigation bar, and select \u201cAPIs & Services\u201d, Credentials. Select the drop down list in the header bar, and change the focus to the \u201cportainer-login\u201d project Click on \u201cOAuth consent screen\u201d Change the application type to \u201cInternal\u201d In the \u201cApplication name\u201d input box, enter the project name \u201cportainer-login\u201d Scroll down to authorised domains, and enter in the FQDN of the server that hosts your Portainer instance (in our case, test.portainer.io) Click Save. Click on \u201cCredentials\u201d, and then \u201cOAuth Client ID\u201d Select \u201cWeb Application\u201d as the Application Type, In the \u201cName\u201d input box, enter the project name \u201cportainer-login\u201d In the \u201cJavascript Origins\u201d and \u201cRedirect URI\u201d text boxes, enter in the FDQN and Port of your Portainer instance Click \u201cCreate\u201d You will now be presented with your API tokens, copy Client ID and Client Secret for later use (note be careful with trailing spaces as the auto-copy adds a trailing space, which breaks things) Configuration To start to configure Google OAuth Provider, once you logged to Portainer, click Settings and then authentication . After that, select OAuth option and then, select Google . Define the following information and click Save settings . Client ID Client Secret Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Notes Contribute to these docs","title":"Google"},{"location":"v2.0-be/auth/oauth-ms/","text":"Microsoft OAuth Provider Requirements You will need to have the following info handy before configuring OAuth using Microsoft Provider. Tenant ID : ID of the Azure Directory you wish to authenticate against. Also known as the Directory ID. Application ID : Public identifier of the OAuth application. Application key : The secret of this Application. You can obtain these details by following the steps below: Login to your Azure Portal as an Admin Retrieve your Tenant ID / Directory ID; Click on \u201cAzure Active Directory\u201d, and then Click on \u201cProperties\u201d, and then note your Directory ID for later use. Define your Portainer Instance Still in Azure Active Directory, Click on App Registrations Click on \u201c+ New Application Registration\u201d Enter in a friendly name for the Portainer Instance Keep the app type as Web App / API In the \u201cSign-on URL\u201d field, enter the FQDN or IP address that your Portainer instance listens on. Retrieve the Application ID After creating the app, the screen below is displayed; record the Application ID for later use Create The Application login key Click on \u201cSettings\u201d, then \u201cKeys\u201d Under the \u201cPasswords\u201d section, create a new key called \u201clogin\u201d, set the Duration to \u201cnever expires\u201d, and then click Save. The Key will then be generated for you. Note this Application Key Value for later use. Configuration To start to configure Microsoft OAuth Provider, once you logged into Portainer, click Settings and then authentication . After that, select OAuth option and then, select Microsoft . Here, you only need to define the following information: Tenant ID Application ID Application key Click Save Settings and you're done. Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Notes Contribute to these docs","title":"Microsoft"},{"location":"v2.0-be/auth/oauth/","text":"OAuth authentication Portainer Business Edition can be connected to several OAuth providers in an easy way without need to understand complex configurations. Microsoft OAuth Provider To start to configure Microsoft OAuth Provider, once you logged to Portainer, click in Settings and then in authentication . After that, select OAuth option and then, do select Microsoft . Here, you only need to define the following information: Tenant ID: ID of the Azure Directory you wish to authenticate against. Also known as the Directory ID. Application ID: Public identifier of the OAuth application. Application key: The secret of this Application. Do a click in save and you're done. Google OAuth Provider To start to configure Google OAuth Provider, once you logged to Portainer, click in Settings and then in authentication . After that, select OAuth option and then, do select Google . Define the following information and do a click in Save settings . Client ID: Public identifier of the OAuth Application. Client Secret: The secret of this client. Github To start to configure Github OAuth Provider, once you logged to Portainer, click in Settings and then in authentication . After that, select OAuth option and then, do select Github . Define the following information and do a click in Save settings . Client ID: Public identifier of the OAuth Application. Client Secret: The secret of this client. Custom OAuth Provider To configure a custom OAuth provider, once you logged to Portainer, click in Settings and then in authentication . After that, select custom option. In this screen, you need to configure the data that you OAuth provider give you to configure Portainer. The fields are: Automatic User Provisioning: Toggle on these options if you want to create users for each user logged using OAuth. After enable the toggle, you need to define in wich team that users should be created. Client ID: This is the public identifier of the OAuth application. Client Secret: Here, you need fill with the token access to the OAuth Application. Authorization URL: URL used to authenticate against the OAuth provider. Will redirect the user to the OAuth provider login view. Access Token URL: URL used to authenticate against the OAuth provider. Will redirect the user to the OAuth provider login view. Resource URL: URL used by Portainer to retrieve information about the authenticated user. Redirect URL: URL used by the OAuth provider to redirect the user after successful authentication. Should be set to your Portainer instance URL. User Identifier: Identifier that will be used by Portainer to create an account for the authenticated user. Retrieved from the resource server specified via the Resource URL field. Scopes: Required by the OAuth provider to retrieve information about the authenticated user. Refer to your OAuth provider documentation for more information about this. Once that all fields are completed, do a click in Save Settings Manage access to OAuth Team and Users To understand how to enable access to OAuth Teams and Users, please, refer to this article . Notes Contribute to these docs","title":"OAuth authentication"},{"location":"v2.0-be/backup/backup/","text":"Backup Portainer Backup and Restore feature is introduced in Portainer Business Version 2.4 Backup includes all information that Portainer stores on the /data volume, archived in a tar.gz file and optionally encrypted with a provided password. This archive is all you need to restore Portainer. Logged in as an Admin, you will find the Backup option under Settings menu in Portainer. You have several options for backups; i.e., Backup to local disk, Manual Backup to S3 and Automated Scheduled Backups to S3. Backup to Local Disk Login as an Admin User into Portainer Click on Settings in the menu Scroll down to Backup Portainer Option Download backup file is the default option, you can toggle the Password protect on and enter a password to encrypt the backup file Click on Download backup A tar.gz file will be downloaded through your browser. Manual Backup to S3 Login as an Admin User into Portainer Click on Settings in the menu Scroll down to Backup Portainer Option Select Store in S3 option Enter Access Key ID, Secret Access Key, Region and Bucket name for your S3 storage Optionally, Enable Password protect and enter a password to protect the backup (recommended) Click Export backup to export the backup file to S3 Bucket Scheduled Backups to S3 Login as an Admin User into Portainer Click on Settings in the menu Scroll down to Backup Portainer Option Select Store in S3 option Enable Schedule automatic backups and enter a Cron rule for your schedule Enter Access Key ID, Secret Access Key, Region and Bucket name for your S3 storage Optionally, Enable Password protect and enter a password to protect the backup (recommended) Click Save backup settings to save the schedule. Notes Contribute to these docs","title":"Backup"},{"location":"v2.0-be/backup/restore/","text":"Restore Portainer Backup and Restore feature is introduced in Portainer Business Version 2.4 Restore could be only performed on a fresh instance of Portainer, during its' initialization stage. When you need to restore portainer, deploy a fresh instance of Portainer with an empty data volume and choose the Restore Portainer from backup option on the initialization page of the new instance. You can perform a restore from either a file available locally or direct from S3 bucket. Restore from local file On the initialization page, expand Restore Portainer from backup option Click on Select file , browse to and select the tar.gz backup file Enter the password if the backup was originally encrypted Click Restore Portainer Restore may take a few moments. Once complete you will be redirected to the login page. You should now be able to login with your previous credentials. All your Portainer config should be restored. Restore from S3 On the initialization page, expand Restore Portainer from backup option Click on Retrieve from S3 option Enter the details to retrieve backup file from S3 bucket Enter the password if the backup was originally encrypted Click Restore Portainer Restore may take a few moments. Once complete you will be redirected to the login page. You should now be able to login with your previous credentials. All your Portainer config should be restored. Notes Contribute to these docs","title":"Restore"},{"location":"v2.0-be/configs/add/","text":"Add configs Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Adding Configs To add configs to Portainer click Configs and then Add config . Then, in the Editor, you need to write your configuration. In this example, you can see an nginx configuration file. Once this config is defined, you can add labels and/or manage access control of this config. When everything is set, click Create config . Notes Contribute to these docs","title":"Add custom configs"},{"location":"v2.0-be/configs/delete/","text":"Delete Configs From Portainer you can delete the configs that you created before. Deleting Configs To delete a config, go to Configs , select the config you want to delete and click Remove . Notes Contribute to these docs","title":"Delete configs"},{"location":"v2.0-be/containers/console/","text":"Access to a Container console Adjusting or editing containers can be done through the console. Accesing to container console To access to a specific container console, go to Containers and select the container you want. Then click Console . Select your command and the user you want to allow access for. If you're using an Alpine Linux container, you need to change your command from the list and pick /bin/ash. If successful, you will see the console and you can run commands like any other Linux system. Notes Contribute to these docs","title":"Access container console"},{"location":"v2.0-be/containers/create/","text":"New Containers Portainer allows you to deploy a new container direct from the UI with no code required. Deploying a New Container First select the Endpoint you want to add a container to, then select Containers from the side menu before clicking Add Container . Add details to your container: Name: Friendly name for your container Registry: Where your image is hosted Image: The name of the image you want to deploy Ports: Expose the desired ports Advanced Settings: Many options available here to customise the deploymeny from volume and environment configuration to capabilities Once complete, click Deploy the Container . If successful your container will be shown in the Container List. Notes Contribute to these docs","title":"Create New Container"},{"location":"v2.0-be/containers/delete/","text":"Delete/Remove a container In Portainer, you can Remove/Delete containers in simply and easily. Deleting Containers To delete a container, click Containers , then check the container you want delete and select Remove A pop-up will ask for confirmation, and ask you decide if you want to automatically the non-persistent volumes . Once you selection has been made, click Remove If successfully removed, a pop up will confirm this. Notes Contribute to these docs","title":"Delete/Remove a Container"},{"location":"v2.0-be/containers/duplicate-edit/","text":"Duplicate or Edit Containers In Portainer you have the ability to duplicate and / or edit your containers. Duplicate a running container To duplicate a container, click Containers and then select the container you want to duplicate. Click Duplicate/Edit . Change the settings you need, in this example I have changed the name of the container and published a random port, the port exposed by the container by default. When all the changes needed are done, click Deploy the Container If everything worked as expected, you will see your duplicate container in the containers list. Edit a container You can change: * The command & logging options, * volumes, * Networks, * Environment Variables, * Labels, * Restart Policy, * Runtime & Resources and * Capabilites. To change a running container, you need to click Containers , Choose the container you want to change. Click Duplicate/edit . Scrolldown to the bottom of the page and you will see the options to configure to this container. When the changes are made, click Deploy Container . You will see a warning about removing and re-creating the current container with the new settings. If everything works as expected, you will see a pop up confirming the creation of the new container with the new settings and the removal of the old one. Notes Contribute to these docs","title":"Duplicate or Edit a Container"},{"location":"v2.0-be/containers/inspect/","text":"Inspect a Container Inspecting a container allows you to view information about your container, such as networking settings, volumes, images, etc. Inspecting a Container To inspect a container, click Containers , select your container and click the Inspect button. Here, you can view all the information of this container. Clicking on a category will show more information if available. Notes Contribute to these docs","title":"Inspect a Container"},{"location":"v2.0-be/containers/logs/","text":"View Containers Logs Viewing container logs is one of the most important features for troubleshooting and investigation. Viewing Containers Logs To view a container logs, click Containers and then select your container. Then click Logs In the following screen, you will see a few options: Auto-refresh logs: Disabling this option allows you to pause the logs collection process and the auto-scrolling. Wrap lines: To allow easier reading of long lines of logs. Display timestamps: this options is useful when you need to find specific time and date logs. Fetch: This option allows you to filter the logs by day, hours or minutes. Search: You can find specific words in the logs, very useful for finding specific errors. Lines: Specify how many lines you want to the see in the logs; default is 100. Actions: You can copy all the logs displayed or a select number of lines. Notes Contribute to these docs","title":"View logs"},{"location":"v2.0-be/containers/ownership/","text":"Change Container Ownership Portainer allows you to to limit the usage of resources to certains teams or users from the GUI. Changing Container Ownership To change your container ownership, click in Containers , pick the container you want to change the ownership. Scroll down to Access Control section and click Change Ownership . You will see three options: Administrators: This resource is only managed by Portainer Administrators. Restricted: Use this option when you want to restrict this resource to a specific Team or User. Public: Use this options if you want that anyone that had access to the endpoint can manage this container. After you define the ownership, click Update Ownership . You will be presented with a warning: If everything works as expected, you will see a pop up confirming your updates: After that, you can view your ownership settings applied in the container: Notes Contribute to these docs","title":"Change Container Ownership"},{"location":"v2.0-be/containers/stats/","text":"View Container Stats Stats are very important to understand the resource consumption of yours containers. In Portainer, you are able to monitor this from the UI. Viewing Container Stats First Click Containers , select the container you want to see the stats. Then click Stats Here, you can view a very comprehensive list of consumption stats: Memory Usage CPU Usage Network Usage: RX and TX Process running in the container Refresh Rate: You can configure time intervals to get new stats data. Notes Contribute to these docs","title":"View Container stats"},{"location":"v2.0-be/deploy/beinstalldocker/","text":"Deploying Portainer Business in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. If you are using Docker Swarm, please refer to the Swarm-specific installation instructions . Regardless of your configuration, you will need: The latest version of Docker installed and working. You can refer to the Docker documentation for platform-specific instructions. Administrator or sudo access on the machine that will host your Portainer instance. If you are using Docker Desktop on Windows you need to enable WSL2 if you need to run Linux containers. By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Portainer Deployment Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Docker on Linux Portainer Server Deployment docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.0.0 Docker on Windows WSL / Docker Desktop Before you can deploy Portainer in Docker Standalone running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Portainer Server Deployment docker volume create portainer_data docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest Portainer Agent Only Deployment Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.0.0 Docker on Windows Container Service To run Portainer in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands: netsh advfirewall firewall add rule name = \"cluster_management\" dir = in action = allow protocol = TCP localport = 2377 netsh advfirewall firewall add rule name = \"node_communication_tcp\" dir = in action = allow protocol = TCP localport = 7946 netsh advfirewall firewall add rule name = \"node_communication_udp\" dir = in action = allow protocol = UDP localport = 7946 netsh advfirewall firewall add rule name = \"overlay_network\" dir = in action = allow protocol = UDP localport = 4789 netsh advfirewall firewall add rule name = \"swarm_dns_tcp\" dir = in action = allow protocol = TCP localport = 53 netsh advfirewall firewall add rule name = \"swarm_dns_udp\" dir = in action = allow protocol = UDP localport = 53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. Once it has restarted you're ready to deploy Portainer. Portainer Server Deployment docker volume create portainer_data docker run -d -p 9000 : 9000 - -name portainer - -restart always -v \\\\.\\ pipe \\ docker_engine :\\\\.\\ pipe \\ docker_engine -v portainer_data : C :\\ data portainer / portainer-ee : latest Now you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Portainer Agent Only Deployment To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001 : 9001 - -name portainer_agent - -restart = always -v \\\\.\\ pipe \\ docker_engine :\\\\.\\ pipe \\ docker_engine portainer / agent : 2 . 0 . 0 Advanced Options CLI Configuration Options Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command if you have installed apache2-utils package: htpasswd -nb -B admin \"your-password\" | cut -d \":\" -f 2 If your system does not have the mentioned command, you can run a container to run the command: docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"your-password\" | cut -d \":\" -f 2 To specify the admin password from the command line, start Portainer with the --admin-password flag: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --admin-password = '$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: Add your password to a file, for example with the following command: echo -n mypassword > /tmp/portainer_password Now you can start the Portainer container by running: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ce --admin-password-file /tmp/portainer_password This works well with Docker Swarm and Docker secrets too: echo -n mypassword | docker secret create portainer-pass - docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000 :9000 \\ --publish 8000 :8000 \\ --replicas = 1 \\ --constraint 'node.role == manager' \\ --mount type = bind,src = /var/run/docker.sock,dst = /var/run/docker.sock \\ portainer/portainer-ce \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): docker run -d --label owner = acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme Note that the -l flag can be repeated multiple times to specify multiple labels: docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce -l owner = acme -l service = secret Use your own logo If you wish to replace our logo with your own, you can specify an external logo (it must be exactly 155px by 55px) using the --logo flag : docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" This can also be updated via the GUI in the Portainer Settings menu. Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you\u2019ll need to clear any existing templates (default templates) via the user interface or the HTTP API. Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. docker run -d -p 9000 :9000 -p 8000 :8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce --templates http://my-host.my-domain/templates.json The template file must be accessible from Portainer without authentication. We suggest hosting the template files on Github . Available flags The following CLI flags are available: --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind, -p : Address and port to serve Portainer (default: :9000) --data, -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --edge-compute : Automatically enable edge-compute features --hide-label, -l : Hide containers with a specific label in the UI --host, -H : Docker daemon endpoint --logo : URL to an image to be displayed as a logo in the UI. Uses the Portainer logo if not specified --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s, 5m, 1h\u2026 as supported by the time.ParseDuration method (default: 5m) --ssl : Secure Portainer instance using SSL (default: false) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt, C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key, C:\\certs\\portainer.key on Windows) --templates, -t : URL to templates (apps) definitions --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem, C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem, C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001 Notes Contribute to these docs","title":"Docker"},{"location":"v2.0-be/deploy/beinstallk8s/","text":"Deploying Portainer Business in Kubernetes Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight containers on Kubernetes. There are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Regardless of your configuration, you will need: A working and up to date Kubernetes cluster Access to run Helm or kubectl commands on your cluster Cluster Admin rights on your Kubernetes cluster. This is so Portainer can create the necessary ServiceAccount and ClusterRoleBinding for it to access the Kubernetes cluster. A default StorageClass configured (see below) By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Access Control & RBAC Kubernetes RBAC needs to enabled and working for Access Control to work properly in Portainer. Portainer Deployment Pre-Req Note: Portainer requires data persistence, and as a result needs at least one storage-class available to use. Portainer will attempt to use the \"default\" storage class during deployment. If you do NOT have a storage class tagged as \"default\" the deployment will likely fail. You can check if you have a default storage class by running: kubectl get sc and looking for a storage class with (default) after its name: kubectl patch storageclass <storage-class-name> -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' and replace with the name of your storage class Example: kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Alternatively, if installing using our helm chart you can add the following option with helm install: --set persistence.storageClass = <storage-class-name> To deploy Portainer within a Kubernetes cluster, you can either use our HELM chart, or our provided manifests. Deploy using Helm Portainer Server Deployment Ensure you're using at least Helm v3.2, which includes support for the --create-namespace argument. First, add the Portainer helm repo running the following: helm repo add portainer https://portainer.github.io/k8s/ helm repo update Based on how you would like to expose the Portainer service, select an option below: NodePort Using the following command, Portainer will be available on port 30777. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled = true Ingress Using the following command, the Portainer service will be assigned a Cluster IP. You should use this with an Ingress, see Chart Configuration Options for Ingress related options. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled = true \\ --set service.type = ClusterIP Example Deployment with Nginx Ingress helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled = true \\ --set service.type = ClusterIP \\ --set ingress.enabled = true \\ --set ingress.annotations. 'kubernetes\\.io/ingress\\.class' = nginx \\ --set ingress.hosts [ 0 ] .host = portainer.example.io \\ --set ingress.hosts [ 0 ] .paths [ 0 ] .path = \"/\" LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled = true \\ --set service.type = LoadBalancer Chart Configuration Options The following table lists the configurable parameters of the Portainer chart and their default values. The values file can be found under deploy/helm/portainer/values.yaml . The parameters will be keep updating. Parameter Description Default replicaCount Number of Portainer service replicas (ALWAYS set to 1) 1 image.repository Portainer Docker Hub repository portainer/portainer-ce image.tag Tag for the Portainer image latest image.pullPolicy Portainer image pulling policy IfNotPresent imagePullSecrets If Portainer image requires to be in a private repository nil nodeSelector Used to apply a nodeSelector to the deployment {} serviceAccount.annotations Annotations to add to the service account null serviceAccount.name The name of the service account to use portainer-sa-clusteradmin service.type Service Type for the main Portainer Service; ClusterIP, NodePort and LoadBalancer LoadBalancer service.httpPort HTTP port for accessing Portainer Web 9000 service.httpNodePort Static NodePort for accessing Portainer Web. Specify only if the type is NodePort 30777 service.edgePort TCP port for accessing Portainer Edge 8000 service.edgeNodePort Static NodePort for accessing Portainer Edge. Specify only if the type is NodePort 30776 service.annotations Annotations to add to the service {} ingress.enabled Create an ingress for Portainer false ingress.annotations Annotations to add to the ingress. For instane, kubernetes.io/ingress.class: nginx {} ingress.hosts.host URL for Portainer Web. For instance, portainer.example.io nil ingress.hosts.paths.path Path for the Portainer Web. / ingress.hosts.paths.port Port for the Portainer Web. 9000 ingress.tls TLS support on ingress. Must create a secret with TLS certificates in advance [] resources Portainer resource requests and limits {} persistence.enabled Whether to enable data persistence true persistence.existingClaim Name of an existing PVC to use for data persistence nil persistence.size Size of the PVC used for persistence 10Gi persistence.annotations Annotations to apply to PVC used for persistence {} persistence.storageClass StorageClass to apply to PVC used for persistence default persistence.accessMode AccessMode for persistence ReadWriteOnce persistence.selector Selector for persistence nil Portainer Agent Only Deployment Helm charts for Agent Only Deployments will be available soon. In the meantime please head over to YAML Manifests tab. Deploy using YAML Manifests Portainer Server Deployment Based on how you would like to expose the Portainer Service, select an option below: NodePort Using the following command, Portainer will be available on port 30777. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Portainer Agent Only Deployment Choose one of the tabs below based on how you would like to expose the agent. NodePort Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on port 30778. kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-nodeport-ee.yaml LoadBalancer Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on LoadBalancer assigned IP @ port 9001 kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-lb-ee.yaml Deploy on Windows WSL / Docker Desktop You can deploy Portainer in a Kubernetes environment in Windows using Docker Desktop. Note This scenario is for testing purpose only. Enable Kubernetes in Docker Desktop To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right click the Docker icon in the system tray and click \"dashboard\" Click Settings: Select Kubernetes 2. Select 'Enable Kubernetes' 3. Click 'Apply and Restart'. After a few minutes, you will see that Kubernetes is running: Portainer Server Deployment Based on how you would like expose the Portainer Service, select an option below: NodePort Using the following command, Portainer will be available on port 30777. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml LoadBalancer Using the following command, Portainer will be available at an assigned LoadBalancer IP @ port 9000. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Portainer Agent Only Deployment Choose one of the tabs below based on how you would like to expose the agent. NodePort Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on port 30778. kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-nodeport-ee.yaml LoadBalancer Run the following command to deploy the Agent in your Kubernetes Cluster, agent will be available on LoadBalancer assigned IP @ port 9001 kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-lb-ee.yaml Regarding Persisting Data The charts/manifests will create a persistent volume for storing Portainer data, using the default StorageClass. In some Kubernetes clusters (for example microk8s), the default StorageClass simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, \"leaving\" all the persistent data behind and starting the pod with an \"empty\" volume. While this behaviour is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively \"pins\" the Portainer pod to a particular node. The nodeSelector can be added in the following ways: Edit your own values.yaml and set the value of nodeSelector: nodeSelector: kubernetes.io/hostname: \\<YOUR NODE NAME> Explicitly set the target node when deploying/updating the Helm chart on the CLI, by including --set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME> If you've deployed Portainer via manifests, without Helm, run the following one-liner to \"patch\" the deployment, forcing the pod to always be scheduled on the node it's currently running on: kubectl patch deployments -n portainer portainer -p '{\"spec\": {\"template\": {\"spec\": {\"nodeSelector\": {\"kubernetes.io/hostname\": \"'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'\"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1) Notes Contribute to these docs","title":"Kubernetes"},{"location":"v2.0-be/deploy/beinstallswarm/","text":"Deploying Portainer Business in Docker Swarm Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Regardless of your configuration, you will need: The latest version of Docker installed and working, with swarm mode enabled and your nodes added. You can refer to the Docker documentation for platform-specific instructions. Administrator or sudo access on the machine that will host the Portainer Server service. Administrator or sudo access on the machines where you will deploy the Portainer Agent if you need to add more endpoints to your Portainer instance. By default, Portainer will expose the UI over port 9000 and expose a TCP tunnel server over port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. To learn more about the requirements please visit the requirements page. Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Portainer Deployment Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Docker Swarm on Linux Portainer Server Deployment Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. curl -L https://downloads.portainer.io/portainer-ee-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Note : By default this stack doesn't enable Host Management Features, you need to enable from the UI of Portainer. Portainer Agent Only Deployment Deploy Portainer Agent on a remote LINUX Swarm Cluster as a Swarm Service, run this command on a manager node in the remote cluster. First create the network: docker network create --driver overlay --attachable portainer_agent_network The following step to deploy the Agent: docker service create --name portainer_agent --network portainer_agent_network --publish mode = host,target = 9001 ,published = 9001 -e AGENT_CLUSTER_ADDR = tasks.portainer_agent --mode global --mount type = bind,src = //var/run/docker.sock,dst = /var/run/docker.sock --mount type = bind,src = //var/lib/docker/volumes,dst = /var/lib/docker/volumes --mount type = bind,src = /,dst = /host portainer/agent:2.4.0 Docker Swarm on Windows WSL / Docker Desktop Before you can deploy Portainer in Docker Swarm running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker Swarm commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used: Portainer Server Deployment Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploys the Portainer Agent as a global service on every node in your cluster. Remember to initiate the Docker Swarm mode when you use Docker Desktop. You can do this running the following command: docker swarm init The terminal will reply with this: Swarm initialized: current node ( 15gbf4d66mvzk3die00sgirpf ) is now a manager. To add a worker to this swarm, run the <code>swarm join</code> command that is provided when initializing the swarm ( it will look similar to the following ) : docker swarm join --token SWMTKN-1-096qbnf2b9yywagu5ht3731zlpkeqazgctffolntsiljfp0m34-c4snnxplgwq2bd1ohta8k48b9 192 .168.65.3:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. Once this is done, you can continue with the installation by running the following command: curl -L https://downloads.portainer.io/portainer-ee-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Portainer Agent Only Deployment First create the network: docker network create --driver overlay --attachable portainer_agent_network To deploy Portainer Agent on a Swarm Cluster as a Swarm Service, run this command in a manager node in the cluster: docker service create --name portainer_agent --network portainer_agent_network --publish mode = host,target = 9001 ,published = 9001 -e AGENT_CLUSTER_ADDR = tasks.portainer_agent --mode global --mount type = bind src = //var/run/docker.sock,dst = /var/run/docker.sock --mount type = bind,src = //var/lib/docker/volumes,dst = /var/lib/docker/volumes \u2013-mount type = bind,src = /,dst = /host portainer/agent:2.4.0 Docker Swarm on Windows Container Service To run Portainer in a Windows Server/Desktop Environment, you need to create exceptions in the firewall. These can be easily added through PowerShell by running the following commands: netsh advfirewall firewall add rule name = \"cluster_management\" dir = in action = allow protocol = TCP localport = 2377 netsh advfirewall firewall add rule name = \"node_communication_tcp\" dir = in action = allow protocol = TCP localport = 7946 netsh advfirewall firewall add rule name = \"node_communication_udp\" dir = in action = allow protocol = UDP localport = 7946 netsh advfirewall firewall add rule name = \"overlay_network\" dir = in action = allow protocol = UDP localport = 4789 netsh advfirewall firewall add rule name = \"swarm_dns_tcp\" dir = in action = allow protocol = TCP localport = 53 netsh advfirewall firewall add rule name = \"swarm_dns_udp\" dir = in action = allow protocol = UDP localport = 53 You also need to install Windows Container Host Service and install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. After it has restarted, you're ready to deploy Portainer. Portainer Server Deployment You can use our YML manifest to run Portainer in Windows using Windows Containers. In Powershell, run: curl https :// downloads . portainer . io / portainer_ee_windows_stack . yml -o portainer_windows_stack . yml docker stack deploy - -compose -file = portainer_windows_stack . yml portainer Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Portainer Agent Only Deployment To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: curl -L https :// downloads . portainer . io / agent-ee-stack-windows . yml -o agent-stack-windows . yml && docker stack deploy - -compose -file = agent-stack-windows . yml portainer-agent Notes Contribute to these docs","title":"Docker Swarm"},{"location":"v2.0-be/deploy/cli/","text":"CLI Configuration Options Portainer can be easily tuned using CLI flags. Admin password From the command line Portainer allows you to specify a bcrypt encrypted password from the command line for the admin account. You need to generate the bcrypt encrypted password first. You can generate the encrypted password with the following command if you have installed apache2-utils package: htpasswd -nb -B admin \"your-password\" | cut -d \":\" -f 2 If your system does not have the mentioned command, you can run a container to run the command: docker run --rm httpd:2.4-alpine htpasswd -nbB admin \"your-password\" | cut -d \":\" -f 2 s To specify the admin password from the command line, start Portainer with the --admin-password flag: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:latest --admin-password='$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u' Inside a file You can also store the plaintext password inside a file and use the --admin-password-file flag: Add your password to a file running the following command: echo -n mypassword > /tmp/portainer_password Now you can start the Portainer container by running: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ee:latest --admin-password-file /tmp/portainer_password This works well with Docker Swarm and Docker secrets too: echo -n mypassword | docker secret create portainer-pass - docker service create \\ --name portainer \\ --secret portainer-pass \\ --publish 9000:9000 \\ --publish 8000:8000 \\ --replicas=1 \\ --constraint 'node.role == manager' \\ --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\ portainer/portainer-ee:latest \\ --admin-password-file '/run/secrets/portainer-pass' \\ -H unix:///var/run/docker.sock Note: This will automatically create an administrator account called admin with the specified password. Hiding specific containers Portainer allows you to hide containers with a specific label by using the -l flag. For example, take a container started with the label owner=acme (note that this is an example label, you can define your own labels): docker run -d --label owner=acme nginx To hide this container, simply add the -l owner=acme option on the CLI when starting Portainer: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:latest -l owner=acme Note that the -l flag can be repeated multiple times to specify multiple labels: docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:latest -l owner=acme -l service=secret Use your own logo You do not like our logo? Want to make Portainer more corporate? Don\u2019t worry, you can easily switch for an external logo (it must be exactly 155px by 55px) using the --logo flag : docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:latest --logo \"https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg\" This can also be completed via the GUI in the Portaner Settings menu Use your own templates Portainer allows you to rapidly deploy containers using App Templates. By default Portainer templates will be used but you can also define your own templates. Note: at the moment, templates are only loaded once at first Portainer startup. If you already deployed a Portainer instance and want to use your own templates after this, you\u2019ll need to clear any existing templates (default templates) via the HTTP API. Using the --templates flag you can specify an URL where the template file can be accessed via HTTP. docker run -d -p 9000:9000 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:latest --templates http://my-host.my-domain/templates.json Suggestion: You can host your template files in Github Available flags The following CLI flags are available: --assets : Path to the assets --admin-password : Specify a bcrypt hashed password for the admin user --admin-password-file : Path to the file containing the password for the admin user --bind, -p : Address and port to serve Portainer (default: :9000) --data, -d : Directory where Portainer data will be stored (default: /data on Linux, C:\\data on Windows) --edge-compute : Automatically enable edge-compute features --hide-label, -l : Hide containers with a specific label in the UI --host, -H : Docker daemon endpoint --logo : URL to a picture to be displayed as a logo in the UI, use Portainer logo if not specified --no-analytics : Disable Analytics in app (deprecated) --rollback-to-ce : Rollback the database store to CE --snapshot-interval : Time interval between two endpoint snapshot jobs expressed as a string, e.g. 30s, 5m, 1h\u2026 as supported by the time.ParseDuration method (default: 5m) --ssl : Secure Portainer instance using SSL (default: false) --sslcert : Path to the SSL certificate used to secure the Portainer instance (default: /certs/portainer.crt, C:\\certs\\portainer.crt on Windows) --sslkey : Path to the SSL key used to secure the Portainer instance (default: /certs/portainer.key, C:\\certs\\portainer.key on Windows) --templates, -t : URL to templates (apps) definitions --tlscacert : Path to the CA (default: /certs/ca.pem on Linux, C:\\certs\\ca.pem on Windows) --tlscert : Path to the TLS certificate file (default: /certs/cert.pem, C:\\certs\\cert.pem on Windows) --tlskey : Path to the TLS key (default: /certs/key.pem, C:\\certs\\key.pem on Windows) --tlsverify : TLS support (default: false) --tunnel-port : Specify an alternate tunnel port to use with the Edge agent. Use --tunnel-port 8001 with -p 8001:8001 to make the Edge agent communicate on port 8001 Notes Contribute to these docs","title":"CLI Configuration Options"},{"location":"v2.0-be/deploy/initial/","text":"Initial Set Up Once Portainer is deployed and you have navigated to http://ip-server:9000, you will see the following screens. Set Password Admin The first thing to do is set a password for the admin user. This password needs to be at least eight characters long. Collection of statistics We anonymously collect information about how Portainer is used via a tool called Matomo. You can disable this option, but we recommend leaving it activated. This will help us understand how our users use Portainer and improve it. You can read more about our privacy policy here You can enable or disable this using the checkbox shown: This can be changed at any time via the Portainer Settings screen License Registration In order to activate Portainer Business Edition, you need to provide a Portainer Business Edition valid license. Enter the license and do a click in Submit . If you need to add more licenses, you can do it later from the menu, click in the options Licenses . If everything work as expected, the next step is connect Portainer to the initial endpoint. Connect Portainer to the container environment If you installed Portainer in Kubernetes you would choose Kubernetes, but if you installed in Docker , you may want choose manage the local Docker environment. Once the appropriate option is selected, click connect. If everything works as expected, You will then be shown the Portainer home page. Notes Contribute to these docs","title":"Initial Setup"},{"location":"v2.0-be/deploy/linux/","text":"Deploy Portainer in Linux environments Deploy Portainer in Kubernetes To deploy Portainer within a Kubernetes cluster, you can either use our HELM chart, or our provided manifests. Pre-Req Note: Portainer requires data persistence, and as a result needs at least one storage-class available to use. Portainer will attempt to use the \"default\" storage class during deployment. If you do NOT have a storage class tagged as \"default\" the deployment will likely fail. You can check if you have a default storage class by running: > kubectl get sc and looking for a storage class with (default) after its name: If you want to make a storage class the default, you can type the command: >kubectl patch storageclass -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' and replace with the name of your storage class (eg: kubectl patch storageclass local-path -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}' Alternatively, if you are using HELM you can use: --set persistence.storageClass= Using Helm Ensure you're using at least helm v3.2, which includes support for the --create-namespace argument. First, add the Portainer helm repo running the following: helm repo add portainer https://portainer.github.io/k8s/ helm repo update For NodePort Using the following command, Portainer will run at port 30777. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled=true For Load Balancer Using the following command, Portainer will run at port 9000. helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled=true \\ --set service.type=LoadBalancer For Ingress helm install --create-namespace -n portainer portainer portainer/portainer \\ --set enterpriseEdition.enabled=true \\ --set service.type=ClusterIP Using YAML Manifest For NodePort Using the following command, Portainer will run at port 30777. kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Note about Persisting Data The charts/manifests will create a persistent volume for storing Portainer data, using the default StorageClass. In some Kubernetes clusters (microk8s), the default Storage Class simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, \"leaving\" all the persistent data behind and starting the pod with an \"empty\" volume. While this behaviour is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively \"pins\" the portainer pod to a particular node. The nodeSelector can be added in the following ways: Edit your own values.yaml and set the value of nodeSelector like this: nodeSelector: kubernetes.io/hostname: <YOUR NODE NAME> Explicictly set the target node when deploying/updating the helm chart on the CLI, by including --set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME> If you've deployed Portainer via manifests, without Helm, run the following one-liner to \"patch\" the deployment, forcing the pod to always be scheduled on the node it's currently running on: kubectl patch deployments -n portainer portainer -p '{\"spec\": {\"template\": {\"spec\": {\"nodeSelector\": {\"kubernetes.io/hostname\": \"'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'\"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1) Deploy Portainer in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine or within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Note that the recommended deployment mode when using Swarm is using the Portainer Agent. To see the requeriments, please, visit the page of requirements Docker Standalone Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see Portainer and agent scenario below): docker volume create portainer_data docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest Docker Swarm Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster. curl -L https://downloads.portainer.io/portainer-ee-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Note : By default this stack doesn't enable Host Management Features, you need to enable from the UI of Portainer. Portainer Agent Deployments Only Docker Standalone Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.0.0 Note: --tlsskipverify has to be present when deploy an agent and the certs in the agent is not a supported scenario at this moment. Docker Swarm Deploy Portainer Agent on a remote LINUX Swarm Cluster as a Swarm Service, run this command on a manager node in the remote cluster. docker network create portainer_agent_network docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mode global --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes --mount type=bind,src=/,dst=/host portainer/agent:2.0.0 Note: --tlsskipverify has to be present when deploy an agent and the certs in the agent is not a supported scenario at this moment. Notes Contribute to these docs","title":"Deploy Portainer in Linux environments"},{"location":"v2.0-be/deploy/requirements/","text":"Requirements Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine. By default, Portainer will expose the UI over the port 9000 and expose a TCP tunnel server over the port 8000 . The latter is optional and is only required if you plan to use the Edge compute features with Edge agents. Every single release of Portainer goes through an extensive testing process (functional tests, release tests, post release tests) to ensure that what we are creating actually works as expected. Obviously though, we cannot possibly test Portainer against every single configuration variant out there, so we have elected to test against just a subset. To try and alleviate confusion as to what we test against, we have documented the configurations that we personally validate as \"functional\"; any other variant is not tested (this does not mean it wont work, it just means its not tested). Validated Configurations Portainer Version Release Date Docker Version Kubernetes* Version Architectures Business 2.4 (latest) May 4, 2021 20.10.5 1.19 1.20.2 1.21 ARM64, x86_64 Business 2.0 Dec 3, 2020 19.03.13 1.17.13 1.18.6 1.19.3 ARM64, x86_64 *RBAC needs to be enabled on Kubernetes for Portainer Access Control Notes If you report a bug for a configuration that is not on the list above, we will ask you to first update your environment to match a validated configuration before continuing. Consumer Edition Validated Configurations can be found here Contribute to these docs","title":"Requirements"},{"location":"v2.0-be/deploy/ssl/","text":"Secure Portainer using SSL By default, Portainer\u2019s web interface and API is exposed over HTTP. This is not secure, Portainer recommends enabling SSL, particularly in a production environment. Securing Portainer using SSL with Docker To do so, you can use the following flags --ssl , --sslcert and --sslkey : $ docker run -d -p 443:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v ~/local-certs:/certs -v portainer_data:/data portainer/portainer-ee:latest --ssl --sslcert /certs/portainer.crt --sslkey /certs/portainer.key Now, you can navigate to https://$ip-docker-host Securing Portainer using SSL with Docker Swarm Securing Portainer on Docker Swarm is fairly simple. The following example takes in to asumption that you have an external overlay network and external secrets. If you do not, simply create them: Create the overlay network docker network create --driver overlay portainer Create the secrets docker secret create portainer.example.cer portainer.example.cert docker secret create portainer.example.key portainer.example.key More on Docker Networks: https://docs.docker.com/engine/reference/commandline/network_create/ More on Docker Secrets: https://docs.docker.com/compose/compose-file/#secrets version: '3.2' services: agent: image: portainer/agent:2.0.0 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - portainer deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ee:latest command: -H tcp://tasks.agent:9001 --tlsskipverify --ssl --sslcert /run/secrets/portainer.example.com.cer --sslkey /run/secrets/portainer.example.com.key ports: - \"9000:9000\" - \"8000:8000\" volumes: - /data/portainer:/data networks: - portainer deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] secrets: - portainer.example.com.cer - portainer.example.com.key networks: portainer: external: true secrets: portainer.example.com.cer: external: true portainer.example.com.key: external: true Notes Contribute to these docs","title":"Using SSL with Portainer"},{"location":"v2.0-be/deploy/windows10/","text":"Deploy Portainer in Windows 10 Deploy Portainer in Kubernetes through Docker Desktop. You can deploy Portainer in a Kubernetes environment in Windows using Docker Desktop. Note: This scenario is for testing purpose only. Enable Kubernetes in Docker Desktop To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right-click the Docker icon in the system tray and click \"dashboard\" Click Settings: Select Kubernetes 2. Select 'Enable Kubernetes' 3. Click 'Apply and Restart'. After a few minutes, you will see that Kubernetes is running: Deploy Portainer using YAML Manifest First create the Portainer namespace in your cluster kubectl create namespace portainer For NodePort kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml If everything work as expected, you can navigate to Portainer from the browser with the address http://localhost:30777 For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Deploy Portainer in Docker Portainer is comprised of two elements, the Portainer Server, and the Portainer Agent. Both elements run as lightweight Docker containers on a Docker engine or within a Swarm cluster. Due to the nature of Docker, there are many possible deployment scenarios, however, we have detailed the most common below. Please use the scenario that matches your configuration. Note that the recommended deployment mode when using Swarm is using the Portainer Agent. Please see the requirements page for further info . Docker Standalone in WSL2 Before you can deploy Portainer in Docker Standalone running in Windows, you need to install WSL. Read this guide to know more about WSL/WSL2 Use the following Docker commands to deploy the Portainer Server; note the agent is not needed on standalone hosts, however it does provide additional functionality if used (see portainer and agent scenario below): docker volume create portainer_data docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest Docker Swarm in WSL2 Deploying Portainer and the Portainer Agent to manage a Swarm cluster is easy! You can directly deploy Portainer as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploys the Portainer Agent as a global service on every node in your cluster. Remember to initiate the Docker Swarm mode when you use Docker Desktop. You can do this running the following command: docker swarm init The terminal will reply with this: Swarm initialized: current node (15gbf4d66mvzk3die00sgirpf) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-096qbnf2b9yywagu5ht3731zlpkeqazgctffolntsiljfp0m34-c4snnxplgwq2bd1ohta8k48b9 192.168.65.3:2377 To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. Once this is done, you can continue with the installation running the following command: curl -L https://downloads.portainer.io/portainer-ee-agent-stack.yml -o portainer-agent-stack.yml docker stack deploy -c portainer-agent-stack.yml portainer Docker Standalone using Windows Containers Another scenario is running Docker in Windows is running Windows Containers. This is a feature that has to be enabled. To do this, open a PowerShell window as administrator and run: Enable-WindowsOptionalFeature -Online -FeatureName containers -All Once this is done, you need to open a PowerShell console and run the following commands: docker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine -v portainer_data:C:\\data portainer/portainer-ee:latest Now, you can navigate to http://localhost:9000 and start using Portainer. Docker Swarm using Windows Containers You can use our YML manifest to run Portainer in Windows using Windows Containers. In a Powershell window, you must run: curl https://downloads.portainer.io/portainer_ee_windows_stack.yml -o portainer_windows_stack.yml docker stack deploy --compose-file=portainer_windows_stack.yml portainer Deploy Portainer Agent in Windows running WSL Docker Standalone Run the following command to deploy the Agent in your Docker host. docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:2.0.0 Docker Swarm Deploy Portainer Agent on a remote LINUX Swarm Cluster as a Swarm Service, run this command in a manager node in the remote cluster. docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent --mode global --mount type=bind src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \u2013-mount type=bind,src=/,dst=/host portainer/agent:2.0.0 Deploy Portainer Agent in Windows using Windows Containers. Docker standalone To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001:9001 --name portainer_agent --restart=always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine portainer/agent:2.0.0 Notes These deployments were tested in Windows 10 Pro 2004 edition. To use Windows Containers, you need to run Windows 10 ver 1803 or the newest. Contribute to these docs","title":"Deploy Portainer in Windows 10"},{"location":"v2.0-be/deploy/windowsserver/","text":"Deploy Portainer in Windows Server To run Portainer in a Windows Server Environment, you need to create exceptions in the firewall. These, can be easy added trough PowerShell, running the following commands: netsh advfirewall firewall add rule name=\"cluster_management\" dir=in action=allow protocol=TCP localport=2377 netsh advfirewall firewall add rule name=\"node_communication_tcp\" dir=in action=allow protocol=TCP localport=7946 netsh advfirewall firewall add rule name=\"node_communication_udp\" dir=in action=allow protocol=UDP localport=7946 netsh advfirewall firewall add rule name=\"overlay_network\" dir=in action=allow protocol=UDP localport=4789 netsh advfirewall firewall add rule name=\"swarm_dns_tcp\" dir=in action=allow protocol=TCP localport=53 netsh advfirewall firewall add rule name=\"swarm_dns_udp\" dir=in action=allow protocol=UDP localport=53 You also need to install Windows Container Host Service and Install Docker. Enable-WindowsOptionalFeature -Online -FeatureName containers -All Install-Module -Name DockerMsftProvider -Repository PSGallery -Force Install-Package -Name docker -ProviderName DockerMsftProvider Lastly, you need to restart your Windows Server. After it has restarted, you're ready to deploy Portainer. Deploy Portainer Docker Standalone docker volume create portainer_data docker run -d -p 9000:9000 --name portainer --restart always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine -v portainer_data:C:\\data portainer/portainer-ee:latest Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Docker Swarm using Windows Containers You can use our YML manifest to run Portainer in Windows using Windows Containers. In Powershell, run: curl https://downloads.portainer.io/portainer_ee_windows_stack.yml -o portainer_windows_stack.yml docker stack deploy --compose-file=portainer_windows_stack.yml portainer Now, you can navigate to http://localhost:9000 or the IP of the server and start using Portainer. Deploy Portainer Agent Only Docker standalone To run Portainer Agent in a Windows Container scenario, you need to execute the following commands: docker run -d -p 9001:9001 --name portainer_agent --restart=always -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine portainer/agent:2.0.0 Docker Swarm curl -L https://downloads.portainer.io/agent-ee-stack-windows.yml -o agent-stack-windows.yml && docker stack deploy --compose-file=agent-stack-windows.yml portainer-agent Then you just connect to one IP of the remote cluster on port 9001. Notes These deployments were tested in Windows Server 2019 2004 edition. To use Windows Containers, you need to run Windows Server 2019 ver 1803 or newest. Contribute to these docs","title":"Deploy Portainer in Windows Server"},{"location":"v2.0-be/downgrade/be-to-ce/","text":"Downgrade from Portainer Business to Portainer CE If you have a running instance of Portainer Business and want to downgrade to Portainer CE, follow the instructions below. Shutdown the Portainer Business instance Backup Portainer Business data Downgrade the Portainer Business database Re-deploy a Portainer CE instance On Docker Shutdown the existing Portainer Business instance Make sure that the Portainer Business instance is stopped before attempting any of the other steps. Inside a Docker standalone environment it is as simple as: docker stop portainer Inside a Swarm environment, you can simply scale down the Portainer service to 0 replicas: docker service scale portainer=0 Backup your data First make sure to create a copy of the Portainer data volume. You can use the following command to backup the data of the Portainer Business instance, you might need to update this command to match the name of your Portainer container: docker run --rm --volumes-from portainer -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /data This will create a backup.tar file in your current folder containing the Portainer Business instance data backup. Downgrade the Portainer Business database Use the following command to downgrade the Portainer database: docker run -it --name portainer-database-rollback -v portainer_data:/data portainer/portainer-ee:latest --rollback-to-ce Redeploy a Portainer CE instance After downgrading the database, you can now redeploy Portainer CE and re-use the existing Portainer Business data by following our instructions in Deploying Portainer . On Kubernetes Work-in-progress.","title":"Downgrade from BE to CE"},{"location":"v2.0-be/edge/groups/","text":"Edge Groups Edge Groups allows you to create groups of Edge endpoints based on a manual selection or synamically through tags . This feature is very useful when you manage multiple Edge Endpoints in multiple zones. To create a group, 1. go to Edge Groups and then 2. click Add Edge Group . Enter a Name and then 2. select either Static or Dynamic . Static Select the Endpoints you want to add to that group 4. These should then appear in the table on the right and finally 5. Click Add edge group Dynamic If you choose Dynamic you must choose between two options to match via Tags your Edge endpoints: Partial Match: Associate any endpoint matching at least one of the selected tags. (Each endpoint can have multiple tags). Full Match: Associate any endpoint matching all of the selected tags. Type the tag and endpoints with that tag will appear in the screen. Finally, click Add edge group Notes Contribute to these docs","title":"Managing Edge Groups"},{"location":"v2.0-be/edge/stacks/","text":"Deploy an Edge Stack This feature allows the deployment of multiple applications to multiple endpoints from a single screen and multiple sources. Edge stacks lets you deploy an app to all selected edge endpoints concurrently, regardless of their current state (online, disconneted, new). Deploying an Edge Stack Select Edge Stacks and then 2. Click Add stack . Next 1. Name your stack and 2. select one or more Edge Groups . In the Build Methond you need to define how to deploy your app from one of these options: Web Editor: You can use our web editor to write or paste a docker-compose file. Upload: Upload a docker-compose.yml file from your computer Repository: Use a git repository where the compose file is. Template: Use an Edge stack template. Once complete, click Deploy stack Notes Contribute to these docs","title":"Add a Stack"},{"location":"v2.0-be/edge/jobs/add/","text":"Add a Edge Job Adding a Edge Job is a excellent way to schedule jobs in your Edge hosts. This can be used to run any scripts you need, for example, run a backup in a determined period of time. Note : This is a beta feature. Note 2 : Computing features needs to be enabled. Take a look at this section in our admin guide . Adding a Edge Job To add a job, click Edge Jobs and then Add Edge job . Then 1. Name your job and 2. Choose between the following two options: Basic Configuration: Select a date from a calendar Advanced Configuration: Write your own CRON rule. Select if this job is a recurring job and enter the job time. You can then use the web editor to write or paste the script. Select the target endpoints. To create and run the job click Create edge job. Notes Contribute to these docs","title":"Add a Job"},{"location":"v2.0-be/endpoints/access/","text":"Manage Endpoint Access Portainer can manage endpoint access. Depending on your needs, this can be broad or granular. Teams and/or users can be added to manage an Endpoint. Access tagged as inherited relies on the group access rules. They cannot be removed or modified at the endpoint level but they can be overridden. Access tagged as override are overriding the group access for the related users/teams. Adding a Team or User To Add access to a Team or User click in Endpoints , Select the desired Endpoint, and click in Manage Access . Next select the team or user you want to give access to one by one. Once the team or user is selected click in dropdown menu Role and select the role you want to add to this user: Create Access If everything work as expected, you will see the next pop up at the top right of your screen. Notes Contribute to these docs","title":"Managing Endpoints Access"},{"location":"v2.0-be/endpoints/aci/","text":"Add an Azure Container Instance Endpoint Portainer Business allows you to deploy and manage apps in Azure Container Instances quickly and easily and like no other tool. There is no need to type commands via CLI or go to the Azure Portal to manage your containers; Portainer does it all. Simply deploy Portainer in an Azure container and manage it like any other node. Requirements Before connecting to your Azure Subscription, you need to create an Azure AD Application. For more information see the Microsoft Documentation . Adding an ACI Endpoint To add an ACI Endpoint you will need the following information: Name: Choose a name to identify this endpoint. Application ID: This value is from the application you created in Azure. Tenant ID: You can get your tenant ID of Azure Subscription page Authentication ID: This value is from the process of Application creation in Azure. Once you have these values, you can start to add an ACI Endpoint to Azure. Go to Endpoints 2. Click Add Endpoints Select Azure 4. Complete Application and Azure Subscription 5. Click Add Endpoint Is everything works as expected, you will the following pop up Notes Contribute to these docs","title":"Add ACI Endpoint"},{"location":"v2.0-be/endpoints/api/","text":"Create/Add a new endpoint through Portainer API In this help article, you will learn how to add the following type of endpoints trough our API: Local endpoint using Docker socket communication Remote endpoint using TCP communication Remote endpoint using TCP communication secured via TLS The API documentation is available here . WARNING: This documentation is valid for Portainer >= 1.18.0. NOTE: We're using httpie to execute HTTP queries from the CLI. Once you have deployed portainer (see Deploying Portainer ) you need to initialize your admin user. Initialize the admin password http POST :9000/api/users/admin/init Username=\"admin\" Password=\"adminpassword\" Authenticate against the API using the admin account http POST :9000/api/auth Username=\"admin\" Password=\"adminpassword\" The response is a JSON object containing the JWT token inside the jwt field: { \"jwt\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" } You need to retrieve this token and pass it into the Authorization header when executing an authentication query against the API. The value of the Authorization header must be of the form Bearer JWT_TOKEN . Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE NOTE: This token has an 8 hour validity, you'll need to generate another token to execute authenticated queries once this one expires. Local endpoint via the Docker socket This query will create an endpoint called test-local and will use the Docker socket to communicate with this environment. NOTE: This example requires to you bind-mount the Docker socket when running Portainer. Run the following: http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-local\" EndpointCreationType=1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Name\": \"test-local\", \"PublicURL\": \"\", \"Type\": 1, \"TLSConfig\": { \"TLS\": false, \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"unix:///var/run/docker.sock\" } Retrieve the value of the Id property, it will be used to execute queries against the Docker engine for that endpoint. Remote endpoint This query will create an endpoint called test-remote and will communicate with this environment over TCP using the IP address 10.0.7.10 and port 2375 (these are example values, ensure that you're using the correct IP & port). NOTE: The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-remote\" URL=\"tcp://10.0.7.10:2375\" EndpointCreationType=1 The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Type\": 1, \"Name\": \"test-remote\", \"PublicURL\": \"\", \"TLSConfig\": { \"TLS\": false, \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"tcp://10.0.7.10:2375\" } Retrieve the value of the Id property, it will be used to execute queries against the Docker engine for that endpoint. Remote endpoint secured using TLS This query will create an endpoint called test-remote-tls and will communicate with this environment over TCP (secured with TLS) using the IP address 10.0.7.10 and port 2376 (these are example values, ensure that you're using the correct IP & port). NOTE: The Docker API must be exposed on that IP address & port. Please refer to the Docker documentation to check how to configure this. http --form POST :9000/api/endpoints \\ \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE\" \\ Name=\"test-remote\" URL=\"tcp://10.0.7.10:2376\" EndpointCreationType=1 TLS=\"true\" TLSCACertFile@/path/to/ca.pem TLSCertFile@/path/to/cert.pem TLSKeyFile@/path/to/key.pem The response is a JSON object representing the endpoint: { \"AuthorizedTeams\": [], \"AuthorizedUsers\": [], \"Extensions\": [], \"GroupId\": 1, \"Id\": 1, \"Type\": 1, \"Name\": \"test-remote\", \"PublicURL\": \"\", \"TLSConfig\": { \"TLS\": true, \"TLSCACert\": \"/data/tls/1/ca.pem\", \"TLSCert\": \"/data/tls/1/cert.pem\", \"TLSKey\": \"/data/tls/1/key.pem\", \"TLSSkipVerify\": false }, \"Type\": 1, \"URL\": \"tcp://10.0.7.10:2376\" } Retrieve this ID, it will be used to execute queries against the Docker engine for that endpoint. Notes Contribute to these docs","title":"Add Endpoint through Portainer API"},{"location":"v2.0-be/endpoints/docker/","text":"Add Docker Endpoint If you want to manage any standalone Docker Host, you must connect to the Docker API directly. To expose the Docker API to admit remote connections, you need to follow these steps . Once this is complete we can connect the Docker API with and without TLS. Connect to Docker Host API without TLS Go to Endpoints 2. Click Add Endpoint . The next step is choose the environment type and select Docker . In the following section (Environment Details), you need to specify the following information: Name: This a descriptive name that will help you to identify this endpoint in the future. Endpoint URL: Is the name or IP address to connect to the Docker Host. Don't forget to specify the port. When you set Docker to use TLS, the default port is 2376 Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. TLS: Enable this option if you need to connect to the Docker endpoint with TLS. Once all this has been specified, you can click Add Endpoint button If successful, you will see a pop up confirming that the Endpoint was added successfully: Connect to Docker Host API with TLS Portainer is able to connect to the Docker Host API using TLS. To use this option, the Docker environment must be protected already. You can find out more information about how to protect a Docker environment with TLS in the Docker documentation To connect directly to a Docker host API TLS: 1. Go to Endpoints and 2. Click in the Add Endpoint . The next step is choose the environment type and select Docker . In the following section (Environment Details), you need to specify the following information: Name: Name: This a descriptive name that will help you to identify this endpoint in the future. Endpoint URL: Is the name or IP address to connect to the Docker Host. Don't forget to specify the port. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. TLS: Enable this option if you need to connect to the Docker endpoint with TLS. TLS CA Certificate: Define your CA Cerficate. TLS Certificate: Define your certificate. TLS Key: Define your certificate key. Once all this has be specified, you can click in the Add Endpoint button. Scroll down to the bottom of the page and click Add Endpoint . Notes Contribute to these docs","title":"Add Docker Endpoint"},{"location":"v2.0-be/endpoints/edge/","text":"Add Edge Endpoint. The edge agent was created as a way to manage an edge compute environment where devices typically lack the networking capability to run the traditional Portainer agent. Expose port 8000. This scenario only applies when Portainer is running in a Docker or Docker Swarm environment. Portainer communicates with the edge agent over port 8000; through this port the edge agent can poll the Portainer instance, connect to Portainer, see when it is needed & initiate a tunnel or receive config updates. Without port 8000 exposed on Portainer, you cannot access the edge endpoint. If you already have Portainer deployed, you need to redeploy with port 8000 exposed alongside the port used to access Portainer. Using the CLI flag --tunnel-port you are able to set a different port if 8000 is already in use. For more information see CLI options . Recommended Portainer deployment methods. Portainer with TLS: If your Portainer instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. This is the recommended approach. Portainer with self-signed certs: If you are using a self-signed Portainer instance, the edge agent must be deployed with the flag: -e EDGE_INSECURE_POLL=1 . If you do not deploy Portainer with this flag, then the agent will not be able to communicate with Portainer. This option is less secure than TLS. Portainer fallback to HTTP: If Portainer is not configured with either of the above options, it will fallback to using HTTP for the agent polling. This option is no longer recommended, as it is insecure. Deploying Edge agent in Docker Standalone environment. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Standalone in the tabbed Information section and then 2. Copy Command This command needs to be run in the Docker Standalone. Running docker ps should result in something similar to: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b9e27f356de8 portainer/agent \"./agent\" 12 seconds ago Up 12 seconds portainer_edge_agent Next, in the Configuration section, 1. Define the IP address of the node you want to manage 2. Click Update Endpoint . You should then see the following pop up. Deploying Edge agent in Docker Swarm environment. Adding a Docker Swarm environment with Edge Agent is very similar to the scenario with Docker Standalone. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Swarm in the tabbed Information section and then 2. Copy Command Run the command in the Docker Swarm node, expected results should look similar to: cp2v1mqzkjpcroo3ama8wsve1 overall progress: 1 out of 1 tasks okei8p76rf6k: running [==================================================>] verify: Service converged Running docker service ls you should see: ID NAME MODE REPLICAS IMAGE PORTS cp2v1mqzkjpc portainer_edge_agent global 1/1 portainer/agent:latest Next, in the Configuration section, 1. Define the IP address of the node you want to manage 2. Click Update Endpoint . You should then see the following pop up: Deploying Edge agent in Kubernetes environment. To add an Edge Endpoint to Portainer: 1. Click Endpoints 2. Click Add Endpoint button. Click Edge Agent 2. Assign friendly name 3. Set the Portainer Server URL indicating the Public IP of your Portainer instance and the port 4. Define a Pull Frequency (default is 5s) and 5. Click Add Endpoint In the next screen, 1. Select Docker Swarm in the tabbed Information section and then 2. Copy Command . You need to run this command in the Kubernetes host and the expected results is the following: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 3190 100 3190 0 0 1249 0 0:00:02 0:00:02 --:--:-- 1248 Downloading agent manifest... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 2070 100 2070 0 0 1582 0 0:00:01 0:00:01 --:--:-- 1582 Creating Portainer namespace... namespace/portainer created Creating agent configuration... configmap/portainer-agent-edge-id created Creating agent secret... secret/portainer-agent-edge-key created Deploying agent... Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply namespace/portainer configured serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin unchanged service/portainer-agent created deployment.apps/portainer-agent created Portainer Edge agent successfully deployed You can validate if the Edge Agent is running in your host executing the following command: kubectl get pods --namespace=portainer After running the command, you can enter the IP address of the host and click in Update Endpoint button. You should then see the following pop up: ||||| SPACE FOR POP UP ||||| Notes Contribute to these docs","title":"Add Edge Endpoint"},{"location":"v2.0-be/endpoints/groupstags/","text":"Endpoints Groups and Endpoint Tags In Portainer, you will able to set up Groups and Tags to organize your endpoints. For example, you can set up a group for Development, Stage or Production and use the Tags to identify to which department is the resource \"owner\" or where it is located. Add a Endpoint Group Adding an Endpoint is very easy in Portainer. Once logged in 1. Click Endpoints and then 2. Groups Next, define the Group: 1 - Name: Define the name of your group. 2 - Description: Add a description to your group. (Optional) 3 - Select the endpoints for that group 4 - You will see the endpoints associated to that group. 5 - Once is defined, do a click in Create The Group. Once groups have been created you should see this: Add Endpoint Tags Use tags to define node or resource metadata. E.g. Add tag \"LA\" for a node located in Los Angeles, you can set a tag to that node to have more visibility when looking for nodes running in Los Angeles. The same concept for department or \"owners\" of those resources. Click Endpoints 2. Select Tags 3. Define Tag names and 4. Click Create Tag . All tags will then be shown in a table: Adding a Tag to an Endpoint To add a Tag to an Endpoint. 1. Go to Endpoints and 2. Select the desired endpoint. Select the desired tag and click Update Endpoint Once complete the Home Page shows the Endpoints and their associated tags. Notes Contribute to these docs","title":"Creating Endpoints Groups and Endpoint Tags"},{"location":"v2.0-be/endpoints/kubernetes/","text":"Add Kubernetes Endpoint Adding Kubernetes endpoints to Portainer Business 2.0 is very straightforward. As a requirement, you need to define if you are going to deploy the Agents for Kubernetes via NodePort or LoadBalancer. In this guide, you will see how to deploy in both scenarios. You can view the supported Kubernetes versions in this [page]. For more information on supported Kubernetes Versions please view the [Requirements] (/v2.0-be/deploy/requirements.md) page. Add Kubernetes Endpoint via NodePort. Deploying the Agent. Once logged into Portainer go to 1. Endpoints 2. Select Agent from Environment Type section. 3. Select Kubernetes via Node Port in the tabbed Information section, 4. Copy the command. Note: It is important to fill the environment details by first running the command in the Kubernetes node. This command is the same each time you want to add a new Kubernetes Endpoint via NodePort: curl -L https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml Once is running in the Kubernetes host, the terminal is going to reply with something like this: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1617 100 1617 0 0 846 0 0:00:01 0:00:01 --:--:-- 845 namespace/portainer created serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin created service/portainer-agent created service/portainer-agent-headless created deployment.apps/portainer-agent created To validate if the Agent is running, you can run the following command: kubectl get pods --namespace=portainer The result of that command should be something like this: NAME READY STATUS RESTARTS AGE portainer-agent-5988b5d966-bvm9m 1/1 Running 0 15m Now, we're ready to move on to the next step. Finishing the configuration. Once the Agent is running in the Kubernetes host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Kubernetes host) and specify the port (30778) if this is needed. This field is requiered. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metadata section, you can define a group and tags for this endpoint. See the following screenshot for reference. Once everything is set click Add Endpoint . You will then see the final configuration screen (below). In this screen, you can set the following options: Allow users to use external load balancer: Enabling the load balancer feature will allow users to expose application they deploy over an external IP address assigned by cloud provider. Ingress controller: Adding ingress controllers will allow users to expose application they deploy over a HTTP route. Enable features using metrics server: Enabling this feature will allow users to use specific features that leverage the metrics server component. Available storage options: Select which storage options will be available for use when deploying applications. Have a look at your storage driver documentation to figure out which access policy to configure and if the volume expansion capability is supported. The options in the sections are: Local-path: In this scenario your applications will be storaged in the node. Shared Access Policy: RWO or RWX Volume Expansion: Enable the option to expand the persistent storage of the pods. You can find more information about access modes in the official Kubernetes documentation . See the following screenshot for reference: Once this has all been set, click Save Configuration . Congratulations! Your Kubernetes endpoint was added. Add Kubernetes Endpoint via Load Balancer Deploying the Agent. Once you login to Portainer, you need go to Endpoints and pick in the environment type section, Agent . In the tab below to the information section, you need pick Kubernetes via Load Balancer and copy the command displayed in the page. Note: Is important run the command in the Kubernetes node before to fill the environment details. The command in this scenario is the same of each time you want to add a new Kubernetes Endpoint via Load Balancer to Portainer. The command is the following: curl -L https://downloads.portainer.io/portainer-agent-k8s-lb.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml Once is running in the Kubernetes host, the terminal is going to reply with something like this: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 1617 100 1617 0 0 846 0 0:00:01 0:00:01 --:--:-- 845 namespace/portainer created serviceaccount/portainer-sa-clusteradmin created clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin created service/portainer-agent created service/portainer-agent-headless created deployment.apps/portainer-agent created To validate is the Agent is running, you can run the following command: kubectl get pods --namespace=portainer The result of that command should be something like this: NAME READY STATUS RESTARTS AGE svclb-portainer-agent-52xrp 1/1 Running 0 2m26s Now, we're ready to move on to the next step. Finishing the configuration. Once the Agent is running in the Kubernetes host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Kubernetes host) and specify the port (9001) if this is needed. This field is requiered. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metada section, you can define a group and tags for this endpoint. See the following screenshot for reference. When everything is set, you only need to click in Add Endpoint button. If everything work as expected, you will see the last screen for configuration. In this screen, you can set the following options: Allow users to use external load balancer: Enabling the load balancer feature will allow users to expose application they deploy over an external IP address assigned by cloud provider. Ingress controller: Adding ingress controllers will allow users to expose application they deploy over a HTTP route. Enable features using metrics server: Enabling this feature will allow users to use specific features that leverage the metrics server component. Available storage options: Select which storage options will be available for use when deploying applications. Have a look at your storage driver documentation to figure out which access policy to configure and if the volume expansion capability is supported. The options in the sections are: Local-path: In this scenario your applications will be storaged in the node. Shared Access Policy: RWO or RWX Volume Expansion: Enable the option to expand the persistent storage of the pods. You can find more information about access modes in the official Kubernetes documentation . See the following screenshot for reference: Once all is set, you must click in Save Configuration button. Congratulations. You Kubernetes endpoint via Load Balancer was added. Notes Contribute to these docs","title":"Add Kubernetes Endpoint"},{"location":"v2.0-be/endpoints/local/","text":"Add Local Endpoints You can only add a local endpoint during the creation of the Portainer container. You cannot add a local endpoint after Portainer was deployed. You can view how to install Portainer (including adding a local endpoint) in the following articles: Deploy Portainer in Linux To learn more go to Deploy Portainer in Linux Environments. Deploy Portainer in Windows 10 and Windows Server To learn more go to Deploying on Windows 10 or Deploying on Windows Server . Initial Setup Adding a local endpoint must be done in the initial setup. To learn more see initial setup Notes Contribute to these docs","title":"Add Local Endpoint"},{"location":"v2.0-be/endpoints/swarm/","text":"Add a Docker Swarm Endpoint Add a Docker Swarm Endpoint is very straighforward in Portainer Business 2.0. Deploy the Agent. Once logged into Portainer, go to Endpoints and select Agent as the Environment Type . In the tabbed section below titled Information , select Docker Swarm and copy the command. Note: It is important run the command in the Docker Swarm host before to fill the environment details. Use this same command each time you want to add a new Docker Swarm endpoint: curl -L https://downloads.portainer.io/agent-stack.yml -o agent-stack.yml && docker stack deploy --compose-file=agent-stack.yml portainer-agent Once running in the Docker Swam host, the terminal will reply with something similar to: % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 484 100 484 0 0 249 0 0:00:01 0:00:01 --:--:-- 249 Creating network portainer-agent_portainer_agent Creating service portainer-agent_agent To validate is the Agent is running, you can run the following command: docker service ls The result of that command should be something like this: ID NAME MODE REPLICAS IMAGE PORTS tshb6ee2710s portainer-agent_agent global 1/1 portainer/agent:latest Now, we're ready to move on to the next step. Finishing the configuration Once the Agent is running in the Docker Swarm host, you need to fill the environment details . The following options are available: Name: This is a descriptive name for your endpoint. This field is required. Endpoint URL: Define your IP or name to connect to the endpoint (Docker Swarm Host) and specify the port (9001) if this is needed. This field is requiered. Public IP: URL or IP address where exposed containers will be reachable. This field is optional and will default to the endpoint URL. In the Metadata section, you can define a group and tags for this endpoint. See the following screenshot for reference. When everything is set, you can click Add Endpoint . If successful, you will see this pop up at the top right corner. Notes Contribute to these docs","title":"Add Docker Swarm Endpoint"},{"location":"v2.0-be/images/build/","text":"Build Image Portainer allows you to create/build new images from a friendly UI. You can define your build in three ways: Web Editor: You can use our web editor to build your image. Upload: If you already have a dockerfile, you can upload to Portainer to build that image. URL: If the dockerfile is hosted in Internet, you can download directly to Portainer and build the image. Building an Image using our web editor Go to Images and click Build a new image . In the next screen, you need to define a name for your image and start to write your dockerfile in the editor. Note : You can define multiple names for you image. When you're ready, scrolldown, select the node you going to save the image to and click Build the image When the building process is complete, you need to click in the tab Output and you will see the build history and the result. If everything works as expected, you will see a similar output to this: Notes Contribute to these docs","title":"Build images"},{"location":"v2.0-be/images/export/","text":"Export Images Portainer allows you to export any Docker image that is stored in any node. This is useful when you need to move a container from a one host to another or simply make backup of the images. Note : Be advised that when you export a container to a tar file, the volumes are not exported with it. You need to save the data from those volumes in a another way. Exporting Images To export images, click Images , select the image you want to export and click Export . You will see a pop up warning you about that the export may take several minutes, this time depends of the size of your image. Click Continue . When the process is ready you will see a pop up at the top right corner and you will see that your image is downloading: Notes Contribute to these docs","title":"Export images"},{"location":"v2.0-be/images/import/","text":"Import Images Portainer allows you to import the images that you have created in another Portainer instance or in the CLI of Docker and Docker Swarm. Importing Images To import an image using Portainer, go to Images and then click Import . Select your image , select the node where you will save the image and click Upload . Once the images have uploaded, you will see the following pop up: Notes Contribute to these docs","title":"Import images"},{"location":"v2.0-be/images/pull/","text":"Pull Images You can pull images from any registry already added to Portainer, see how to add new registries to Portainer for more information. This option is currently only available, when you manage Docker and Docker Swarm environments. Pulling Images Pulling in Simple Mode To pull images from Docker Hub or another registry that you have connected before you must do the following: Go to Images and then type the name of the image, select the node that will download the image and click Pull the Image . When the image is sucessfully downloaded, you will see a pop up at the right top corner. Pulling in Advanced Mode Using Advanced Mode you can define a custom registry URL , port and image . This use case is ideal when you run your own private registry. To pull images, go to Images click in Advanced Mode and then, define your registry , port , image , and specify the node where the image is going to be downloaded and click Pull the Image You will see an animation in the button while the imeage is downloading: When the image is sucessful downloaded, you will see a pop up at the right top corner. Notes Contribute to these docs","title":"Pull images"},{"location":"v2.0-be/kubernetes/applications/create/","text":"Deploy New Applications From Portainer, you can deploy new applications in your Kubernetes cluster without the need to learn complex CLI commands or edit large YML files. In this help article, you will learn how to deploy an App into a Kubernetes cluster using Portainer. Deploying an application Deploying an application in Portainer to Kubernetes is very easy and very customizable depending on your need. To deploy a new application, click Applications and then Add Application . After that, you will see a form to complete according to your needs. The options available are: Name: Name of your Container. Image: This is the image you want to use to deploy your container. Resource Pool: This is the namespace where your container is going to live. To add a new resource pool, see this help article . Stack: Portainer can automatically bundle multiple applications inside a stack. Enter a name of a new stack or select an existing stack in the list. Leave empty to use the application name. Environment Variables: Fill the environment that your app needs, this is optional and only depends of the configuration supported by your app. Configurations: If you created configuration files before using Portainer, you can select that configuration in this space. Persisting Data: Define what folder of the container needs to be persisted. Data Access Policy: Here you need to specify how the data will be used across instances. The options are the following: Shared: All the instances of this application will use the same data. Isolated: Every instance of this application will use their own data. Resource Reservations: Define what resources can be used by your application. Deployment: Select how you want to deploy your application inside the cluster. The options are the following: Replicated: Run one or multiple instances of this container. Global: Deploy an instance of this container on each node of the cluster. Auto Scaling: Select this to enable the auto-scaling of your application and define how many instances need to scale and under what conditions. Placement rules: Deploy this application on nodes that respect ALL of the following placement rules. Placement rules are based on node labels. Placement Policy: Specify the policy associated to the placement rules. This can be any of two options: Preferred: Schedule this application on nodes that match the rules if possible. Mandatory: Schedule this application ONLY on nodes that match ALL Rules. Publish Application: Select how you want to publish your application. This can be one of two options: Internal: Internal communications inside the cluster only. Cluster: Publish this application via a port on all nodes of the cluster. Publish Ports: Only applicable if you have selected Cluster above. When everything was set up, click Deploy application . Notes Contribute to these docs","title":"Deploy a new application"},{"location":"v2.0-be/kubernetes/applications/delete/","text":"Delete an Application You can remove/delete applications using the Portainer GUI. Deleting an Application To delete an Application, click Applications , select the Application you want to delete and then click Remove . Notes Contribute to these docs","title":"Delete an Application"},{"location":"v2.0-be/kubernetes/applications/inspect/","text":"Inspect Application. From Portainer, you can see a lot of details about your application running in a cluster. To access to this information click Applications and then click the application you want to inspect. Application information In the tab Application , you can find the following information: Name: Name of the application. Stack: Name of the stack that this container belongs. Resource Pool: In what resouce pool / Namespace this application in running. Application Type. Status: See if the application is running. Creation: Information about who and when the application was created. You can also find specific configuration of this application: Port published: Show what port is published from this container. Auto Scaling: Show if this application has an auto scaling policy defined. Configuration: Here, we can see if the application has a special configuration defined. Data Persistence: Here we can see what directories are persitent. In the Application container section you can see the pod that runs your application, what the image is using, status, node and information about when it was created. Also, you can access the logs or the console of this Pod. Placement In this tab, you will find information what node your application is running in. Events This shows find information about the events related of your container. YML In this section, you can find the YML generated from the deployment of your application using Portainer. This is very useful to create \"backups\" of your configuration. Notes Contribute to these docs","title":"Inspect an Application"},{"location":"v2.0-be/kubernetes/applications/manifest/","text":"Deploy an App from a manifest In Portainer you can launch new applications using your current manifest in YML for K8s or convert from a docker-compose file format. Note : Portainer uses Kompose to convert your Compose manifest to a Kubernetes compliant manifest. Be wary that not all the Compose format options are supported by Kompose at the moment. Deploying an App from a Kubernetes Manifest. To start, click Applications and then Advanced Deployment . In this section, you need to define the resource pool where your applications are going to be deployed and start to write or paste your Kubernetes Manifest. Once this is done, click Deploy . If everything works as expected you will see this pop up: Notes Contribute to these docs","title":"Deploy from a Kubernetes Manifest"},{"location":"v2.0-be/kubernetes/cluster/inspect/","text":"Inspect the Cluster From Portainer, you can inspect Kubernetes Clusters. Inspecting the cluster Click Cluster and you will see information about this cluster. Memory Reservation: Memory used and available for this cluster. CPU Reservation: How much CPU reserved is used. Client Satus: View if the components are healthy or they have some any issues. Leader Status: You will see if this node is a Leader or not. At the bottom of the page, you will see information about the nodes that are part of this cluster. Name, Role, CPU, Memory, Version of Kubernetes, IP Address. Inspecting nodes Node When you click in a node, you can inspect it. You will find the following information: Hostname Kubernetes API Por Role Kubelet Version Creation date Status Labels Applications running on this node Events In the events tab, you will see information about the events related to your node. YAML Here you will find the configuration of your node in YAML format. You can copy the content and save it to mantain a backup of the node configuration. Notes Contribute to these docs","title":"Inspect cluster"},{"location":"v2.0-be/kubernetes/configurations/create/","text":"Create a configuration From Portainer you can create Configurations files outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Creating a configuration To create a configuration, click Configurations and then click Add configuration . In the next screen, you need to define the following: Name: Name your configuration. Resource Pool: Where the configuration is going to be saved. Configuration Type: Non-sensitive: This configuration holds non-sensitive information. Sensitive: This configuration holds sensitive information like passwords or certificates In the data section, clicking Advanced Mode allows you to define your configuration in YAML format. If you would prefer not to use advanced mode, you can create entries using the fields below or taking from a file. Once you have set your configuration, click Create configuration Notes Contribute to these docs","title":"Add a configuration"},{"location":"v2.0-be/kubernetes/configurations/remove/","text":"Delete a configuration From Portainer, you can delete configurations created previously. Deleting a configuration Go to Configurations , select the configuration and then, click Remove . Notes Contribute to these docs","title":"Remove a configuration"},{"location":"v2.0-be/kubernetes/resource_pools/access/","text":"Manage access to a resource pool Access Control & RBAC Kubernetres RBAC needs to enabled and working for Access Control to work properly in Portainer. In this help article, you will learn how to manage access to created resource pools. Managing access Click Resource Pools then click Manage Access of the resource pool you want. Select the user(s) and or team(s) to add and click Create Access . If everything works as expected, you will see this pop up confirming your action. Notes Contribute to these docs","title":"Manage Access"},{"location":"v2.0-be/kubernetes/resource_pools/create/","text":"Create a Resource Pool The Resource Pools are helpful when multiple teams are using the same cluster and there is an potential collision, you can prevent this by using a virtual wall between multiple clusters. In this help article, you will learn how to create a Resource Pool (Namespace) using Portainer. Creating a Resouce Pool Go to Resouce Pools and then click Add resource pool . In the next screen, you need to define a few things: Name Name your Resource Pool. Resource Assignment A resource pool is a logical abstraction of a Kubernetes cluster, to provide for more flexible management of resources. The best practice is to set a quota assignment as this ensures the greatest security/stability; alternatively, you can disable assigning a quota for unrestricted access (not recommended). Here you can define resource limits: Memory CPU Note : To Enable Resource Quota, you need to enable from the settings of the cluster . Load balancers You can set a quota on the amount of external load balancers that can be created inside this resource pool. Set this quota to 0 to effectively disable the use of load balancers in this resource pool. To enable a Load Balancer quota for this resource pool, enable the toggle Load Balancer quota and set the Max Load Balancers . Note : To Enable Load Balancer Quota, you need to enable from the settings of the cluster . Storages Quotas can be set on each storage option to prevent users from exceeding a specific threshold when deploying applications. You can set a quota to 0 to effectively prevent the usage of a specific storage option inside this resource pool. To enable Storage Quota for this resource pool, enable the toogle Enable quota , set the Maximum Usage and the unit of storage (MB, GB, TB). When everything is set, click Create resource pool . If everything works as expected, you will see a pop up confirming the creation of this resource pool. Notes Contribute to these docs","title":"Create a Resource Pool"},{"location":"v2.0-be/kubernetes/resource_pools/delete/","text":"Delete/Remove a Resource Pool When you have finished your project, you can delete resource pools to free up resources. Removing a Resouce Pool Click Resouce Pools , select the resource pool and click Remove . You need to confirm this action: If everything works as expected, you will see a pop up confirming your action. Notes Contribute to these docs","title":"Delete a Resource Pool"},{"location":"v2.0-be/kubernetes/volumes/inspect/","text":"Inspect a volume In Portainer, you can inspect volumes that you mounted in a Kubernetes Pod. Inspecting a Volume Go to Volumes and then choose the volume you want inspect. In the first view, you will see the following data: Resource pool where this volume was saved Used By: Name of the app that is using the volume Storage: What is the storage Size Created: Information about who and when it was created. After selecting the volume, you will see three tabs. In the first one, you will information about the volume itself. In the events tab you will see the events related to this volume: And the YAML tab you will see the configuration of this volume in YAML format. From this tab, you can copy and save the content as a backup. Notes Contribute to these docs","title":"Inspect a volume"},{"location":"v2.0-be/kubernetes/volumes/remove/","text":"Remove a Volume In Portainer you can remove volumes, but please note the volume needs to be unattached from any container beforehand. Unattaching a volume from a container To remove the volume that is attached to a container, go to Applications and select the App. Click Edit this application . Scroll down to the section Persisting Data and click the trash basket icon. You will see the volume label with a strikethrough effect. Scroll down anc click Update Application . A warning will pop up. Click Update to confirm. Removing a Volume If your volume is free you can delete it. First click Volumes , select the volume you want delete, and click Remove . You will be asked for confirmation, click Remove to confirm. If everything works as expected, you will see a pop up confirmating this action: Notes Contribute to these docs","title":"Remove a volume"},{"location":"v2.0-be/kubernetes/volumes/resize/","text":"Increase the volume Using Portainer, you can increase the size of a volume. Note : Is only possible to increase the size of the volume. You cannot reduce the size of a volume. Increasing a volume Go to Volumes and select the volume you want resize. In the tab Volume you will see the current size of your volume. Click Increase size . After that you will able to enter a new size for that volume. Enter the new value and click Update size . You will see a warning if the volume is used by any app at this this time and you will be asked to confirm if you want resize and redeploy the app. Click Redeploy the applications to confirm. If eveything works as expected, you will see a pop up confirming the resize of your volume. Notes Contribute to these docs","title":"Resize a volume"},{"location":"v2.0-be/licensing/licensing/","text":"Add a Business Edition License If you add more nodes to your environment and want to manage with Portainer Business Edition, you need to upgrade your license to fit the numbers of nodes. Once you have the right license for the quantity of nodes, you need to add this license in Portainer Configuration. Adding / Upgrading a Business Edition License To add new licenses to your current instance of Portainer, go to Licenses and click Add license Add your new license and click Submit . If everything goes well, you will see your quantity of nodes licensed increases and your new license added. Adding multiple licenses If you buy more than one license, you can add it in a single process. Go to Add License and click Add License . When all the licenses are entered, click Summit Removing a License Note : If you have a single license installed in your Portainer instance, you cannot remove the license because at least one is needed. To remove a license, go to Licenses , select the license you want to remove and click Remove . You will ask for confirmation. If you're sure, click Remove . And you're done, you have removed the license. Notes Contribute to these docs","title":"Add or remove license key"},{"location":"v2.0-be/networks/add/","text":"Add a Network Portainer allows you to manage networks for your containers environments. You will be able to to create these network types: Bridge: the default network driver. If you don\u2019t specify a driver, this is the type of network you are creating. Bridge networks are usually used when your applications run in standalone containers that need to communicate. Macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host\u2019s network stack. Overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. IPvlan: IPvlan is similar to macvlan with the difference being that the endpoints have the same mac address. ipvlan supports L2 and L3 mode. In ipvlan l2 mode, each endpoint gets the same mac address but different ip address. In ipvlan l3 mode, packets are routed between endpoints, so this gives better scalability. Adding a Network To add a network in Portainer, click Networks and then click Add Network . In the next screen, you need to define the following information: Name: Name your network Driver: Define the type of network that you will use. (See above the description of each driver). IPv4 Network configuration: You can define IP ranges, Subnet, gateway and exclude IP. If this data is not filled, Docker will assign a range automatically. IPv6 Network configuration: You can define IP ranges, Subnet, gateway and exclude IP. If this data is not filled, Docker will assign a range automatically. Labels: Define labels for you network. Restrict External Access to the network: Allows you to isolate the containers inside of that network. Enable manual container attachment: Select the toggle if the users can attach this network to running containers. Deployment: Select the node where this network is going to be created. When everything is set, click Create the Network . Notes Contribute to these docs","title":"Add a Network"},{"location":"v2.0-be/networks/delete/","text":"Delete a Network Portainer allows you to delete networks. Deleting Networks To delete a network, click Networks , select the network you want to delete, and click Remove . Notes Contribute to these docs","title":"Delete a Network"},{"location":"v2.0-be/registries/auth-docker-hub/","text":"How to enable Docker Hub authentication In this helpful video, you will learn how to enable Docker Hub authentication in Portainer. Enabling Docker Hub authentication in Portainer Notes Contribute to these docs","title":"Enable Docker Hub Authentication"},{"location":"v2.0-be/registries/browse/","text":"Browse a Registry Portainer Business Edition comes with a Registry Manager feature enabling simple operational management of your docker registries and their content, such as browsing the registries, exploring repositories and images, manipulating the tags that are attached to repositories and images, adding new tags, and deleting existing tags. In this help article, you will see how to browse a registry Browsing a Registry To browse a registry go to Registries and select browse on the desired registry. On the next screen, you will see the repositories and Tags count. If you enter to any repository, you can see a complete picture of the repository. You will find the following information: Name of the repository Tags count Images count Names of the images OS/Architecture Image ID Compressed size If you click a tag, you will see relevant data, for example: ID: Identifier of the Tag. Parent: ID of the parent tag. Created: Date and time that was created. Build: Information about the docker version and OS used to build the image. Author In the section DockerFile details, you will find information about the software (and the version) installed in that image. You will also see the Image Layers to understand how the image was built. Notes Contribute to these docs","title":"Browse a Registry"},{"location":"v2.0-be/registries/connect/","text":"Add / Connect a new registry Portainer can connect to many of the well-known registries including Quay.io, Azure Container Registry, Gitlab Container Registry, and a Custom Registry. Quay.io To connect to a Quay registry, go to Registries and then Add Registry In the next screen, choose Quay.io and enter your Username and Password , then click Add registry . Azure Container Registry To connect to a Azure registry, go to Registries and then Add Registry In the next screen, choose Azure , name your registry, enter the Registry URL , Username , and Password , then click Add registry . Gitlab To connect to a Gitlab registry, go to Registries and then Add Registry In the next screen, choose Gitlab , enter the Username , and Personal Token , then Add registry . Note : For information on how to generate a Gitlab Personal Access Token, follow the Gitlab guide . How to add a Custom Registry Portainer can connect to custom or 3rd party registries. First select Custom Registry and enter the details there. The required fields are name of the registry and address , if any authentication is required, you must enable the authentication toggle and add your login details. Once all the details are entered, click Add Registry . If successful you will see the following: Notes Contribute to these docs","title":"Connect to a Registry"},{"location":"v2.0-be/registries/description/","text":"Registry Management Description The Registry Manager is a feature of Portainer Business Edition, that extends your container management experience with the capability to browse defined registries and manipulate their content. By using the Registry Manager feature, container users enjoy the benefit of having a single interface to manage any Docker registry deployment*, providing a consistent look and feel across any provider. The Registry Manager feature enables simple operational management of your docker registries and their content, such as browsing the registries, exploring repositories and images, manipulating the tags that are attached to repositories and images, adding new tags, and deleting existing tags. Portainer Business Edition enables you to retag an image as a means to promote it through the deployment lifecycle, or simply add or remove tags to annotate changes or usage. Also allows you to clean up legacy images by safely deleting unused images. * The registry must support Docker Registry API v2. Currently supported registries: Private Docker registry, Azure Container Registry, Sonatype Nexus3. Notes Contribute to these docs","title":"Registry Management Overview"},{"location":"v2.0-be/registries/manage/","text":"Manage a Registry From Portainer Business Edition, you can manage Registries and Repositories. Managing a Repository Add a Tag Adding a tag to an image hosted in the registry is an easy task with Portainer, it doesn't require type any commands in the CLI. Go to Registries , choose the registry you want to manage and click browse . After that, you will see the repositories saved in that registry. Select the one you want to manage. The next step is to look at the top right of the screen, you will see a box with the section name Add tag , you only need write the name of the tag, select the image and click Add tag . If everything work as expected, you will see a pop up at the right top corner. Retag Note : If you have hosted your own Docker registry, you need to add a specific environment variable to enable retag and deleting. The env is REGISTRY_STORAGE_DELETE_ENABLED=TRUE . Another capability of Portainer Business Edition is Retagging the current images saved in a repository. To do this, you need to go to Registries , choose the registry you want to manage and click browse . After that, you will see the repositories saved in that registry. Select the image you want to Retag. After that, click Retag . Type the new tag for this image and click the \u2714 If everything work as expected, you will see a pop-up confirming the action. Remove a Tag Note : If you have hosted your own Docker registry, you need to add a specific environment variable to enable retag and deleting. The env is REGISTRY_STORAGE_DELETE_ENABLED=TRUE . You can remove a tag from Portainer Business Edition. To do this, you need to go to Registries , choose the registry you want to manage and click browse . After that, you will see the repositories saved in that registry. Select the image you want to Remove. Select the image/tag and click Remove . You will be asked for confirmation, if you're sure, click Remove . If everything works as expected, you will see a pop-up confirming the action. Notes Contribute to these docs","title":"Manage a Registry"},{"location":"v2.0-be/secrets/add/","text":"Add Secrets In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application\u2019s source code. In Docker 1.13 and higher, you can use Docker secrets to centrally manage this data and securely transmit it to only those containers that need access to it. Secrets are encrypted during transit and at rest in a Docker swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running. You can use secrets to manage any sensitive data which a container needs at runtime but you don\u2019t want to store in the image or in source control, such as: Usernames and passwords TLS certificates and keys SSH keys Other important data such as the name of a database or internal server Generic strings or binary content (up to 500 kb in size) Creating a Secret To create a secret in Portainer, go to Secrets and click Add Secret . In the next screen, you need to set a name for you secret, define the 'secret' , choose if you need to encode that secret, (this is useful when you set a password in plain text) and click Create the secret . Notes Contribute to these docs","title":"Add a new secret"},{"location":"v2.0-be/secrets/delete/","text":"Delete a Secret It is good practice to delete the secrets that you don't need anymore. Deleting a Secret To delete a secret, go to Secrets , select the secret you want delete and then, click Remove . Notes Contribute to these docs","title":"Delete secrets"},{"location":"v2.0-be/services/create/","text":"How to Create a new service Services are collections of containers. In this example, ee're going to deploy an NGINX Web Server. Note : This article only covers Docker Swarm environments at present. Creating a new service Click Services from the side menu and then Add Service . Complete the fields: Name: Choose a name for the service Registry & Image: Select where these are located Replicated or Global: Replicated in the same host or deployed Globally with one container in each host Ports: define the ports to expose for that service Further settings are available on this screen, once these have been set appropriately, click Create The Service . If successful, your service will be listed in the table of services. Notes Contribute to these docs","title":"Create a New Service"},{"location":"v2.0-be/services/logs/","text":"How to view services logs Service logs are incredibly useful for troubleshooting issues and service behaviour. Accessing to Service Logs Click Services and then choose the service you want to view the logs for. Click Service logs . Logs are then displayed with the ability to: Turn off Auto Refresh Wrap Lines Display Timestamps Search or filter logs Increase the number of lines to fetch Copy, Copy Selected or Unselect log lines Notes Contribute to these docs","title":"View Service Logs"},{"location":"v2.0-be/services/options/","text":"Configure Service Options Before of after you deploy a service, you can configure a wide range of options to your service. In this article, we going to review each option available that you can use from Portainer. To make additions or changes of configuration, you need go to Services and choose the service you want configure. Container Specification Environment Variables The environment variables are useful to set configuration at the same time that the container is created. If you need to add new environment variables after that service was deployed, you can do it. Labels Container labels can be used to leave notes of that container or specify configuration. Mounts You can mount or bind volumes from Portainer. You can also set if that volume needs to set in Read Only . The only thing you need to do is select a created volume, specify the path in container and click Apply Changes . Networks & ports Networks You can define one or more networks for your service; this can even been done after it has been deployed. You only need to create your network and then, select from the dropdown list. Published Ports Here, you can publish ports to access this container from outside the host. You can set new or modify the current ports. Host file entries This is used when you need to manually specify a hostname or url; associat the URL to an internal or external IP Address. Service specification Resource limits and reservations From Portainer, you can set limitations about the resource utilization, like Memory, CPU Reservation, CPU Limit, etc. Placement constraints Use placement constraints to control the nodes a service can be assigned to. Placement preferences While placement constraints limit the nodes a service can run on, placement preferences try to place tasks on appropriate nodes in an algorithmic way (currently, this is only spread evenly). Restart Policy Docker provides restart policies to control whether your containers start automatically when they exit, or when Docker restarts. Restart policies ensure that linked containers are started in the correct order. The options are the following: Any: Restart under any condition (Restarted host or Docker daemon). On Failure: Restart the container if it exits due to an error, which manifests as a non-zero exit code. None: Do not automatically restart the container. You can also adjust Restart Delay, Max Attempts and Restart Window. Update Configuration Updates a service as described by the specified parameters. The parameters are the same as docker service create. Refer to the description there for further information. Normally, updating a service will only cause the service\u2019s tasks to be replaced with new ones if a change to the service requires recreating the tasks for it to take effect. Logging Driver Docker includes multiple logging mechanisms to help you get information from running containers and services. These mechanisms are called logging drivers. Each Docker daemon has a default logging driver, which each container uses unless you configure it to use a different logging driver. Service Labels Add metadata to containers using Docker labels. You can use either an array or a dictionary. It\u2019s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software. Configs Docker 17.06 introduces swarm service configs, which allow you to store non-sensitive information, such as configuration files, outside a service\u2019s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. Secrets In terms of Docker Swarm services, a secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application\u2019s source code. Notes Contribute to these docs","title":"Configure Service Options"},{"location":"v2.0-be/services/rollback/","text":"Rollback a Service After make a change to a service in Docker Swarm, you can rollback those changes if your applications are not working as expected. Rollbacking a Service To rollback a service to the last state click Services , choose the service you want to rollback. Then click Rollback the service . You will be asked to confirm this rollback. If successful, a green pop up confirming will show at the top right of screen.","title":"Rollback a Service"},{"location":"v2.0-be/services/scale/","text":"How to scale a service This is a powerful feature that allows you to scale your services horizontally. Scaling a Service Click Services and then Click scale . Enter the number of replicas you want for this service and click the check box . If successful you will see the green pop up at the top right of screen. Refreshing this page will show you the replicas (3 in this case) running, depending on the size of the containers, you may have a slight delay in seeing this. Notes Contribute to these docs","title":"Scaling a Service"},{"location":"v2.0-be/services/status/","text":"Service task status Services in a Docker Swarm environment are a collection of tasks (or individuals containers). Portainer allows you to very quickly see the status of the containers are part of a service. Viewing the task of the services Click Services , and then click the dropwdown arrow to the left of the service you want to inspect. This shows the tasks that make up this service. In this example, you can see three running containers that make up the Docker Swarm service. Notes Contribute to these docs","title":"Service Task Status"},{"location":"v2.0-be/settings/apps/","text":"How to use Templates Template definitions are written in JSON. It must consist of an array with every template definition consisting of one element. Container template definition format A template element must be a valid JSON object. Example of a container template: { \"version\": \"2\", \"templates\": [ { // template1 }, { // template2 }, ... ] } It is composed of multiple fields, some mandatory and some optionals. type Template type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). NOTE: Type 3 (Compose stack) is limited to using the version: \u201c2\u201d stack format, this is a limitation of docker/libcompose. This field is mandatory. type Title of the template. This field is mandatory . description Description of the template. This field is mandatory . image The Docker image associated to the template. The image tag must be included. This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template\u2019s logo. This field is optional . registry The registry where the Docker image is stored. If not specified, Portainer will use the Dockerhub as the default registry. This field is optional . command The command to run in the container. If not specified, the container will use the default command specified in its Dockerfile. This field is optional . Example: { \"command\": \"/bin/bash -c \\\"echo hello\\\" && exit 777\" } env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } network A string corresponding to the name of an existing Docker network. Will auto-select the network (if it exists) in the templates view. This field is optional . Example: { \"network\": \"host\" } volumes A JSON array describing the associated volumes of the template. Each element in the array must be a valid JSON object that has a required container property. For each element in the array, a Docker volume will be created and associated when starting the container. If a bind property is defined it will be used as the source of a bind mount. If a readonly property is is defined and true, the volume will be mounted in read-only mode. This field is optional . Example: { \"volumes\": [ { \"container\": \"/etc/nginx\" }, { \"container\": \"/usr/share/nginx/html\", \"bind\": \"/var/www\", \"readonly\": true } ] } ports A JSON array describing the ports exposed by template. Each element in the array must be a valid JSON string specifying the port number in the container and the protocol. It can be optionally prefixed with the port that must be mapped on the host in the port: form. If the host port is not specified, the Docker host will automatically assign one when starting the container. This field is optional . Example: { \"ports\": [\"8080:80/tcp\", \"443/tcp\"] } labels A JSON array describing the labels associated to the template. Each element in the array must be a valid JSON object with two properties name and value. This field is optional . Example: { \"labels\": [ { \"name\": \"com.example.vendor\", \"value\": \"Acme\" }, { \"name\": \"com.example.license\", \"value\": \"GPL\" }, { \"name\": \"com.example.version\", \"value\": \"1.0\" } ] } privileged Should the container be started in privileged mode. Boolean, will default to false if not specified. This field is optional . { \"privileged\": true } interactive Should the container be started in foreground (equivalent of -i -t flags). Boolean, will default to false if not specified. This field is optional . { \"interactive\": true } restart_policy Restart policy associated to the container. Value must be one of the following: no unless-stopped on-failure always This field is optional. Will default to always if not specified. { \"restart_policy\": \"unless-stopped\" } hostname Set the hostname of the container. This field is optional . Will use Docker default if not specified. { \"hostname\": \"mycontainername\" } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to linux or windows. This will display a small platform related icon in the Portainer UI. This field is optional . { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Stack template definition format A template element must be a valid JSON object. Example of a stack template: { \"type\": 2, \"title\": \"CockroachDB\", \"description\": \"CockroachDB cluster\", \"note\": \"Deploys an insecure CockroachDB cluster, please refer to CockroachDB documentation for production deployments.\", \"categories\": [\"database\"], \"platform\": \"linux\", \"logo\": \"https://cloudinovasi.id/assets/img/logos/cockroachdb.png\", \"repository\": { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } } It is composed of multiple fields, some mandatory and some optionals. type emplate type, valid values are: 1 (container), 2 (Swarm stack) or 3 (Compose stack). A Swarm stack will be deployed using the equivalent of docker stack deploy whereas a Compose stack will be deployed using the equivalent of docker-compose. NOTE : Type 3 (Compose stack) is limited to using the version: \u201c2\u201d stack format, this is a limitation of docker/libcompose. This field is mandatory . type Title of the template. This field is mandatory . description Description of the template. This field is mandatory . repository A JSON object describing the public git repository from where the stack template will be loaded. It indicates the URL of the git repository as well as the path to the Compose file inside the repository. Element format: { \"url\": \"URL of the public git repository (mandatory)\", \"stackfile\": \"Path to the Compose file inside the repository (mandatory)\", } Example: { \"url\": \"https://github.com/portainer/templates\", \"stackfile\": \"stacks/cockroachdb/docker-stack.yml\" } This field is mandatory . administrator_only Should the template be available to administrator users only. This field is optional . Example: { \"administrator_only\": true } name Default name to use for this template in the UI. This field is optional . logo URL of the template\u2019s logo. This field is optional . env A JSON array describing the environment variables required by the template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select). This field is optional . Element format: { \"name\": \"the name of the environment variable, as supported in the container image (mandatory)\", \"label\": \"label for the input in the UI (mandatory unless set is present)\", \"description\": \"a short description for this input, will be available as a tooltip in the UI (optional)\", \"default\": \"default value associated to the variable (optional)\", \"preset\": \"boolean. If set to true, the UI will not generate an input (optional)\", \"select\": \"an array of possible values, will generate a select input (optional)\" } Example: { \"env\": [ { \"name\": \"MYSQL_ROOT_PASSWORD\", \"label\": \"Root password\", \"description\": \"Password used by the root user.\" }, { \"name\": \"ENV_VAR_WITH_DEFAULT_VALUE\", \"default\": \"default_value\", \"preset\": true }, { \"name\": \"ENV_VAR_WITH_SELECT_VALUE\", \"label\": \"An environment variable\", \"description\": \"A description for this env var\", \"select\": [ { \"text\": \"Yes, I agree\", \"value\": \"Y\", \"default\": true }, { \"text\": \"No, I disagree\", \"value\": \"N\" }, { \"text\": \"Maybe\", \"value\": \"YN\" } ], \"description\": \"Some environment variable.\" } ] } note Usage / extra information about the template. This will be displayed inside the template creation form in the Portainer UI. Supports HTML. This field is optional . { \"note\": \"You can use this field to specify extra information. It supports HTML .\" } platform Supported platform. This field value must be set to Linux or Windows . This will display a small platform related icon in the Portainer UI. This field is optional. { \"platform\": \"linux\" } categories An array of categories that will be associated to the template. Portainer UI category filter will be populated based on all available categories. This field is optional . { \"categories\": [\"webserver\", \"open-source\"] } Build and host your own templates The simplest way to use your own templates is to bind mount your own template file directly into the Portainer container, see Configuration. You can also build your own container that will use Nginx to serve the templates definitions. Clone the Portainer templates repository , edit the templates file, build and run the container: $ git clone https://github.com/portainer/templates.git portainer-templates $ cd portainer-templates # Edit the file templates.json $ docker build -t portainer-templates . $ docker run -d -p \"8080:80\" portainer-templates Now you can access your templates definitions at http://docker-host:8080/templates.json . You can also mount the templates.json file inside the container, so you can edit the file and see live changes: $ docker run -d -p \"8080:80\" -v \"${PWD}/templates.json:/usr/share/nginx/html/templates.json\" portainer-templates Notes Contribute to these docs","title":"App Templates"},{"location":"v2.0-be/settings/edge/","text":"Enable Edge Computing features In today\u2019s world you can easily have hundreds - if not thousands - of Docker-enabled devices in your environment. Most of these systems run without any form of clustering or run a lean orchestrator such as Docker Swarm or Kubernetes. Remote devices may be distributed across multiple sites and/or across many different networks, some may even be attached to the internet using mobile data or satellite. To be managed effectively, engineers need a way to control distributed instances centrally, which is exactly what Portainer does with Edge Computer Features. Enabling Edge Compute Features First you must enable Edge Compute in the Portainer Settings. Click Settings and scroll down to Edge Compute section. Enable the toggle and 3. click Save Settings After that, you will see that a few options appear in the side menu. More Resources Take a look to the Edge section in the User Guide to see how to use it. Deploy an Stack Add a Job Managind Edge Groups Notes Contribute to these docs","title":"Enable Edge Computing"},{"location":"v2.0-be/settings/host_management/","text":"Enable Host Management features From Portainer, you can enable Host Management Features. The benefit of enabling this setting is to do Host system browsing, understand what PCI devices, and physical disk are present in the node. To get access to this data from Portainer, you need to run the agent with the following environment variable CAP_HOST_MANAGEMENT: 1 . The following features are disabled by default for security reasons: Ability to manage the filesystem of the host where the agent is running Ability to retrieve hardware information about the host where the agent is running (PCI devices/disks) In order to enable these features, the agent must be configured properly by: Enabling the host management features via the CAP_HOST_MANAGEMENT environment variable Bind-mounting the root of the host in the agent container (must be bind-mounted in /host) Deploy Portainer Agent Docker Swarm To deploy a new agent with this setting enable, you must run the following: docker service create --name portainer_agent --network portainer_agent_network --publish mode=host,target=9001,published=9001 -e AGENT_CLUSTER_ADDR=tasks.portainer_agent -e CAP_HOST_MANAGEMENT=1 --mode global --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes --mount type=bind,src=/,dst=/host portainer/agent Deploying via stack file: version: '3.2' services: agent: image: portainer/agent environment: CAP_HOST_MANAGEMENT: 1 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes - /:/host ports: - target: 9001 published: 9001 protocol: tcp mode: host networks: - portainer_agent deploy: mode: global placement: constraints: [node.platform.os == linux] networks: portainer_agent: driver: overlay attachable: true . Notes Contribute to these docs","title":"Enable Host Management Features"},{"location":"v2.0-be/settings/lb/","text":"Enable external Load Balancer usage Enabling the load balancer feature will allow users to expose applications they deploy over an external IP address assigned by Cloud provider. Note : Ensure that your cloud provider allows you to create load balancers if you want to use this feature. Might incur costs. Enabling usage of External Balancer To do this, you need to open Portainer Business Edition, go to Cluster and the to Setup . After that, you need to enable the toggle Allow users to use external load balancer . After you enabled the toggle, scroll down and do a click in Save Configuration . Starting now, when you create a resource pool, you can define an external load balancer quota. Notes Contribute to these docs","title":"Enable use of external load balancer"},{"location":"v2.0-be/settings/namespaces/","text":"Limit usage of \"default\" Kubernetes Namespace (Kubernetes Only) By default, a Kubernetes cluster will instantiate a default namespace when provisioning the cluster to hold the default set of Pods, Services, and Deployments used by the cluster but for an any reason, you want to limitate the usage of that namespace, with Portainer Business Edition, you can do it. Limiting the usage of \"default\" namespace To do this, you need to open Portainer Business Edition, go to Cluster and the to Setup . After that, you need to enable the toggle Restrict access to the default namespace . After you enabled the toggle, scroll down and click Save Configuration . Starting now, the only user with the power to run applications in the default namespace is the Administrator of Portainer. Notes Contribute to these docs","title":"Limit usage of default namespace"},{"location":"v2.0-be/settings/overcommit/","text":"Over Commitment of Resources (Kubernetes Only) With Portainer Business Edition, you can use your resources on full where are most needed. You can configure more resources to namespaces than is physically available in the cluster. Important : By ENABLING resource over-commit, you are able to assign more resources to namespaces than is physically available in the cluster. This may lead to unexpected deployment failures if there is insufficient resources to service demand. By DISABLING resource over-commit (highly recommended), you are only able to assign resources to namespaces that are less (in aggregate) than the cluster total minus any system resource reservation. Enabling Over Commitment of Resources To do this, you need to open Portainer Business Edition, go to Cluster and then to Setup . After that, you need to enable the toggle Allow resource over-commit . After you enabled the toggle, scroll down and click Save Configuration . Disabling Over Commitment of Resources When you disable the Over Commitment of resources, you can reserve a system resource reservation percentage. To do this, you need to open Portainer Business Edition, go to Cluster and then to Setup . After that, you need to disable the toggle Allow resource over-commit , you cam then do a reservation of resources. Insert the percentage of the resources you want to reserve... After you disabled the toggle, scroll down and click Save Configuration . Notes Contribute to these docs","title":"Allow/Disallow over-commitment of resources"},{"location":"v2.0-be/settings/security/","text":"Security Options Portainer allows various configuration options to add secuirty to your environment. In this help article, we going to review the security options that you can find under Settings . Docker Endpoint Security Options Disable bind mounts for non-administrators : This security setting blocks the ability for non-admin users within Portainer to use bind mounts when creating containers and/or services/stacks. When this is enabled, the option to attach to a host file system path is removed. Disable privileged mode for non-administrators : This security setting blocks the ability for non-admin users within Portainer to elevate the privilege of a container to bypass SELinux/AppArmour. When this is enabled, the option to select \"Privileged\" mode when creating a container is removed. Disable the use of host PID 1 for non-administrators : This blocks the ability for non-admin users within Portainer to request that a deployed container operates AS the host PID. This is a security risk if used by a non-trustworthy authorized user as when they operate as PID1, they are in effect able to run any command in the container console as root on the host. Disable the use of Stacks for non-administrators : This is a \"sledgehammer\" method to remove any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer have provided the ability to disable some of the more common exploits, we cannot possibly block them all as there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry-points. Disable device mappings for non-administrators : This blocks the ability for users to map host devices into containers. Whilst the ability to map devices is generally used for good (eg mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount /dev/sda1 into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By enabling this feature, Portainer blocks the ability for non-admins to map ANY devices into containers. Disable container capabilities for non-administrators : Enabling the setting will hide the container capabilities tab for non-administrators when they are creating a container. Notes Contribute to these docs","title":"Security Options"},{"location":"v2.0-be/stacks/create/","text":"How to create a new Stack Stacks are collections of services running in a Docker Swarm environment. Deploying a new stack You can deploy a new stack from Portainer using the following options: Web editor: Using our Web Editor, you will capable to define the services for this stack using a docker-compose format. Upload: If you're already have a stack.yml file, you can upload from your computer to deploy that stack. Git Repository: You can use a docker-compose format file hosted in Github. Custom Template: If you already created a template of stacks, you can deploy from this option. Web Editor To use our web editor, you need to Select Stacks , name the stack, select Web Editor and you can start to define your services using the editor. You can also define Environment Variables if needed. When everything is set up, click Deploy the Stack . Uploading a stack file In Portainer, you can create Stacks from compose YML files. To achieve this. Click Stacks , then Add Stack . Now Name your new stack, select Upload and choose your compose file from your computer, add environment variables if needed and then click Deploy the Stack . Deploy from Github Repository If you have your compose file hosted in Github, you can deploy from there. Select Stacks , then Add Stack , select Git Repository . Name your stack, and then, you need to define information about your Github repository : Repository URL: Here, you need to set the URL of your Github Repository. Repository Reference: Here, you need to define your branch. Compose Path: Here, you need to define the path to your compose file from the root of the repository. If you need authenticate, define your user and password. NOTE : If you have a 2FA configured in Github, your passcode is your password. Set environment variables if needed and then click Deploy the Stack . Notes Contribute to these docs","title":"Add/Create a Stack"},{"location":"v2.0-be/stacks/duplicate_migration/","text":"Migrate a Stack to another Swarm Cluster From Portainer, you can migrate your stacks from one cluster to another. In this help article, you will learn how to do it. Migrating a Stack to another Swarm Cluster In this case, we have a local Swarm Cluster and we want to move 'my-awesome-stack' to another cluster. To do this, go to Stacks , and select your Stack. From the Duplicate/Migrate section, select the endpoint where you want to migrate. Once you selected the endpoint, click Migrate . You will see an pop-up advising about the migration. If you're sure, click Migrate . Once the migration is complete, you will see a pop-up confirming the migration. Notes Contribute to these docs","title":"Duplicate / Migrate Stacks"},{"location":"v2.0-be/stacks/inspect/","text":"Inspect a Stack In Portainer, you can inspect your stacks to see what is running or access to their logs and stats. Inspecting a Stack To inspect the task associated to your stack, select Stacks and then select the stack you want to inspect. Here you can: * View what services that make up this stack * If they are running or stopped * How many replicas running in each host * Access to logs * Inspect the task stats * Access to the container console Notes Contribute to these docs","title":"Inspect a Stack"},{"location":"v2.0-be/stacks/template/","text":"Create a template from a deployed Stack In Portainer, you can create an App template from deployed Stacks. This is really useful when you need to deploy the same stack several times. How to creating a Template from a Stack Select Stacks and select the desired and already deployed stack. Then click Create Template from stack . Now define some properties for this new template: Title: Name your new template. Description: Short description about your template. Notes: You can write notes about this template. Icon URL: You can set up a icon from a URL Platform: Here, you need to define if your template is ready for use in Linux or Windows environments. Type: Choose between Swarm and Docker Standalone. You can also upload another compose file from your computer or a Github repository if needed. Once this has been defined, you can add more services to your template. Once complete click create custom template . Notes Contribute to these docs","title":"Create a template from a Stack"},{"location":"v2.0-be/templates/deploy_container/","text":"Deploy a standalone app (Container) From Portainer, you can deploy a standalone app from the default template list. Deploying an standalone app To deploy a standalone container from the templates, you need to go to App Templates , enable the toggle Show container templates and pick the app you want to deploy. For this example, we will deploy an Apache Web Server. After that, define a name , network , access control if needed, port mapping , volumes and when all is set, do a click in Deploy the Container . You will see an animation in the button while the container is deploying: If everything work as expected, you will see a pop up confirming that the container was deployed. Notes Contribute to these docs","title":"Deploy an App (Container)"},{"location":"v2.0-be/templates/deploy_stack/","text":"How to deploy a stack from a template Portainer allows you to deploy an entire stack from a template from the template list which includes default and custom templates. Also see creating a template from a Stack . Deploying a Stack To deploy a stack, go to App Templates and choose the template you want to deploy. In this example, I will deploy a CockroachDB cluster. Set a name , define access control (if enabled with the toogle) and click Deploy the Stack You will see an animation in the button while the stack is deploying: If everything work as expected, you will see your new stack deployed. Click the name of your stack to see the details of the deployment: Notes Contribute to these docs","title":"Deploy a Stack"},{"location":"v2.0-be/troubleshooting/deprecated/","text":"Deprecated and removed features Deprecated features This section lists features and capabilities that have been marked as deprecated, and should no longer be used. Features and capabilities marked as deprecated will no longer receive enhancements or support. The table below provides an overview of deprecated features and capabilities. The Deprecated column contains the release in which the feature was marked deprecated, whereas the Remove column contains a tentative release in which the feature is to be removed. If no release is included in the Remove column , the release is yet to be decided on. Feature Deprecated Remove Disabling analytics via: --no-analytics v2.0 TBD Removed features This section outlines features & capabilities that have been removed from Portainer. Feature Removed Specifying external endpoints via JSON via --external-endpoints v2.0 Setting time between endpoint synchronization requests via --sync-interval v2.0 Disabling Portainer internal authentication via --no-auth v2.0 Specifying a templates file to load on first run via --templates-file v2.0 Preventing Portainer from running a snapshot of endpoints via --no-snapshot v2.0 Notes Contribute to these docs","title":"Deprecated and Removed Features"},{"location":"v2.0-be/troubleshooting/troubleshooting/","text":"Portainer Deployment Troubleshooting The FAQ is updated periodically and designed to answer the questions our users most frequently ask about Portainer If you are still experiencing issues after reading this FAQ, feel free to contact us via any one of the following channels: Slack for community support GitHub to log an issue if you've found a bug Youtube for guided tutorials and updates How do I upgrade Portainer Instructions for upgrading Portainer CE can be found here How do I reset my Portainer password? You can ask another Portainer admin to reset the password for you, or alternatively if it is for the default admin account (from when Portainer was initialized), you can try our password reset helper tool . There is an open feature request to bring this functionality inside Portainer, which can be tracked on our GitHub repository here . Why does my version number not match the latest version? If you have recently updated your version of Portainer, this usually indicates your browser has cached the page. To properly clear your cache, you will need to go into the browser settings and empty the cache. Note: You can use Ctrl + Shift + R on most browsers to load the specific page without cache, however you will need to repeat this on each page of Portainer to load the changes. Please also check you have pulled from the latest repo url. I signed up for a licence to BE but can't enter it in to CE, why not? Because of the difference in versions and features we don't provide the facility for a Business licence to be entered into CE. You will need to switch images from CE to BE. Once done you'll be able to enter the trial licence provide and get all the functionality of BE. The steps to install BE are at documentation.portainer.io You should experience no data loss in switching the images over. Users have access to an endpoint, but they cannot see anything. By default all resources inside an endpoint are assigned to administrator only for security reasons. To give non-admin users access you can use the access control widget within each resource to assign users ownership, or you can make the resource public to give all users access. Portainer lost it\u2019s configuration, why? Portainer as a Container: If you have not created a persistent volume for your Portainer container, then Portainer data will be stored inside the Docker container. If the container is then restarted, you will lose all of your data. Portainer as a Service: If you have not created a persistent volume for your Portainer service, then Portainer data will be stored inside the Docker container created by the service. If the service is updated, you may lose your Portainer configuration. See Deployment on how to create a persistent volume. If you have a persistent volume, then the issue may be that Portainer is not constrained to the node where the data is persisted. See the below section for more info. External endpoints are not working in the latest Portainer version, is this a bug? We are aware that the --external-endpoint feature is not working in some of the latest versions of Portainer. If you require use of external endpoints, we recommend rolling back to Portainer version 1.21.0 until a fix has been released. My host is using SELinux, can I use Portainer? If you want to manage a local Docker environment with SELinux enabled, you\u2019ll need to pass the --privileged flag to the Docker run command when deploying Portainer: docker run -d --privileged -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:latest You can also have a look at this helper . How can I use Portainer behind a proxy? With Portainer behind a proxy, some features requiring access to the Internet (such as Apps Templates) might be unavailable. When running Portainer as a container, you can set the HTTP_PROXY and HTTPS_PROXY env vars to specify which proxy should be used: docker run -d -p 9000:9000 -p 8000:8000 -e HTTP_PROXY=my.proxy.domain:7777 portainer/portainer-ee:latest For examples on how to configure a reverse proxy to work with Portainer, you can refer to our example repo here . Note: these are in no way production ready, and are intended solely for demonstration purposes. Exposed ports in the container view redirects me to 0.0.0.0, what can I do? You can \"fix\" this in two ways. In order for Portainer to be able to redirect you to your Docker host IP address and not the 0.0.0.0 address, you will have to change the configuration of your Docker daemon and add the --ip option. Note: that you will have to restart your Docker daemon for the changes to be taken in effect. Recommended : Go to Endpoints , select your endpoint and introduce the IP of the host in the field Public IP . Do a click in Update Endpoint . TLS Settings in local Kubernetes endpoint We're addressing a bug in the endpoint details view of a Kubernetes endpoint, TLS settings, and information about Docker TLS is incorrectly shown. Changing the TLS settings does not affect. The expected behavior is don't show TLS settings and Docker TLS message. These options are no needed, and no make any effect in the configuration of local Kubernetes endpoints. You can view more information about this bug and the progress for your resolution here . Can you view Deleted Docker Containers' logs in Portainer? There is no history of deleted containers kept, so once they are gone the logs will go as well. Why do Custom standalone app templates not show when using Swarm The underlying principle of Portainer is to enforce best practice across all functions, including Swarm. When using Swarm, you should always use Swarm services and not containers. Notes Contribute to these docs","title":"Portainer Deployment Troubleshooting"},{"location":"v2.0-be/upgrade/upddocker/","text":"Upgrade a Standalone Docker Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Docker Standalone Assuming you've used our recommended deployment scripts: when upgrading to the latest version of Portainer, use the following commands: docker stop portainer docker rm portainer Those 2 commands will stop and remove the container respectively. Doing this will NOT remove your other applications/containers/etc. Now that you have stopped and removed the old version of Portainer, you can run this command docker run -d -p 8000 :8000 -p 9000 :9000 --name = portainer --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee That will deploy the newest version of Portainer on your system, using the persistent data and upgrade the DB Now you can go to http://your-server-address:9000 and login. You should notice that the bottom left corner looks different than it did before. There is no more update nag and the version is no longer shown next to the Portainer logo. Agent Only Upgrade When upgrading to the latest version of Portainer Agent, use the following commands: docker stop portainer_agent docker rm portainer_agent Those 2 commands will stop and remove the container respectively. Doing this will NOT remove your other applications/containers/etc. Now that you have stopped and removed the old version of Portainer Agent, you can run this command docker run -d -p 9001 :9001 --name portainer_agent --restart = always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent Notes Contribute to these docs","title":"Upgrading on Docker"},{"location":"v2.0-be/upgrade/updk8s/","text":"Upgrade Kubernetes Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Steps to upgrade Portainer and or Portainer agent deployed into Kubernetes. Upgrade method depends on the original install method used. Using Helm Add Portainer helm repo running the following, ignore any warning about the repo being there already. helm repo add portainer https://portainer.github.io/k8s/ helm repo update Run the command below to upgrade to latest version of Portainer helm upgrade -n portainer portainer portainer/portainer --reuse-values Using YAML Manifest Method 1: Easiest way to upgrade is to use Portainer UI and use manifest files.. Copy the contents of manifest file from For NodePort https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml Agent Only https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-nodeport.yaml For LoadBalancer https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Agent Only https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-lb.yaml Login to portainer, in Kubernetes endpoint where portainer is installed go to Applications --> Advanced Deployment. Paste the yaml content. Paste the yaml content and click Deploy. Portainer should come back to a login page in a few seconds. Method 2: For NodePort kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-ee.yaml Agent Only kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-nodeport.yaml For Load Balancer kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer-lb-ee.yaml Agent Only kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/agent/portainer-agent-k8s-lb.yaml Now you can go to portainer url and login. You should notice that the bottom left corner looks different than it did before. There is no more update nag and the version is no longer shown next to the Portainer logo. Notes Contribute to these docs","title":"Upgrading on Kubernetes"},{"location":"v2.0-be/upgrade/updswarm/","text":"Upgrade a Docker Swarm Deployment Agent Versions Always match the agent version to Portainer Server version. i.e., while installing or upgrading to Portainer 2.6 make sure all the agents are also version 2.6. Docker Swarm Steps to upgrade Portainer and or Portainer agent deployed into Docker Swarm as a service. Run the following on manager node of your docker swarm cluster docker service ls Make note of the service names for Portainer To upgrade Portainer to the latest version, run the command below (You may need to replace Service Name portainer_portainer to match your setup) docker service update --image portainer/portainer-ee --force portainer_portainer To upgrade Portainer Agent to the latest version, run the command below (You may need to replace Service Name portainer_agent to match your setup) docker service update --image portainer/agent --force portainer_agent That will deploy the newest version of Portainer on your system, using the persistent data and upgrade the DB Now you can go to http://your-server-address:9000 and login. You should notice that the bottom left corner looks different than it did before. There is no more update nag and the version is no longer shown next to the Portainer logo. Notes Contribute to these docs","title":"Upgrading on DockerSwarm"},{"location":"v2.0-be/users/create-team/","text":"Create a new team The Team Management feature means that you can now assign users into teams, authorize teams to access endpoints, enable containers/services/volume management at the team level, and provide fine-grained access control. Creating a Team To create a team in Portainer, select Users . Then 1. select Teams 2.Type the name of Team and 3. click Create Team . Then, you're done. Notes Contribute to these docs","title":"Create a Team"},{"location":"v2.0-be/users/create/","text":"Create a User Portainer allows the management of users and access. Creating a User Click Users Type the username 2. pick a password (a strong one) and 3. click Create User . List all users Confirmation at the top right shows on completion. Notes Contribute to these docs","title":"Create a User"},{"location":"v2.0-be/users/promoting/","text":"How to promote a regular user to administrator First click Users and select the user you want to promote. Enable the toggle Administrator in the next screen and click Save . Confirmation appears at the top right of screen. The user list now shows the selected user with the administrator role. Notes Contribute to these docs","title":"Promote a User as Admin"},{"location":"v2.0-be/users/reset-admin/","text":"Reset password for the Admin user It can happen to anyone, admin passwords get forgoteen and lost all the time. If this ever happens to your Portainer admin, you can follow these steps to reset it. Resetting Admin password in Portainer running as container Reset the password for the Admin user can be accomplished using our reset password container helper . First, stop the Portainer container by running: docker stop \"id-portainer-container\" Run the helper with the following command. Be advised that you need to mount the Portainer data volume. docker run --rm -v portainer_data:/data portainer/helper-reset-password If successful, your output should look like this: 2020/06/04 00:13:58 Password successfully updated for user: admin 2020/06/04 00:13:58 Use the following password to login: &_4#\\3^5V8vLTd)E\"NWiJBs26G*9HPl1 Start the Portainer container running and try login with the password generated: docker start \"id-portainer-container\" Resetting Admin password in Portainer running as a stack/service To reset the password of the Admin user in Portainer running as Stack or Service, we need to scale the Portainer service to zero. To do this, you can run the following: docker service scale portainer_portainer=0 Run the helper using the same bind-mount/volume for the data volume: docker run --rm -v portainer_portainer_data:/data portainer/helper-reset-password If successful, your output should look like this: 2020/06/04 00:13:58 Password successfully updated for user: admin 2020/06/04 00:13:58 Use the following password to login: &_4#\\3^5V8vLTd)E\"NWiJBs26G*9HPl1 Start the Portainer service scaling up and try login with the password generated: docker service scale portainer_portainer=1 Notes Contribute to these docs","title":"Reset Administrator Password"},{"location":"v2.0-be/users/reset-user/","text":"How to change/reset user password Select Users and then select the User who's password you would like to reset. Set the new password (a strong one) and click update password . You will see confirmation at the top right of screen if successful. Notes Contribute to these docs","title":"Reset User Password"},{"location":"v2.0-be/users/roles/","text":"Roles Description of Roles Portainer Business come with Role-Based Access Control features that refines the access privileges available natively within Portainer. The RBAC feature allows you to create fine-grained access for users across all resources and all endpoints defined within Portainer. Basics Understanding Role is a predefined set of privileges. Privileges define rights to perform actions. Users are assigned roles and each role has specific privileges. To assign privileges, you pair a user or team with a role and associate that pairing with an endpoint or endpoint group. A single user or team can have different roles for different endpoints in the Portainer inventory. Built-in Roles There are several types of roles: Endpoint Administrator: has complete control over the resources deployed within a given endpoint, but is not able to make any changes to the infrastructure that underpins an endpoint (i.e. no host management), nor are they able to make any changes to Portainer internal settings. Operator: has operational control over the resources deployed within a given endpoint. Operator is able to Update/Re-deploy/Start/Stop Containers/Services, check logs and console into containers but is not able to create any resources. Helpdesk: has read-only access over the resources deployed within a given endpoint but is not able to make any changes to any resource, nor open a console to a container, or make changes to a container\u2019s volumes. Standard User: has complete control over the resources that a user deploys, or if the user is a member of a team, complete control over the resources that users of that team deploy. Read-Only User: has read-only access over the resources they are entitled to see (resources created by members of their team, and public resources). The Administrator role sits outside of these four roles, and effectively acts as a \u201cGlobal Admin\u201d. A user assigned this role has complete control over Portainer settings, and all resources on every endpoint under Portainer control. Notes Contribute to these docs","title":"RBAC Overview"},{"location":"v2.0-be/users/user-team/","text":"Add a user to a team First select Users under settings , then select Teams and choose the team that you want to add users to. Click Add next to the user you want to add to the team. You should now see the user under team members Notes Contribute to these docs","title":"Add a User to a Team"},{"location":"v2.0-be/users/viewer/","text":"Effective Access Viewer In Portainer Business Edition, you will capable to see in a general view what role had each user. Viewing Access To see what access a user has, click Roles , in Effective access viewer you will see a dropdown menu, pick the user from there and you will see what permissions and where that role was granted to that user. Notes Contribute to these docs","title":"Effective access viewer"},{"location":"v2.0-be/volumes/attaching/","text":"Attach an existing Volume to a Container Portainer can attach a new volume to a running container. Be advised that this operation destroys the running container and starts a new one with the volume attached. Backup your data before doing this. Attaching a volume Go to Containers and select the container that you want to attach a volume to. Click Duplicate/Edit. Scroll down to see the options for this container. Select Volumes and click Map an Additional Volume. Next, type the path in the container, in the example below, for an NGINX container, the path to persist is \"/usr/share/nginx/html\". We also need to specify the volume created. Finally, click Deploy The Container . You will receive the following warning: If successful you will see the confirmation pop up at the top right of screen. To confirm the configuration of your container, select it and scroll to the volume configuration, you should see a similar screen to the below: Notes Contribute to these docs","title":"Attach an Existing Volume"},{"location":"v2.0-be/volumes/browse/","text":"Browse a volume Portainer allows users to view volumes in Docker Swarm nodes. Browsing a Volume Click Volumes from the side menu, and then click browse next to the volume you want to explore. From this screen, you can upload files to this volume and expose it to the container quickly and without using a CLI. Notes Contribute to these docs","title":"Browse a Volume"},{"location":"v2.0-be/volumes/create/","text":"How to create a new volume Volumes are used to make persistent storage that you can manage from Portainer. Note: Creating a standalone volume is only supported in a Docker Swarm and Docker Standalone endpoints. Creating a LOCAL volume Click Volumes from the side menu and then click Create Volume . Complete the detail fields for this volume: Name: Give your volume with a descriptive name Driver Configuration: Local NFS: For local volumes leave this off CIFS: For local volumes leave this off Once complete, click Create the Volume . Creating an NFS volume In Portainer, you can mount an NFS volume to persist the data of your containers. To achieve this, go to Volumes and then click Create Volume. Complete the detail fields for this volume: Name: Give your volume with a descriptive name Driver Configuration: Local NFS: Enable this toggle Under the NFS Settings section. You will find: Address: Type the hostname or IP address of your NFS Server. NFS Version: Choose the version of NFS that your NFS Server uses. Mount Point: The path where that volume is mounted. E.g. /mnt/nfs01. Options: We recommend leaving the default values in this field. When this is complete click Create the Volume . Creating a CIFS volume In Portainer, you can mount a CIFS volume to persist the data of your containers. To achieve this, go to Volumes and then click Create Volume. Complete the detail fields for this volume: Name: Give your volume with a descriptive name. Driver Configuration: Local NFS: Leave this toggle off CIFS: Enable this toggle In CIFS Settings section. You will find: Address: Type your CIFS Server name or IP Address Share: Type the name of the share resource CIFS Version: Pick the correct version of CIFS that you're using Username: Your defined user to authenticate Password: Your defined password to authenticate When this is complete click Create the Volume . Notes Contribute to these docs","title":"Create a Volume"},{"location":"v2.0-be/volumes/delete/","text":"Delete a Volume From Portainer you can delete a volume. Note that all the content inside the deleted volume will be erased. Deleting a Volume Go to Volumes , select the volume you want remove, and click Remove . Note: You can't delete volumes attached to a container, to do this, remove the container first and then, try to delete the volume. Notes Contribute to these docs","title":"Delete a Volume"},{"location":"v2.0-be/webhooks/create/","text":"Webhooks You can use webhooks to cause an action in a service in response to a push event in a repository. Webhooks are POST requests sent to a URL you define in Docker Hub or another registry. Enable Service Webhook To enable a webhook for a service, go to Services , click in the service you want to set up the Webhook, and enable the toggle Service Webhook . After you enable the toggle you will see the URL to configure your webhook in Docker Hub or another repository. do a click in copy to get the full URL. Examples Here, you can find a few examples to understand how easy is to trigger the webhook. Redeploy <form action=\"http://192.168.1.12:9000/api/webhooks/638e6967-ef77-4906-8af8-236800621360\" method=\"post\"> Redeploy with latest image of same tag <input type=\"submit\" /> </form> Update Service with another tag <form action=\"http://192.168.1.12:9000/api/webhooks/638e6967-ef77-4906-8af8-236800621360?tag=latest\" method=\"post\"> Update Service image with different tag <input type=\"submit\" /> </form> Configuring the Webhook in Docker Hub To see how to complete the configuration in Docker Hub, click here . Notes Contribute to these docs","title":"Configure a Webhook"}]}